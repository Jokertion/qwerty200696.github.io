<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>王立杰的博客</title>
    <link>http://wangwlj.com/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>所谓王者，必卓然特立，争当人杰。</description>
    <pubDate>Thu, 04 Jan 2018 10:46:58 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>西瓜书《机器学习》学习笔记(2)：比较检验与偏差方差</title>
      <link>http://wangwlj.com/2018/01/04/ML_chap2_02/</link>
      <guid>http://wangwlj.com/2018/01/04/ML_chap2_02/</guid>
      <pubDate>Thu, 04 Jan 2018 10:46:46 GMT</pubDate>
      <description>
      
        
        
          &lt;h2 id=&quot;比较检验-2-4-P37&quot;&gt;&lt;a href=&quot;#比较检验-2-4-P37&quot; class=&quot;headerlink&quot; title=&quot;比较检验(2.4, P37)&quot;&gt;&lt;/a&gt;比较检验(2.4, P37)&lt;/h2&gt;&lt;p&gt;在比较学习器泛化性能的过程中，&lt;strong&gt;统计假
        
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="比较检验-2-4-P37"><a href="#比较检验-2-4-P37" class="headerlink" title="比较检验(2.4, P37)"></a>比较检验(2.4, P37)</h2><p>在比较学习器泛化性能的过程中，<strong>统计假设检验（hypothesis test）</strong>为学习器性能比较提供了重要依据，即若A在某测试集上的性能优于B，那A学习器比B好的把握有多大。</p><h3 id="假设检验-2-4-1-P38"><a href="#假设检验-2-4-1-P38" class="headerlink" title="假设检验(2.4.1, P38)"></a>假设检验(2.4.1, P38)</h3><p>假设检验(Hypothesis Testing)是数理统计学中根据一定假设条件<strong>由样本推断总体</strong>的一种方法。</p><p>“假设”指的是对学习器泛化错误率分布的某种判断或猜想，如“$\epsilon = \epsilon_0 $”，现实任务中，我们并不知道学习器的泛化错误率$\epsilon$，但是可以通过测试错误率$\hat \epsilon$推算。</p><p>在包含了 m 个样本的测试集上，【泛化错误率为 $\epsilon$ 的学习器】被测得测试错误率为$ \hat \epsilon $的概率为：<br>$$P(\hat\epsilon;\epsilon) = \begin{pmatrix} m \\ \hat\epsilon\times m  \end{pmatrix} \epsilon^{\hat\epsilon\times m}(1-\epsilon)^{m-\hat\epsilon\times m}$$</p><blockquote><p>上式中的$\begin{pmatrix} m \\ \hat\epsilon\times m  \end{pmatrix} $表示$C_m^{m’}$，即从m个数中任取m’个数。</p></blockquote><p>这个概率，表达了【泛化错误率为 $\epsilon$ 的学习器】被测得【测试错误率】为 $\hat{\epsilon}$ 的可能性。 $\hat{\epsilon} $取0~100%。若以这个【可以测得的测试错误率$ \hat{\epsilon} $】作为自变量，以概率 $P(\hat{\epsilon};\epsilon) $为因变量，建立平面坐标图，则对于不同的测试错误率，有不同的可能性。在某点可能性越高，这个未知的【泛化错误率$ \epsilon $】和这个点代表的测试错误率的关系就越密切。</p><p>现在要找其可能性最高的点，就要对概率$ P(\hat{\epsilon};\epsilon)$ 求 $\epsilon$ 的导数，导数为0时，存在极值。</p><p>而对此概率函数求导并解出导函数等于0的式子之后，发现存在一个值 $\epsilon_0$ ，使得$P(\hat{\epsilon};\epsilon)$在$\epsilon=\epsilon_0$时最大，$|\epsilon-\epsilon_0|$ 增大时减小。整个图像其实是个山峰形状，符合二项分布。</p><p>那么此时也可以反过来讲，如果这个泛化错误率 $\epsilon$ 已知为 $\epsilon_0$ ，则理论上，横坐标为 $\epsilon_0$的概率值$P(\hat{\epsilon};\epsilon)$是最大的。这也和书中图2.6的例子一致。</p><p>即：<strong>若泛化错误率为$ \epsilon_0$ ，则测试错误率也为 $\epsilon_0$ 的概率最大（可能性最高）</strong>。</p><p>此时，我们得到了泛化错误率为$ \epsilon_0$，我们可以用这个数值来进行假设，假设这个学习器的泛化错误率不会超过 $\epsilon_0$。</p><p>即假设：“$ H_0:\epsilon≤\epsilon_0$ ”。</p><p>到底要不要接受这个假设呢？</p><p>我们需要检验一下。</p><blockquote><p>显著度（显著性水平）是估计总体参数落在某一区间内，可能犯错误的概率，用$\alpha$表示。$\alpha$的常用取值很小，如0.05，0.1等。<br>$1-\alpha$则表示置信度(confidence)。</p></blockquote><p>通过二项检验(binomial test)，我们得到结论：在$\alpha$的显著度下，假设$ H_0:\epsilon≤\epsilon_0$ 不能被拒绝，能<strong>以$1-\alpha$的置信度认为，学习器的泛化错误率不大于$\epsilon_0$</strong>；否则假设被拒绝，即在$\alpha$的显著度下可认为该学习器的泛化错误率大于$\epsilon_0$。</p><hr><p>现实中我们并非仅作出一次留出法估计，而是做多次，所以会得到不同的多个测试错误率，假定为k个测试错误率： $\hat \epsilon_1$、$\hat \epsilon_2、\cdots 、\hat \epsilon_k$，则平均错误率$ \mu  $和方差$ \sigma^{2}$为：<br>$$\mu = \frac 1k \sum_{i=1}^k\hat \epsilon_i $$<br>$$ \sigma^2 = \frac{1}{k-1} \sum_{i=1}^k (\hat \epsilon_i - \mu)^2$$</p><blockquote><p>假设X服从标准正态分布N（0,1），Y服从$ \chi^2$分布，那么$ T=X/\sqrt{Y/n}$  的分布称为自由度为n的t分布,记为$T \sim t(n)$。</p><p>t分布这边需要一定的数学基础。默默记住吧。</p></blockquote><p>T 为自由度为 n 的 t 分布，变量 $\tau_{t}=(\sqrt{k}(\mu-\epsilon_0))/\sigma $服从自由度为 k-1 的 t 分布。（ $\mu-\epsilon_{0} $服从正态分布， $\sigma^{2} $服从自由度为 k-1 的$ \chi^2 $分布）</p><p><img src="http://ww1.sinaimg.cn/large/c38a0784ly1fn3pvrkvwjj20em09pjrr.jpg" alt=""></p><p>由此图和 t 分布图的性质可知，最高点处就是测试错误率的最大值$\epsilon_0$ 。</p><p>现在要重新假设了，“ $H_1:\mu=\epsilon_0 $”。</p><p>接下来就是继续确定显著度 $\alpha$ ，确定门槛值（此处用双边假设），最后进行在置信度为 $1-\alpha$ 下的判断了。</p><h3 id="交叉验证-t-检验-2-4-2-P40"><a href="#交叉验证-t-检验-2-4-2-P40" class="headerlink" title="交叉验证 t 检验(2.4.2, P40)"></a>交叉验证 t 检验(2.4.2, P40)</h3><p>回顾一下上一篇中的<strong>k折交叉验证</strong>：</p><blockquote><p>“k折交叉验证法”(cross validation)先将数据集D划分为k个大小相似的互斥子集，即$D=D_1\cup D_2 \cup \cdots\cup D_k,D_i \cap D_j =\oslash (i\neq j)$</p></blockquote><p>如果说前一种的<strong>假设检验是得到单个学习器的泛化错误率的大致范围假设</strong>，那么<strong>“交叉验证t检验”方法就是在比较A、B两学习器性能的优劣</strong>了（不过偏向于验证A、B性能是否相同）。</p><p>现在有两个学习器A和B，使用 k 折交叉验证法得到测试错误率分别为 $\epsilon_{1}^{A},\epsilon_{2}^{A},\epsilon_{3}^{A},…\epsilon_{k}^{A}$ 和$\epsilon_{1}^{B},\epsilon_{2}^{B},\epsilon_{2}^{B},…\epsilon_{k}^{B} $。其中$ \epsilon_{i}^{A} $和 $\epsilon_{i}^{B} $是在相同的第 i 折训练/测试集上得到的结果。</p><blockquote><p>注意，此时的测试错误率和之前的假设检验那一节的测试错误率采用了不同的符号，此时由于没有提到泛化错误率，测试错误率被标记为$ \epsilon $，只不过增加了上下角标，请各位不要将其与上一节的泛化错误率混淆。</p></blockquote><p>基本思想：若两个学习器的性能相同，则它们使用的训练/测试集得到的测试错误率应相同，即 $\epsilon_{i}^{A}=\epsilon_{i}^{B} $。</p><p>实际上却不会像理想状态一样，两个学习器的测试错误率并不完全相同，而是存在一定的微小差值。我们想要判断两个学习器的性能是否有显著差别，就要利用这个差值进行假设检验。</p><p>若两个学习器性能相同，这个差值均值应该为0。因此可对这k个差值对“学习器A和B性能相同”这个假设做 t 检验。</p><p>1、先对每一对结果求差，$ \Delta_i=\epsilon_{i}^{A}-\epsilon_{i}^{B}$</p><p>2、计算出这$k$个差值的均值$ \mu $和方差 $\sigma^2$</p><p>3、根据 t 检验的公式$ T=X/\sqrt{Y/n} $，得 $\tau_t=|\frac{\sqrt{k}\mu}{\sigma}|$ ，满足自由度为 k-1 的 t 分布，故在显著度$ \alpha $，若其小于临界值 $t_{\alpha/2,k-1} $，则假设不能被拒绝，即认为两个学习器性能没有显著的差别。反之则认为平均错误率小的性能更优。</p><p>这里$t_{\alpha/2,k-1}$ 是分布上尾部累积分布为$\alpha/2$ 的临界值。</p><p>但是这样使用 k 折交叉验证法，通常情况下会因为样本有限，使得不同轮次的训练集产生一定程度的重叠。这样训练出来的学习器，会让得出的这组测试错误率无法做到彼此完全独立。</p><p>而进行有效的假设检验的一个重要的前提就是：测试错误率均为泛化错误率的独立采样。（例如 t 分布就需要随机变量X和Y相互独立。）</p><p>所以为了缓解这个问题，可采用“5×2交叉验证”法。</p><h4 id="5×2交叉验证-2-4-2-P41"><a href="#5×2交叉验证-2-4-2-P41" class="headerlink" title="5×2交叉验证(2.4.2, P41)"></a>5×2交叉验证(2.4.2, P41)</h4><p>待补。</p><h3 id="McNemar检验-2-4-3-P41"><a href="#McNemar检验-2-4-3-P41" class="headerlink" title="McNemar检验(2.4.3, P41)"></a>McNemar检验(2.4.3, P41)</h3><p>McNemar检验适用于二分类问题，与成对t检验一样也是用于比较两个学习器的性能大小。通过联列，可以获得学习器A和B的分类结果的差别。下表即为两分类器分类差别列联表， e 为样本数。</p><p><img src="http://ww1.sinaimg.cn/large/c38a0784ly1fn4g3oembgj20es08474e.jpg" alt="列联表"></p><p>主要思想是：若两学习器的性能相同，则A预测正确B预测错误数应等于B预测错误A预测正确数，即$e_{01}=e_{10}$，且$|e_{01}-e_{10}|$符合正态分布。</p><blockquote><p>$| e_{01}-e_{10}|$为什么符合正态分布？</p><p>按理说，实际生活中，凡自然状态下的整体数据分布几乎都符合<strong>正态分布</strong>，那么当假设两学习器性能相同的时候，如果用大量不同的测试集进行测试，这个差值应该就可能符合正态分布。</p></blockquote><p>McNemar检验考虑变量：</p><p><img src="http://ww1.sinaimg.cn/large/c38a0784ly1fn4gg36qwrj209902j3yb.jpg" alt="McNemar检验变量"></p><blockquote><p>但上式中的“-1”并非因为$ |e_{01}-e_{10}| $的均值 $\mu$ 为1，实际上均值$ \mu $应近似为0，这里的“-1”，是为了<strong>连续性校正</strong>。</p><p>什么是连续性校正？$2*2$列联表资料是分类资料,所以样本量较小时要进行连续性校正。。卡方检验要求：最好是大样本数据。一般每个个案最好出现一次，四分之一的个案至少出现五次。如果数据不符合要求，就要应用校正卡方。参见<a href="https://en.wikipedia.org/wiki/McNemar%27s_test#cite_note-Edwards1948-3" target="_blank" rel="external">维基百科</a></p></blockquote><p>上述变量$\tau_{\chi^2}$ 符合自由度为1 的$ \chi^2 $分布。</p><blockquote><p>$ \chi^2 $分布的定义：若k个独立的随机变量$Z_1,Z_2,⋯,Z_k$，且符合标准正态分布$N(0,1)$，则这k个随机变量的平方和 $X=∑_{i=1}^kZ^2_i$为服从自由度为k的卡方分布，记为： $X\sim \chi^2(k)$。<br>卡方分布的期望与方差分为为：<br>$E(\chi^2)=k，D(\chi^2)=2k$，其中k为卡方分布的自由度。</p></blockquote><p>给定显著度$\alpha $，当上述变量小于临界变量值的时候，不能拒绝假设，即认为两学习器的性能没有显著差别；否则拒绝假设，即认为两者性能有显著差别，平均错误率较小的学习器性能较好。这个过程也是自由度为1 的卡方检验。</p><blockquote><p>$\chi^2 $检验，中文名为<strong>卡方检验</strong>。卡方检验是一种用途很广的计数资料的假设检验方法。它属于非参数检验的范畴，主要是比较两个及两个以上样本率( 构成比）以及<strong>两个分类变量的关联性分析</strong>。其根本思想就是在于比较理论频数和实际频数的吻合程度或拟合优度问题。</p></blockquote><h3 id="Friedman检验与Nemenyi后续检验-2-4-4-P42"><a href="#Friedman检验与Nemenyi后续检验-2-4-4-P42" class="headerlink" title="Friedman检验与Nemenyi后续检验(2.4.4, P42)"></a>Friedman检验与Nemenyi后续检验(2.4.4, P42)</h3><p>上述的三种检验（假设检验、交叉验证t检验，McNemar检验）都只能在一组数据集上，Friedman检验则可以在多组数据集进行多个学习器性能的比较，基本思想是在同一组数据集上，根据测试结果（例：测试错误率）对学习器的性能进行排序，赋予<strong>序值1,2,3…</strong>，相同则平分序值，如下图所示：</p><p><img src="http://ww1.sinaimg.cn/large/c38a0784ly1fn4o1uvti5j20h005yglo.jpg" alt=""></p><blockquote><p>比如：D1数据集上，算法A的性能最好，其次算法B的性能，最差的是算法C的性能。<br>数字越小，代表该算法在该数据集上的表现越好。</p></blockquote><p><font color="000AA0">Friedman检验</font>：判断算法是否性能都相同。 检验变量$\tau_{\chi^2}$与F检验的临界值进行比较。</p><p>若<strong>“H0：所有算法的性能相同”</strong>这个假设被拒绝，则需要进行后续检验(post-hoc test)，来得到具体的算法之间的差异。常用的就是<strong>Nemenyi后续检验</strong>。</p><p>Nemenyi检验计算出平均序值差别的<strong>临界值域</strong>，<strong>若两个算法的平均序值差超出了临界值域CD，则相应的置信度1-α拒绝“两个算法性能相同”的假设</strong>。</p><p>总结一下多学习器的比较：</p><ul><li>Friedman + Nemenyi</li><li>Friedman 检验(基于序值，F检测，判断“是否都相同”)</li><li>Nemenyi 后续检验 (基于序值，进一步判断两两差别)</li></ul><h2 id="偏差与方差-2-5-P44"><a href="#偏差与方差-2-5-P44" class="headerlink" title="偏差与方差(2.5, P44)"></a>偏差与方差(2.5, P44)</h2><p>“偏差-方差分解”(bias-variance decomposition)是解释学习算法泛化性能的重要工具。</p><ul><li>测试样本：x</li><li>测试样本x在数据集中的标记： $y_D$</li><li>测试样本x的真实标记： y</li><li>训练集： D</li><li>从训练集 D 上学得的模型f</li><li>模型 f 在测试样本x上的预测输出$f(x;D) $</li></ul><p>从而可得：</p><p>学习算法的期望预测：<br>$$\bar f(x) = \mathbb{E}_D [f(x;D)] $$<br>使用样本数相同的不同训练集产生的<font color="00AA00"><strong>方差</strong></font>为：度量了同样大小的训练集的变动所导致的学习性能的变化，也就是<strong>数据扰动所造成的影响</strong>。<br>$$var(x) = \mathbb{E}_D [(f(x;D)- \bar f (x) )^2] $$</p><p><font color="00AA00"><strong>噪声</strong></font>(数据集标记和真实标记的方差)为：当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了<strong>学习问题本身的难度</strong>。<br>$$ \varepsilon^2 =  \mathbb{E}_D [(y_D - y)^2]$$</p><p><font color="00AA00"> <strong>Bias（偏差）</strong></font>：期望输出与真实标记的偏离程度，刻画了<strong>学习算法本身的拟合能力</strong>。<br>$$bias^2(x) = (\bar f (x) - y)^2 $$</p><p>对回归任务，泛化误差可通过“偏差-方差分解”拆解为：<br>$$E(f;D) = bias^2(x) + var(x) + \varepsilon^2 $$</p><p>也就是说，<strong>泛化误差可分解为 偏差、方差与噪声之和</strong>。<br>偏差-方差分解说明，<strong>泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的</strong>。</p><p>一般来说，偏差与方差是由冲突的，这称为“偏差-方差窘境”。<br><img src="http://ww1.sinaimg.cn/large/c38a0784ly1fn4m77isg5j20k00fvt8z.jpg" alt="偏差-方差窘境"></p><p>随着训练程度的提升，期望预测值与真实值之间的差异越来越小，即偏差越来越小，但是另一方面，随着训练程度加大，学习算法对数据集的波动越来越敏感，方差值越来越大。换句话说：<strong>在欠拟合时，偏差主导泛化误差，而训练到一定程度后，偏差越来越小，方差主导了泛化误差</strong>。因此训练也不要贪杯，适度辄止。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>周志华《机器学习》</li><li><a href="https://zhuanlan.zhihu.com/p/29248751" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/29248751</a></li><li><a href="http://blog.csdn.net/bitcarmanlee/article/details/52279907" target="_blank" rel="external">卡方分布与卡方检验</a></li><li><a href="http://blog.sina.com.cn/s/blog_4a0824490102v8tz.html" target="_blank" rel="external">卡方检验（Chi-square test）和费舍尔精确检验（Fisher exact test）</a></li></ul>]]></content:encoded>
      
      <comments>http://wangwlj.com/2018/01/04/ML_chap2_02/#disqus_thread</comments>
    </item>
    
    <item>
      <title>西瓜书《机器学习》学习笔记(1)：评估方法与度量指标</title>
      <link>http://wangwlj.com/2018/01/03/ML_chap2_01/</link>
      <guid>http://wangwlj.com/2018/01/03/ML_chap2_01/</guid>
      <pubDate>Wed, 03 Jan 2018 13:31:09 GMT</pubDate>
      <description>
      
        &lt;p&gt;笔记直接跳过了第一章，从第二章开始。&lt;/p&gt;
&lt;p&gt;本次笔记主要回顾评估方法与性能度量指标。&lt;br&gt;&lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<p>笔记直接跳过了第一章，从第二章开始。</p><p>本次笔记主要回顾评估方法与性能度量指标。<br><a id="more"></a></p><h2 id="经验误差与过拟合-2-1-P23"><a href="#经验误差与过拟合-2-1-P23" class="headerlink" title="经验误差与过拟合(2.1, P23)"></a>经验误差与过拟合(2.1, P23)</h2><p>学习器在训练集上的误差称为<strong>训练误差</strong>(training error)或<strong>经验误差</strong>(empirical error)，在新样本上的误差称为<strong>泛化误差</strong>(generalization error)，我们希望得到泛化误差小的学习器。</p><p>过拟合(overfitting)，欠拟合(underfitting)。</p><p>多种因素导致过拟合，最常见的就是由于学习能力过于强大，以至于把训练样本不太一般的特性都学到了。欠拟合相反。</p><p>欠拟合比较容易克服，如在决策树学习中学习扩展分支，在神经网络学习中增加训练轮数等。</p><p>过拟合无法彻底避免。只能“缓解”，减小风险。</p><h2 id="评估方法-2-2-P24"><a href="#评估方法-2-2-P24" class="headerlink" title="评估方法(2.2, P24)"></a>评估方法(2.2, P24)</h2><p>测试集(testing set)上的测试误差(testing error) 作为泛化误差的近似。</p><h3 id="留出法-2-2-1-P25"><a href="#留出法-2-2-1-P25" class="headerlink" title="留出法(2.2.1, P25)"></a>留出法(2.2.1, P25)</h3><p>“留出法”(hold-out) 将数据集D划分为两个<strong>互斥</strong>的集合，其中一个集合作为训练集S，另一个作为测试集T，即$D=S\cup T,S\cap T=\oslash $。</p><p>常见的划分为：大约2/3-4/5的样本用作训练，剩下的用作测试。</p><p>注意：</p><ul><li>训练/测试集的划分需要尽可能保持<strong>数据分布的一致性</strong>。</li><li>由于划分的随机性，单次留出法得到的评估结果往往不够稳定可靠，一般采用<strong>若干次随机划分、重复进行实验评估后取平均值</strong>。</li></ul><h3 id="交叉验证法-2-2-2-P26"><a href="#交叉验证法-2-2-2-P26" class="headerlink" title="交叉验证法(2.2.2, P26)"></a>交叉验证法(2.2.2, P26)</h3><p>“交叉验证法”(cross validation)先将数据集D划分为k个大小相似的互斥子集，即$D=D_1\cup D_2 \cup \cdots\cup D_k,D_i \cap D_j =\oslash (i\neq j)$</p><p>每次用k-1个子集作为训练集，余下的那个子集作为测试集；这样就可以得到k组训练/测试集。从而可进行k次训练和测试，最终返回k次测试结果的均值。</p><p>故通常把交叉验证法称为“k折交叉验证”(k-fold cross validation)。<br>10折交叉验证示意图：</p><p><img src="http://ww1.sinaimg.cn/large/c38a0784ly1fn3il11kesj20d706bdgd.jpg" alt="10折交叉验证示意图"></p><p>与留出法类似，将数据集D划分为K个子集的过程具有随机性，因此K折交叉验证通常也要重复p次，称为<strong>p次k折交叉验证</strong>，常见的是10次10折交叉验证，即进行了100次训练/测试。特殊地当划分的k个子集的每个子集中只有一个样本时，称为“留一法”，显然，留一法的评估结果比较准确，但对计算机的消耗也是巨大的。</p><h3 id="自助法-2-2-3-P27"><a href="#自助法-2-2-3-P27" class="headerlink" title="自助法(2.2.3, P27)"></a>自助法(2.2.3, P27)</h3><p>“自助法”(bootstrapping)以自助采样法(bootstrapping sampling)为基础。<br>每次随机从包含m个样本的数据集D中挑选一个样本，将其拷贝到$D’$，然后再将该样本放回D中，使得该样本下次采样时仍有可能被采到。<br>重复执行m次后，就得到包含m个样本的数据集$D’$。</p><p>我们将$D’$用作训练集，$D-D’$(D中除了$D’$以外的样本)用作测试集。</p><p>在m次采样中，样本始终不被采到的概率取极限为：<br><img src="http://ww1.sinaimg.cn/large/c38a0784ly1fn3iphjqzuj206w01fdfm.jpg" alt=""></p><p>自助法在数据集较小、难以有效划分训练/测试集时很有用。</p><h3 id="调参与最终模型-2-2-4-P28"><a href="#调参与最终模型-2-2-4-P28" class="headerlink" title="调参与最终模型(2.2.4, P28)"></a>调参与最终模型(2.2.4, P28)</h3><p>大多数学习算法都有些参数(parameter) 需要设定，参数配置不同，学得模型的性能往往有显著差别，这就是通常所说的”参数调节”或简称”调参” (parameter tuning)。</p><p>当选定好模型和调参完成后，我们需要使用初始的数据集D重新训练模型，即让最初划分出来用于评估的测试集也被模型学习，增强模型的学习效果。</p><p>学得模型(训练后的模型)实际使用中遇到的数据称为测试数据，在模型评估选择中用于评估测试的数据集称为“验证集”(calidation set)。【和吴恩达讲得差不多(略有区别？)。吴恩达说，通常将数据分为三类：训练集，验证集与测试集。】</p><h2 id="性能度量performance-measure-2-3-P28"><a href="#性能度量performance-measure-2-3-P28" class="headerlink" title="性能度量performance measure(2.3, P28)"></a>性能度量performance measure(2.3, P28)</h2><p>分类和回归属于监督学习。</p><ul><li><p>【分类】：对是离散值的结果进行预测。</p></li><li><p>【回归】：对是连续值的结果进行预测。</p></li></ul><p>回归任务和分类任务的常用性能度量如下图所示。</p><p><img src="http://ww1.sinaimg.cn/large/c38a0784ly1fn3mv5tkf5j20dw04zq3a.jpg" alt=""></p><p><del>预测任务：学习器预测结果$f(x)$与真实标记$y$进行比较。</del></p><p>回归任务：“均方误差”(mean squared error)<br>$$E(f;D) = \frac 1m \sum_{i=1}^m (f(x_i)-y_i)^2 $$</p><p>下面将依次介绍上图中分类任务的四类性能度量。</p><h3 id="错误率与精度-2-3-1-P29"><a href="#错误率与精度-2-3-1-P29" class="headerlink" title="错误率与精度(2.3.1, P29)"></a>错误率与精度(2.3.1, P29)</h3><p>错误率：分类错误的样本占样本总数的比例：<br>$$E(f;D) = \frac 1m \sum_{i=1}^m |(f(x_i)\neq y_i) $$<br>精度：分类正确的样本占样本总数的比例：<br>$$acc(f;D) = \frac 1m \sum_{i=1}^m |(f(x_i)= y_i) = 1-E(f;D)  $$</p><p>错误率+精度=1。</p><h3 id="查准率、查全率与F1-2-3-2-P30"><a href="#查准率、查全率与F1-2-3-2-P30" class="headerlink" title="查准率、查全率与F1(2.3.2, P30)"></a>查准率、查全率与F1(2.3.2, P30)</h3><p><img src="http://ww1.sinaimg.cn/large/c38a0784ly1fn3j33r8v2j20c006v74f.jpg" alt=""></p><p>查准率就是准确率，查全率就是召回率。</p><p>更具体的，可参考我的这篇文章：<a href="http://wangwlj.com/2017/10/08/DL_Precision_and_Recall/">准确率、召回率与F1值</a><br>【重点，单独列出】</p><h3 id="ROC-与AUC-2-3-3-P33"><a href="#ROC-与AUC-2-3-3-P33" class="headerlink" title="ROC 与AUC(2.3.3, P33)"></a>ROC 与AUC(2.3.3, P33)</h3><p><strong>ROC：受试者工作特性(Receiver Operating Characteristic)。</strong><br><img src="http://ww1.sinaimg.cn/large/c38a0784ly1fn4csetqxzj20k009l0t5.jpg" alt=""><br>ROC图的纵坐标为“真正例率”，横坐标为“假正例率”。</p><blockquote><p>真正例率（TPR）：【真正例样本数】与【真实情况是正例的样本数】的比值。（查全率）</p><p>假正例率（FPR）：【假正例样本数】与【真实情况是反例的样本数】的比值。</p></blockquote><p>如图，理想模型是真正例率为100%，假正例率为0%的一点。随机猜测模型则是真正例率与假正例率持平的直线。由此可知，在随机猜测模型左上方的曲线和在其右下方的曲线都代表了什么。（右下方的模型，还不如随机猜测准。）</p><p>现实中通常是有限个测试样例来绘制ROC图。无法产生光滑的ROC曲线图。</p><p>同样地，进行模型的性能比较时，若一个学习器A的ROC曲线被另一个学习器B的ROC曲线完全包住，则称B的性能优于A。若A和B的曲线发生了交叉，则不太好判断。此时，AUC应运而生。</p><p>AUC(Area Under ROC Curve)：判断两个ROC曲线的性能，AUC计算的是ROC曲线下的面积。面积越大，性能越好。</p><h3 id="代价敏感错误率与代价曲线-2-3-4-P35"><a href="#代价敏感错误率与代价曲线-2-3-4-P35" class="headerlink" title="代价敏感错误率与代价曲线(2.3.4, P35)"></a>代价敏感错误率与代价曲线(2.3.4, P35)</h3><p>上面的方法中，将学习器的犯错同等对待，但在现实生活中，将正例预测成假例与将假例预测成正例的代价常常是不一样的，例如：将无疾病–&gt;有疾病只是增多了检查，但有疾病–&gt;无疾病却是增加了生命危险。以二分类为例，由此引入了“代价矩阵”（cost matrix）。</p><p><img src="http://ww1.sinaimg.cn/large/c38a0784ly1fn4d0hvlu2j20ak06w0sq.jpg" alt="二分类代价矩阵"></p><p>在非均等错误代价下，我们希望的是最小化“总体代价”，这样“代价敏感”(cost sensitive)的错误率为：<br><img src="http://ww1.sinaimg.cn/large/c38a0784ly1fn3ji8c6pjj20jh02baa9.jpg" alt=""></p><p>同样对于ROC曲线，在非均等错误代价下，性能度量的方法演变成了<strong>“代价曲线”</strong>，代价曲线横轴是取值在[0,1]之间的正例概率代价，式中p表示正例的概率，纵轴是取值为[0,1]的归一化代价。</p><p><img src="http://ww1.sinaimg.cn/large/c38a0784ly1fn3lfih9eaj20cs0260sl.jpg" alt=""></p><p><img src="http://ww1.sinaimg.cn/large/c38a0784ly1fn3m2chlkwj20fo028glj.jpg" alt=""><br>代价曲线的绘制：设ROC曲线上一点的坐标为(TPR，FPR) ，则可相应计算出FNR，然后在代价平面上绘制一条从(0，FPR) 到(1，FNR) 的线段，线段下的面积即表示了该条件下的期望总体代价；如此将ROC曲线上的每个点转化为代价平面上的一条线段，然后取<strong>所有线段的下界</strong>，围成的面积即为在所有条件下学习器的期望总体代价，如图所示：</p><p><img src="http://ww1.sinaimg.cn/large/c38a0784ly1fn3jugpwecj20fc09jaak.jpg" alt="代价曲线"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>周志华《机器学习》</li><li><a href="http://blog.csdn.net/u011826404/article/details/53229609" target="_blank" rel="external">http://blog.csdn.net/u011826404/article/details/53229609</a></li><li><a href="https://zhuanlan.zhihu.com/p/28482121" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/28482121</a></li></ul>]]></content:encoded>
      
      <comments>http://wangwlj.com/2018/01/03/ML_chap2_01/#disqus_thread</comments>
    </item>
    
    <item>
      <title>windows下的部分小技巧整理</title>
      <link>http://wangwlj.com/2017/12/29/practical_tricks/</link>
      <guid>http://wangwlj.com/2017/12/29/practical_tricks/</guid>
      <pubDate>Fri, 29 Dec 2017 05:33:25 GMT</pubDate>
      <description>
      
        &lt;p&gt;本文主要是电脑使用中的一些小技巧的整理。&lt;br&gt;主要包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;电脑常用的部分快捷键&lt;/li&gt;
&lt;li&gt;批处理乱码问题&lt;/li&gt;
&lt;li&gt;Photoshop文字添加、删除与旋转&lt;/li&gt;
&lt;li&gt;VMbox虚拟机问题&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<p>本文主要是电脑使用中的一些小技巧的整理。<br>主要包括：</p><ul><li>电脑常用的部分快捷键</li><li>批处理乱码问题</li><li>Photoshop文字添加、删除与旋转</li><li>VMbox虚拟机问题</li></ul><a id="more"></a><h1 id="电脑操作"><a href="#电脑操作" class="headerlink" title="电脑操作"></a>电脑操作</h1><h2 id="打开“我的电脑”的快捷键"><a href="#打开“我的电脑”的快捷键" class="headerlink" title="打开“我的电脑”的快捷键"></a>打开“我的电脑”的快捷键</h2><p><code>winkey +E</code> :<br>打开我的电脑（资源管理器）。winkey指的是键盘上刻有windows徽标的键，就是左边ctrl 和alt中间那个(window标志)。</p><p>其他常用键组合：</p><p><code>winkey + d</code> :<br>这是高手最常用的第一快捷组合键。这个快捷键组合可以将桌面上的所有<strong>窗口瞬间最小化</strong>，无论是聊天的窗口还是游戏的窗口……只要<strong>再次按下这个组合键，刚才的所有窗口都回来了</strong>，而且激活的也正是你最小化之前在使用的窗口！ </p><p><code>winkey + r</code> :<br>在我们的文章中，你经常会看到这样的操作提示:“点击‘开始→运行’，打开‘运行’对话框……”。其实，还有一个更简单的办法，就是按winkey + r！ </p><p><code>alt + tab</code> 或者 <code>winkey + tab</code>:<br>如果打开的窗口太多，这个组合键就非常有用了，它可以在<strong>一个窗口中显示当前打开的所有窗口的名称和图标</strong>，选中自己希望要打开的窗口，松开这个组合键就可以了。而alt+tab+shift键则可以反向显示当前打开的窗口。 </p><p><code>ALT + F4</code> ：<br>关闭当前应用程序 </p><p><code>PRINT SCREEN</code> :<br>将当前屏幕以图象方式拷贝到剪贴板 </p><p>更多快捷键可参考：<a href="https://zhidao.baidu.com/question/100107981.html" target="_blank" rel="external">https://zhidao.baidu.com/question/100107981.html</a></p><h2 id="复制一个当前文件夹窗口的快捷键"><a href="#复制一个当前文件夹窗口的快捷键" class="headerlink" title="复制一个当前文件夹窗口的快捷键"></a>复制一个当前文件夹窗口的快捷键</h2><p><code>Ctrl + N</code></p><h2 id="批量查看照片尺寸"><a href="#批量查看照片尺寸" class="headerlink" title="批量查看照片尺寸"></a>批量查看照片尺寸</h2><p>在空白的地方右击，选择<strong>查看——详细信息</strong>;</p><p>照片就以列表的形式摆放了，但没有尺寸大小的信息~</p><p>再次在空白处右击，选择<strong>排列方式——更多</strong>，</p><p>将滑块往下滑动，<strong>找到尺寸，打上勾</strong>，按确定~</p><p>照片的尺寸信息就出现了~</p><p>若没有理解清楚，详细图文教程可参考：<a href="https://jingyan.baidu.com/article/67508eb4d4d3ff9ccb1ce459.html" target="_blank" rel="external">如何批量查看照片的尺寸</a></p><h2 id="awesomiumProcess是什么进程"><a href="#awesomiumProcess是什么进程" class="headerlink" title="awesomiumProcess是什么进程"></a>awesomiumProcess是什么进程</h2><p>在Windows任务管理器中的相应进程上右键–打开文件位置，发现是MarkDownPad2自带的程序。</p><p>推广一下，就是手动查看进程中是否存在可疑程序。。。</p><h1 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h1><h2 id="批处理脚本bat中文乱码"><a href="#批处理脚本bat中文乱码" class="headerlink" title="批处理脚本bat中文乱码"></a>批处理脚本bat中文乱码</h2><p>面对这个情况是编码不同问题，所以在最开始就应该把编码修正，支持中文的编码是<code>ANSI</code>。</p><p>我们第一步是<strong>新建一个txt文件</strong>。用记事本打开，将原来的bat文件内容拷贝过来，然后选择“<strong>文件”=&gt;“另存为”</strong>。</p><p>cmd中的编码方式为ANSI，若中文不是此编码方式则会出现乱码。所以我们<strong>在编码的时候选择“ANSI”</strong>。</p><h1 id="photoshop"><a href="#photoshop" class="headerlink" title="photoshop"></a>photoshop</h1><h2 id="ps修改图片上的文字"><a href="#ps修改图片上的文字" class="headerlink" title="ps修改图片上的文字"></a>ps修改图片上的文字</h2><h3 id="删去文字"><a href="#删去文字" class="headerlink" title="删去文字"></a>删去文字</h3><p>先选择图层，再选择一个区域后，按delete删除。</p><p>取消当前图层的选区： <code>ctrl + D</code><br>参考自：<a href="https://jingyan.baidu.com/article/456c463b6e5e3a0a5831440e.html" target="_blank" rel="external">ps取消选区快捷键</a></p><h3 id="添加横的文字"><a href="#添加横的文字" class="headerlink" title="添加横的文字"></a>添加横的文字</h3><p>选择添加文本的按钮输入文字，但是不可以旋转（我要变成竖直的文字）。</p><p>按组合键<code>Ctrl + T</code>或者点击编辑菜单下的【自由变换】，进入文字调整。<br>具体参考：<a href="https://zhidao.baidu.com/question/227531179.html" target="_blank" rel="external">ps怎么旋转一个字体</a></p><h1 id="vbox虚拟机"><a href="#vbox虚拟机" class="headerlink" title="vbox虚拟机"></a>vbox虚拟机</h1><h2 id="无法启动E-FAIL-0x80004005"><a href="#无法启动E-FAIL-0x80004005" class="headerlink" title="无法启动E_FAIL (0x80004005)"></a>无法启动E_FAIL (0x80004005)</h2><p>版本问题。回退到4.3.12之前。新版本问题多多。<br>具体参考：<a href="https://bbs.kafan.cn/thread-1798795-1-1.html" target="_blank" rel="external">Oracle VM VirtualBox 虚拟机 启动报错代码:E_FAIL (0x80004005)</a></p><h2 id="VirtualBox显示模式切换热键"><a href="#VirtualBox显示模式切换热键" class="headerlink" title="VirtualBox显示模式切换热键"></a>VirtualBox显示模式切换热键</h2><p>初用VirtualBox, 几个显示切换快捷键还是要记一下的:</p><p>Right Ctrl + F        – 切换到全屏模式<br>Right Ctrl + L        – 切换到无缝模式<br>Right Ctrl + C        – 切换到比例模式<br>Right Ctrl + Home – 显示控制菜单</p><h2 id="无缝模式是灰色的，怎么办"><a href="#无缝模式是灰色的，怎么办" class="headerlink" title="无缝模式是灰色的，怎么办"></a>无缝模式是灰色的，怎么办</h2><p>安装增强模式。相当于VMware里面的”VMware Tools”。</p>]]></content:encoded>
      
      <comments>http://wangwlj.com/2017/12/29/practical_tricks/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Python中的部分tricks整理</title>
      <link>http://wangwlj.com/2017/12/29/python_tricks/</link>
      <guid>http://wangwlj.com/2017/12/29/python_tricks/</guid>
      <pubDate>Fri, 29 Dec 2017 03:38:07 GMT</pubDate>
      <description>
      
        &lt;p&gt;本文整理了本人遇到的一些tricks。主要包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pycharm快捷键整理&lt;/li&gt;
&lt;li&gt;爬虫中的日志记录(logging)、取消SSL警告、字符过滤(re.sub)与查找(find)、文件删除(os)与文件保存(pickle)、词云(wordcloud)的使用&lt;/li&gt;
&lt;li&gt;图像处理的部分基本操作(PIL,numpy)。&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<p>本文整理了本人遇到的一些tricks。主要包括：</p><ul><li>pycharm快捷键整理</li><li>爬虫中的日志记录(logging)、取消SSL警告、字符过滤(re.sub)与查找(find)、文件删除(os)与文件保存(pickle)、词云(wordcloud)的使用</li><li>图像处理的部分基本操作(PIL,numpy)。</li></ul><a id="more"></a><h2 id="0-pycharm-快捷键"><a href="#0-pycharm-快捷键" class="headerlink" title="0 pycharm 快捷键"></a>0 pycharm 快捷键</h2><h3 id="注释-反注释"><a href="#注释-反注释" class="headerlink" title="注释/反注释"></a>注释/反注释</h3><p> <code>Ctrl+斜杠</code>，也就是 <code>Ctrl + /</code> 注释与反注释都是这个组合键。</p><h3 id="块注释"><a href="#块注释" class="headerlink" title="块注释"></a>块注释</h3><p><code>Ctrl+Shift+斜杠</code></p><h3 id="格式化代码"><a href="#格式化代码" class="headerlink" title="格式化代码"></a>格式化代码</h3><p><code>ctrl + alt + F</code>: 格式化代码(用了JetBrains的IDE之后就习惯性地格式化一下)，代码规范化。</p><h3 id="复制当前行"><a href="#复制当前行" class="headerlink" title="复制当前行"></a>复制当前行</h3><p><code>Ctrl + D</code>复制当前行</p><h3 id="另起一行"><a href="#另起一行" class="headerlink" title="另起一行"></a>另起一行</h3><p><code>shift + enter</code> : 向下另起一行，光标在行内任意位置都能另起一行，且不破坏当行结构<br><code>ctrl + alt + enter</code> : 向上另起一行</p><h3 id="查看注释"><a href="#查看注释" class="headerlink" title="查看注释"></a>查看注释</h3><p><code>Ctrl + q</code>: help 查注释，查询documentation</p><h3 id="搜索功能"><a href="#搜索功能" class="headerlink" title="搜索功能"></a>搜索功能</h3><p><code>ctrl + shift + a</code> : 搜索功能: 搜索IDE功能，比如想看看这个文件的历史，就键入history 可以找到 Local history</p><h3 id="万能提示键"><a href="#万能提示键" class="headerlink" title="万能提示键"></a>万能提示键</h3><p><code>ctrl + alt + space</code>: 万能提示键(在Keymap中搜索basic可以找到并修改它)PyCharm的会根据上下文提供补全。</p><h3 id="run相关的快捷键"><a href="#run相关的快捷键" class="headerlink" title="run相关的快捷键"></a>run相关的快捷键</h3><p>根据具体设置可能略有差异，笔者采用的是<br>VS风格（可在<code>File-&gt;Settings-&gt;Keymap</code>中设置）的快捷键。<br><code>ctrl + F9</code> : run the current file （跑当前页面的程序）<br><code>F9</code> :　resume the program (中断后)重新开始程序<br><code>ctrl + F5</code>: run the specific program(直接跑上一个程序)<br><code>F5</code>： debug（弹出debug目录，自行选择运行的文件）<br><code>alt + shift + F10</code> : 运行程序（弹出run目录）</p><h3 id="其他技巧"><a href="#其他技巧" class="headerlink" title="其他技巧"></a>其他技巧</h3><p><code>ctrl + shift + 数字键</code> 与 <code>ctrl + 数字键</code> : 书签功能<br><code>Ctrl + 鼠标点击</code>  ： 查看内置函数啥的<br><code>alt + 上下箭头</code> : <code>preview/next method (def/class)</code><br>debug的时候可以在断点打开Python console然后改变量值<br><code>Ctrl+ B</code>和<code>shift + →</code>，查看源码时很方便，至少在vim下看库的源码没那么容易。对Python程序员而言，看源码很重要<br><code>shift + F6</code> : 重命名，这太重要了，vim没有吧。即使有，那它也没法重构Flask和Django的template下的指令吧。</p><h2 id="1-python信息同时输出到控制台与文件"><a href="#1-python信息同时输出到控制台与文件" class="headerlink" title="1 python信息同时输出到控制台与文件"></a>1 python信息同时输出到控制台与文件</h2><h3 id="1-1-问题"><a href="#1-1-问题" class="headerlink" title="1.1 问题"></a>1.1 问题</h3><p>python编程中，往往需要将结果用print等输出，如果希望输出既可以显示到IDE的屏幕上，也能存到文件中（如txt）中，该怎么办呢？</p><h3 id="1-2-解决方案"><a href="#1-2-解决方案" class="headerlink" title="1.2 解决方案"></a>1.2 解决方案</h3><p>可通过日志<code>logging</code>模块输出信息到文件或屏幕。但可能要设置log的level或输出端，对于同时需要记录<code>debug error</code>等信息的较为合适，官方教程推荐学习用更规范的logger来操作。<br>例如,可参考来自官网的这段代码。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> logging</div><div class="line">logging.basicConfig(filename=<span class="string">'log_examp.log'</span>,level=logging.DEBUG)</div><div class="line">logging.debug(<span class="string">'This message should go to the log file'</span>)</div><div class="line">logging.info(<span class="string">'So should this'</span>)</div><div class="line">logging.warning(<span class="string">'And this, too'</span>)</div></pre></td></tr></table></figure></p><p>其中的<code>level=logging.DEBUG</code>会显示Debug调试信息，若想显示普通的输出信息，可以换成<code>level=logging.INFO</code>。</p><table class="table table-bordered table-striped table-condensed"><br>    <tr><br>        <th>程度</th><br>        <th>使用场景</th><br>    </tr><br>    <tr><br>        <td>DEBUG</td><br>        <td>获得诊断问题是具体的信息</td><br>    </tr><br>    <tr><br>        <td>INFO</td><br>        <td>确认程序是否按正常工作</td><br>    </tr><br>    <tr><br>        <td>WARNING</td><br>        <td>在程序还正常运行时获取发生的意外的信息，这可能会在之后引发异常（例如磁盘空间不足）</td><br>    </tr><br>    <tr><br>        <td>ERROR</td><br>        <td>获取程序某些功能无法正常调用这类严重异常的信息</td><br>    </tr><br>    <tr><br>        <td>CRITICAL</td><br>        <td>获取程序无法继续运行的这类最严重异常信息</td><br>    </tr><br></table> <h3 id="1-3-改变默认输出信息的格式"><a href="#1-3-改变默认输出信息的格式" class="headerlink" title="1.3 改变默认输出信息的格式"></a>1.3 改变默认输出信息的格式</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> logging</div><div class="line"><span class="comment"># output format: output time - logging level - log messages</span></div><div class="line">logging.basicConfig(format=<span class="string">'%(asctime)s - %(levelname)s - %(message)s'</span>)</div><div class="line">logging.warning(<span class="string">'This message will appear in python console.'</span>)</div></pre></td></tr></table></figure><p>在<code>python console</code>中直接打印以下输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">2016-8-2 2:59:11, 510 - WARNING - This message will appear in python console</div></pre></td></tr></table></figure><h2 id="2-Python中将打印输出导向日志文件"><a href="#2-Python中将打印输出导向日志文件" class="headerlink" title="2 Python中将打印输出导向日志文件"></a>2 Python中将打印输出导向日志文件</h2><p>利用<code>sys.stdout</code>将print行导向到你定义的日志文件中，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"></div><div class="line"><span class="comment"># make a copy of original stdout route</span></div><div class="line">stdout_backup = sys.stdout</div><div class="line"><span class="comment"># define the log file that receives your log info</span></div><div class="line">log_file = open(<span class="string">"message.log"</span>, <span class="string">"w"</span>)</div><div class="line"><span class="comment"># redirect print output to log file</span></div><div class="line">sys.stdout = log_file</div><div class="line"></div><div class="line"><span class="keyword">print</span> <span class="string">"Now all print info will be written to message.log"</span></div><div class="line"><span class="comment"># any command line that you will execute</span></div><div class="line">...</div><div class="line"></div><div class="line">log_file.close()</div><div class="line"><span class="comment"># restore the output to initial pattern</span></div><div class="line">sys.stdout = stdout_backup</div><div class="line"></div><div class="line"><span class="keyword">print</span> <span class="string">"Now this will be presented on screen"</span></div></pre></td></tr></table></figure><p>这样子只会打印到日志文件，而控制台没有输出了，笔者一般不采用这种方法。</p><h2 id="3-python3使用requests请求HTTPS取消SSL验证警告"><a href="#3-python3使用requests请求HTTPS取消SSL验证警告" class="headerlink" title="3 python3使用requests请求HTTPS取消SSL验证警告"></a>3 python3使用requests请求HTTPS取消SSL验证警告</h2><h3 id="3-1-问题描述"><a href="#3-1-问题描述" class="headerlink" title="3.1 问题描述"></a>3.1 问题描述</h3><p>使用<code>requests</code>库请求<code>HTTPS</code>时,因为忽略证书验证,导致每次运行时都会报错（警告）:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">D:\python\Python35\lib\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings</div><div class="line"> InsecureRequestWarning)</div></pre></td></tr></table></figure></p><h3 id="3-2-解决方法"><a href="#3-2-解决方法" class="headerlink" title="3.2 解决方法"></a>3.2 解决方法</h3><blockquote><p>虽然这并不影响结果的正确，但是这个提示一直存在，看着是真的别扭，尤其需要输出到报告或者是日志的时候。代码加入下面两行，取消这个警告。</p></blockquote><p>添加如下的这两行代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> requests.packages.urllib3.exceptions <span class="keyword">import</span> InsecureRequestWarning </div><div class="line"></div><div class="line">requests.packages.urllib3.disable_warnings(InsecureRequestWarning)</div></pre></td></tr></table></figure><blockquote><p>python3也可以的。我的pycharm中会显示找不到该库，不过没问题，依旧可以跑，应该是pycharm本身的问题。</p></blockquote><h2 id="4-python过滤中文、英文标点特殊符号"><a href="#4-python过滤中文、英文标点特殊符号" class="headerlink" title="4. python过滤中文、英文标点特殊符号"></a>4. python过滤中文、英文标点特殊符号</h2><h3 id="4-1-垃圾邮件过滤实例"><a href="#4-1-垃圾邮件过滤实例" class="headerlink" title="4.1 垃圾邮件过滤实例"></a>4.1 垃圾邮件过滤实例</h3><p>下面是一封垃圾邮件的过滤实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&quot;想做/ 兼_职/学生_/ 的 、加,我Q：  1 5.  8 0. ！！？？  8 6 。0.  2。 3     有,惊,喜,哦&quot;</div></pre></td></tr></table></figure><p>邮件中的“<code>！？。、</code>”都是中文的，而“/.”是英文的</p><p>下面是采用re正则项过滤方式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> re</div><div class="line"></div><div class="line">temp = <span class="string">"想做/ 兼_职/学生_/ 的 、加,我Q：  1 5.  8 0. ！！？？  8 6 。0.  2。 3     有,惊,喜,哦"</span></div><div class="line">temp = temp.decode(<span class="string">"utf8"</span>) </div><div class="line">string = re.sub(<span class="string">"[\s+\.\!\/_,$%^*(+\"\']+|[+——！，。？、~@#￥%……&amp;*（）]+"</span>, <span class="string">""</span>, temp) <span class="comment"># 将temp中若存在的前面的这一长串替换为空的。</span></div><div class="line">print(string)</div></pre></td></tr></table></figure><h3 id="4-2-目录名称过滤实例"><a href="#4-2-目录名称过滤实例" class="headerlink" title="4.2 目录名称过滤实例"></a>4.2 目录名称过滤实例</h3><p>此外，比如说目录命名时，也需要过滤掉<code>/|</code>等，如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">dirName = re.sub(<span class="string">"[\s+\.\!\/_,$%^*(+\"\'?]+|[+——！，。？、~@#￥%……&amp;*（）]+"</span>, <span class="string">""</span>, dirName)</div><div class="line">os.mkdir(dirName)</div></pre></td></tr></table></figure></p><h2 id="5-Markdown之表格table的处理"><a href="#5-Markdown之表格table的处理" class="headerlink" title="5. Markdown之表格table的处理"></a>5. Markdown之表格table的处理</h2><p>插入表格代码如下：<br><figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">table</span> <span class="attr">class</span>=<span class="string">"table table-bordered table-striped table-condensed"</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">tr</span>&gt;</span>  </div><div class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>北京<span class="tag">&lt;/<span class="name">td</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">td</span>&gt;</span>雾霾<span class="tag">&lt;/<span class="name">td</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">tr</span>&gt;</span>  </div><div class="line">        <span class="tag">&lt;<span class="name">td</span>&gt;</span>深圳<span class="tag">&lt;/<span class="name">td</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;<span class="name">td</span>&gt;</span>暴雨<span class="tag">&lt;/<span class="name">td</span>&gt;</span>  </div><div class="line">    <span class="tag">&lt;/<span class="name">tr</span>&gt;</span>  </div><div class="line"><span class="tag">&lt;/<span class="name">table</span>&gt;</span></div></pre></td></tr></table></figure></p><p>发现table加了个class属性，如果只是table标签 将不起作用。</p><pre><code>table-bordered：带圆角边框和竖线table-striped：奇偶行颜色不同table-condensed：压缩行距</code></pre><p>除了以上另外还有其他可供选择：</p><p>1、如果需要表头跟内容不一样，可以将<code>&lt;td&gt;</code>表头内容<code>&lt;/td&gt;</code>换成<code>&lt;th&gt;</code>表头内容<code>&lt;/th&gt;</code>。</p><p>2、如果表格内文需要换行，可以在要换行的内容后加入<code>&lt;br&gt;</code>，后面的内容就会跑到下一行。</p><p>3、如果内文中有代码，需要特别显示，可使用：<code>&lt;code&gt;代码&lt;/code&gt;</code>。</p><p>4、如果表格中有需要设为斜体的内容，可使用：<code>&lt;I&gt;要设为斜体的内容&lt;/I&gt;</code>。</p><p>5、如果有跨行或者跨列的单元格，可用<code>&lt;th colspan=&quot;跨列数&quot;&gt;内容&lt;/th&gt;</code>或<code>rowspan</code>。</p><p>6、如果要调整某一列的宽度，可使用：<code>&lt;th width=&quot;宽度值或百分比&quot;&gt;表头内容&lt;/th&gt;</code>。</p><h2 id="6-用numpy打开图像和保存图像"><a href="#6-用numpy打开图像和保存图像" class="headerlink" title="6. 用numpy打开图像和保存图像"></a>6. 用numpy打开图像和保存图像</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: utf-8 -*-    </span></div><div class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image    </div><div class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> *    </div><div class="line"><span class="keyword">from</span> PCV.tools <span class="keyword">import</span> imtools    </div><div class="line"><span class="keyword">import</span> numpy  </div><div class="line"></div><div class="line">im = array(Image.open(<span class="string">'C:/pic/train2/1.jpg'</span>).convert(<span class="string">'L'</span>))  <span class="comment"># 打开图像，并转成灰度图像    </span></div><div class="line">img11=Image.fromarray(uint8(im))  </div><div class="line">img11.save(<span class="string">"C:/pic/train2/10.jpg"</span>)<span class="comment"># 保存灰度图像</span></div></pre></td></tr></table></figure><p>补充用opencv打开和保存图像：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#coding=utf-8    </span></div><div class="line"><span class="keyword">import</span> cv2    </div><div class="line"></div><div class="line">img = cv2.imread(<span class="string">"C:/pic/train1/2.jpg"</span>, <span class="number">0</span>)     </div><div class="line">cv2.imwrite(<span class="string">'C:/pic/1/5.jpg'</span>,img)</div></pre></td></tr></table></figure><h2 id="7-PIL-Image转换为OpenCV支持的Image格式"><a href="#7-PIL-Image转换为OpenCV支持的Image格式" class="headerlink" title="7. PIL.Image转换为OpenCV支持的Image格式"></a>7. PIL.Image转换为OpenCV支持的Image格式</h2><p>可参考：<a href="http://www.mobibrw.com/2017/7381" target="_blank" rel="external">http://www.mobibrw.com/2017/7381</a></p><p>后来放弃了。不太方便。</p><h2 id="8-使用pickle把数据保存到文件"><a href="#8-使用pickle把数据保存到文件" class="headerlink" title="8. 使用pickle把数据保存到文件"></a>8. 使用pickle把数据保存到文件</h2><h3 id="8-1-实例一"><a href="#8-1-实例一" class="headerlink" title="8.1 实例一"></a>8.1 实例一</h3><p>使用pickle模块从文件中重构python对象。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pprint, pickle</div><div class="line"></div><div class="line">pkl_file = open(<span class="string">'data.pkl'</span>, <span class="string">'rb'</span>)</div><div class="line"></div><div class="line">data1 = pickle.load(pkl_file)</div><div class="line">pprint.pprint(data1)</div><div class="line"></div><div class="line">data2 = pickle.load(pkl_file)</div><div class="line">pprint.pprint(data2)</div><div class="line"></div><div class="line">pkl_file.close()</div></pre></td></tr></table></figure></p><h3 id="8-2-实例二"><a href="#8-2-实例二" class="headerlink" title="8.2 实例二"></a>8.2 实例二</h3><p>其中，friend是从网页获得的数据，先保存下来，以备后续处理。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 获取好友列表</span></div><div class="line">friends = itchat.get_friends(update=<span class="keyword">True</span>)[<span class="number">0</span>:]</div><div class="line"></div><div class="line">output = open(<span class="string">'data.pkl'</span>, <span class="string">'wb'</span>)</div><div class="line"><span class="comment"># Pickle dictionary using protocol 0.</span></div><div class="line">pickle.dump(friends, output)</div><div class="line">output.close()</div></pre></td></tr></table></figure></p><p>读取保存的文件，用于后续处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pickle, re</div><div class="line"></div><div class="line">pkl_file = open(<span class="string">'data.pkl'</span>, <span class="string">'rb'</span>)</div><div class="line">friends = pickle.load(pkl_file)</div></pre></td></tr></table></figure><h2 id="9-解决Python词云库wordcloud不显示中文的问题"><a href="#9-解决Python词云库wordcloud不显示中文的问题" class="headerlink" title="9. 解决Python词云库wordcloud不显示中文的问题"></a>9. 解决Python词云库wordcloud不显示中文的问题</h2><h3 id="9-1-安装"><a href="#9-1-安装" class="headerlink" title="9.1 安装"></a>9.1 安装</h3><p>安装命令：</p><blockquote><p>pip install wordcloud</p></blockquote><h3 id="9-2-解决方案"><a href="#9-2-解决方案" class="headerlink" title="9.2 解决方案"></a>9.2 解决方案</h3><p>实例代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">text = <span class="string">'''文案 文案</span></div><div class="line"><span class="string">The  抱抱 Zen of LOVE 抱抱 Python, 快乐 by Tim Peters</span></div><div class="line"><span class="string">公众号 公众号 Python 最好的 语言 语言</span></div><div class="line"><span class="string">一辈子 is better LOVE than 一辈子.</span></div><div class="line"><span class="string">喵小姐 is 爱你 than  implicit.爱你 喵小姐</span></div><div class="line"><span class="string">蟹先生 is 爱你 than complex.</span></div><div class="line"><span class="string">一辈子 is 蟹先生  than complicated.</span></div><div class="line"><span class="string">二中 is 喵小姐 我想你了 than nested. 二中 蟹先生</span></div><div class="line"><span class="string">清湖 is 胜于 than 清湖.</span></div><div class="line"><span class="string">思旺 counts. 想你</span></div><div class="line"><span class="string">Special 喵小姐 我想你了 aren't special enough 思旺 break 思旺 rules.</span></div><div class="line"><span class="string">别生气 practicality beats 厨艺好.</span></div><div class="line"><span class="string">Errors should 我想你了 never pass 小龙虾 silently. 运营</span></div><div class="line"><span class="string">别生气 explicitly 好不好. LOVE</span></div><div class="line"><span class="string">In the face of ambiguity, 程序员 the 厨艺好 to guess.龙华 龙华</span></div><div class="line"><span class="string">There 快乐 should be one-- 我想你了 and preferably 红烧肉 only one 小龙虾--obvious way to do it.运营</span></div><div class="line"><span class="string">Although 共享单车 way may not 我想你了 be obvious at first unless you're Dutch. 新媒体 地铁</span></div><div class="line"><span class="string">Now is better 红烧肉 than never.</span></div><div class="line"><span class="string">程序员 Although 共享单车 is often 高铁 than 东莞 now. 高铁 地铁</span></div><div class="line"><span class="string">If the implementation 想你 is hard to explain, it's a bad idea. 想你了</span></div><div class="line"><span class="string">If 成都 implementation is 想你 easy to explain, it may be a good idea.</span></div><div class="line"><span class="string">Namespaces are 端午one 端午 honking great idea -- 成都 do more of those! 想你了</span></div><div class="line"><span class="string">深圳 晚安 深圳 新媒体</span></div><div class="line"><span class="string">'''</span></div><div class="line"></div><div class="line"><span class="comment"># the font from github: https://github.com/adobe-fonts</span></div><div class="line">font = <span class="string">r'C:\Windows\Fonts\simfang.ttf'</span></div><div class="line">wc = WordCloud(collocations=<span class="keyword">False</span>, font_path=font, width=<span class="number">1400</span>, height=<span class="number">1400</span>, margin=<span class="number">2</span>).generate(text.lower())</div><div class="line"></div><div class="line">plt.imshow(wc)</div><div class="line">plt.axis(<span class="string">"off"</span>)</div><div class="line">plt.show()</div><div class="line"></div><div class="line">wc.to_file(<span class="string">'show_Chinese.png'</span>)  <span class="comment"># 把词云保存下来</span></div></pre></td></tr></table></figure></p><h2 id="10-PIL库图片基本操作"><a href="#10-PIL库图片基本操作" class="headerlink" title="10. PIL库图片基本操作"></a>10. PIL库图片基本操作</h2><p>1.打开图片<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> Image</div><div class="line">img=Image.open(<span class="string">"code.jpg"</span>)</div></pre></td></tr></table></figure></p><p>注：有些图片名称是包含中文的，就需要在“”前加上u，例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">img=Image.open(<span class="string">u"阿布.jpg"</span>)</div></pre></td></tr></table></figure></p><p>2.展示图片</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">img.show()</div></pre></td></tr></table></figure><p>3.保存图片<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">img.save(<span class="string">"img1.png"</span>,<span class="string">"png"</span>)</div></pre></td></tr></table></figure></p><p>说明：img为一个图片，存为一个名叫img1的图片，格式为png。后面的png不写也可以，直接按照文件名的后缀.png存为相应格式了。</p><p>4.旋转图片rotate</p><pre><code>fixedIm=img.rotate(90)fixedIm.save(&quot;fixedIm.png&quot;,&quot;png&quot;)</code></pre><p>说明：<code>fixedIm=img.rotate(90)</code>，将图片img逆时针旋转90度，存到fixedIm中。</p><p>更多操作可参考:<br><a href="http://www.cnblogs.com/meitian/p/3699223.html" target="_blank" rel="external">http://www.cnblogs.com/meitian/p/3699223.html</a></p><h2 id="python删除文件"><a href="#python删除文件" class="headerlink" title="python删除文件"></a>python删除文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> os</div><div class="line">   <span class="comment"># 删除文件： </span></div><div class="line">os.remove()</div><div class="line"><span class="comment">#删除空目录： </span></div><div class="line">os.rmdir()</div><div class="line">   <span class="comment"># 递归删除空目录： </span></div><div class="line">os.removedirs()</div></pre></td></tr></table></figure><p>递归删除目录和文件（类似DOS命令DeleteTree）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Delete everything reachable from the directory named in 'top',</span></div><div class="line"><span class="comment"># assuming there are no symbolic links.</span></div><div class="line"><span class="comment"># CAUTION:  This is dangerous!  For example, if top == '/', it</span></div><div class="line"><span class="comment"># could delete all your disk files.</span></div><div class="line"><span class="keyword">import</span> os</div><div class="line"><span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(top, topdown=<span class="keyword">False</span>):</div><div class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> files:</div><div class="line">        os.remove(os.path.join(root, name))</div><div class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> dirs:</div><div class="line">        os.rmdir(os.path.join(root, name))</div></pre></td></tr></table></figure></p><p>参考自：<a href="http://www.cnblogs.com/SophiaTang/archive/2012/01/16/2323467.html" target="_blank" rel="external">python 删除文件</a></p><h2 id="Python3-find-方法"><a href="#Python3-find-方法" class="headerlink" title="Python3 find()方法"></a>Python3 find()方法</h2><h3 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h3><p><code>find()</code>方法检测字符串中是否包含子字符串str，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，如果指定范围内如果包含指定索引值，返回的是索引值在字符串中的起始位置。如果不包含索引值，返回-1。</p><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><p>find()方法语法：</p><blockquote><p>str.find(str, beg=0, end=len(string))</p></blockquote><h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><p>str：指定检索的字符串<br>beg：开始索引，默认为0。<br>end：结束索引，默认为字符串的长度。</p><h3 id="返回值"><a href="#返回值" class="headerlink" title="返回值"></a>返回值</h3><p>如果包含子字符串返回开始的索引值，否则返回-1。</p><h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p>以下实例展示了find()方法的实例(Python 3.0+)：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/python3</span></div><div class="line"> </div><div class="line">str1 = <span class="string">"Runoob example....wow!!!"</span></div><div class="line">str2 = <span class="string">"exam"</span>;</div><div class="line"> </div><div class="line"><span class="keyword">print</span> (str1.find(str2))</div><div class="line"><span class="keyword">print</span> (str1.find(str2, <span class="number">5</span>))</div><div class="line"><span class="keyword">print</span> (str1.find(str2, <span class="number">10</span>))</div></pre></td></tr></table></figure><p>以上实例输出结果如下：</p><blockquote><p>7</p><p>7</p><p>-1</p></blockquote><p>实例(Python 3.0+)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt;info = <span class="string">'abca'</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(info.find(<span class="string">'a'</span>))      <span class="comment"># 从下标0开始，查找在字符串里第一个出现的子串，返回结果：0</span></div><div class="line"><span class="number">0</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(info.find(<span class="string">'a'</span>, <span class="number">1</span>))   <span class="comment"># 从下标1开始，查找在字符串里第一个出现的子串：返回结果3</span></div><div class="line"><span class="number">3</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(info.find(<span class="string">'3'</span>))      <span class="comment"># 查找不到返回-1</span></div><div class="line"><span class="number">-1</span></div><div class="line">&gt;&gt;&gt;</div></pre></td></tr></table></figure></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://blog.csdn.net/woaik110/article/details/52444427" target="_blank" rel="external">python 信息同时输出到控制台与文件</a></li><li><a href="http://www.cnblogs.com/arkenstone/p/5727883.html" target="_blank" rel="external">Python中将打印输出导向日志文件</a></li><li><a href="http://blog.csdn.net/m1mory/article/details/56029638" target="_blank" rel="external">python requests报错InsecureRequestWarning的解决方案</a></li><li><a href="http://blog.csdn.net/xie_0723/article/details/53424809" target="_blank" rel="external">Python requests移除SSL认证，控制台输出InsecureRequestWarning取消方法</a></li><li><a href="http://blog.csdn.net/mach_learn/article/details/41744487" target="_blank" rel="external">python 过滤中文、英文标点特殊符号</a></li><li><a href="http://blog.csdn.net/itmyhome1990/article/details/44085539" target="_blank" rel="external">Markdown之表格table的处理</a></li><li><a href="http://blog.csdn.net/txiaomiao/article/details/50967223" target="_blank" rel="external">用numpy打开图像和保存图像</a></li><li><a href="http://www.cnblogs.com/pzxbc/archive/2012/03/18/2404715.html" target="_blank" rel="external">pickle模块的基本使用</a></li><li><a href="http://blog.csdn.net/xiemanr/article/details/72796739" target="_blank" rel="external">词云库wordcloud显示中文</a></li><li><a href="http://www.runoob.com/python3/python3-string-find.html" target="_blank" rel="external">Python3 find()方法</a></li></ul>]]></content:encoded>
      
      <comments>http://wangwlj.com/2017/12/29/python_tricks/#disqus_thread</comments>
    </item>
    
    <item>
      <title>TensorFlow基础篇与搭建深层神经网络</title>
      <link>http://wangwlj.com/2017/12/28/tensorflow_base/</link>
      <guid>http://wangwlj.com/2017/12/28/tensorflow_base/</guid>
      <pubDate>Thu, 28 Dec 2017 14:24:03 GMT</pubDate>
      <description>
      
        &lt;p&gt;本文是 Tensorflow：实战Google深度学习框架的第三章与第四章。&lt;br&gt;&lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<p>本文是 Tensorflow：实战Google深度学习框架的第三章与第四章。<br><a id="more"></a></p><h1 id="第3章-TensorFlow入门"><a href="#第3章-TensorFlow入门" class="headerlink" title="第3章 TensorFlow入门"></a>第3章 TensorFlow入门</h1><h2 id="0-1-查看已安装tensorflow版本"><a href="#0-1-查看已安装tensorflow版本" class="headerlink" title="0.1 查看已安装tensorflow版本"></a>0.1 查看已安装tensorflow版本</h2><p>由于tensorflow版本不同,可能一些函数的调用也有变换,这时候可能需要查看tensorflow版本,可以在终端输入查询命令如下:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">python //windows下cmd进入python环境，linux下终端类似</div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line">tf.__version__</div></pre></td></tr></table></figure></p><p>查询tensorflow安装路径为:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tf.__path__</div></pre></td></tr></table></figure></p><p>参考自：<a href="http://blog.csdn.net/u011961856/article/details/76861052" target="_blank" rel="external">查看已安装tensorflow版本</a></p><h2 id="0-2-Tensorflow：实战Google深度学习框架-源码下载"><a href="#0-2-Tensorflow：实战Google深度学习框架-源码下载" class="headerlink" title="0.2 Tensorflow：实战Google深度学习框架 源码下载"></a>0.2 Tensorflow：实战Google深度学习框架 源码下载</h2><ul><li><a href="http://www.broadview.com.cn/book/111" target="_blank" rel="external">Tensorflow：实战Google深度学习框架</a></li><li><a href="https://github.com/caicloud/tensorflow-tutorial/tree/master/Deep_Learning_with_TensorFlow" target="_blank" rel="external">caicloud/tensorflow-tutorial</a></li></ul><h2 id="3-2-TensorFlow数据模型——张量"><a href="#3-2-TensorFlow数据模型——张量" class="headerlink" title="3.2 TensorFlow数据模型——张量"></a>3.2 TensorFlow数据模型——张量</h2><h3 id="3-2-1-张量的概念"><a href="#3-2-1-张量的概念" class="headerlink" title="3.2.1 张量的概念"></a>3.2.1 张量的概念</h3><p>一个张量中主要保存了三个属性：名字（name）、维度（shape）、类型（type）。</p><h3 id="3-2-2-张量的使用"><a href="#3-2-2-张量的使用" class="headerlink" title="3.2.2 张量的使用"></a>3.2.2 张量的使用</h3><p>两大类。</p><p>一是对中间结果的引用。</p><p>二是用来获得计算的结果。tf.Session().run(result)</p><h2 id="3-3-TensorFlow运行模型——会话"><a href="#3-3-TensorFlow运行模型——会话" class="headerlink" title="3.3 TensorFlow运行模型——会话"></a>3.3 TensorFlow运行模型——会话</h2><h3 id="3-3-1-创建和关闭会话"><a href="#3-3-1-创建和关闭会话" class="headerlink" title="3.3.1 创建和关闭会话"></a>3.3.1 创建和关闭会话</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 创建一个会话。</span></div><div class="line">sess = tf.Session()</div><div class="line"></div><div class="line"><span class="comment"># 使用会话得到之前计算的结果。</span></div><div class="line">print(sess.run(result))</div><div class="line"></div><div class="line"><span class="comment"># 关闭会话使得本次运行中使用到的资源可以被释放。</span></div><div class="line">sess.close()</div></pre></td></tr></table></figure><h3 id="3-3-2-使用with-statement-来创建会话"><a href="#3-3-2-使用with-statement-来创建会话" class="headerlink" title="3.3.2 使用with statement 来创建会话"></a>3.3.2 使用with statement 来创建会话</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">   print(sess.run(result))</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 下面的两个命令有相同的功能。</span></div><div class="line">print(sess.run(result))</div><div class="line">print(result.eval(session=sess))</div></pre></td></tr></table></figure><h3 id="3-3-3-指定默认会话"><a href="#3-3-3-指定默认会话" class="headerlink" title="3.3.3 指定默认会话"></a>3.3.3 指定默认会话</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">sess = tf.Session()</div><div class="line"></div><div class="line"><span class="comment"># 下面的两个命令有相同的功能。</span></div><div class="line">print(sess.run(result))</div><div class="line">print(result.eval(session=sess))</div></pre></td></tr></table></figure><h3 id="3-3-4-通过ConfigProto配置会话"><a href="#3-3-4-通过ConfigProto配置会话" class="headerlink" title="3.3.4 通过ConfigProto配置会话"></a>3.3.4 通过ConfigProto配置会话</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">config=tf.ConfigProto(allow_soft_placement=<span class="keyword">True</span>, log_device_placement=<span class="keyword">True</span>)</div><div class="line">sess1 = tf.InteractiveSession(config=config)</div><div class="line">sess2 = tf.Session(config=config)</div></pre></td></tr></table></figure><h2 id="3-4-TensorFlow实现神经网络"><a href="#3-4-TensorFlow实现神经网络" class="headerlink" title="3.4 TensorFlow实现神经网络"></a>3.4 TensorFlow实现神经网络</h2><h3 id="3-4-2-前向传播算法简介"><a href="#3-4-2-前向传播算法简介" class="headerlink" title="3.4.2 前向传播算法简介"></a>3.4.2 前向传播算法简介</h3><p>tf.matmul 矩阵乘法</p><h3 id="3-4-3-神经网络参数与tensorflow变量"><a href="#3-4-3-神经网络参数与tensorflow变量" class="headerlink" title="3.4.3 神经网络参数与tensorflow变量"></a>3.4.3 神经网络参数与tensorflow变量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">weights = tf.Variable(tf.random_normal([<span class="number">2</span>, <span class="number">3</span>], stddev=<span class="number">2</span>))</div></pre></td></tr></table></figure><p>产生一个[2,3]的矩阵，矩阵中元素是均值为0，方差为2的随机数。</p><p> <strong>1.TensorFlow随机数生成函数</strong></p><table><thead><tr><th style="text-align:center">函数名称</th><th style="text-align:center">随机数分布</th><th style="text-align:center">主要参数</th></tr></thead><tbody><tr><td style="text-align:center">tf.random_normal</td><td style="text-align:center">正态分布</td><td style="text-align:center">平均值、标准差、取值类型</td></tr><tr><td style="text-align:center">tf.truncated_normal</td><td style="text-align:center">正太分布,但如果随机出来的值离平均值超过2个标准差，那么这个数将会被重新随机</td><td style="text-align:center">平均值、标准差、取值类型</td></tr><tr><td style="text-align:center">tf.random_uniform</td><td style="text-align:center">平均分布</td><td style="text-align:center">最小、最大取值、取值类型</td></tr><tr><td style="text-align:center">tf.random_gramma</td><td style="text-align:center">Gramma分布</td><td style="text-align:center">形状参数alpha、尺度参数beta、取值类型</td></tr></tbody></table><p> <strong>2.TensorFlow常数生成函数</strong></p><table><thead><tr><th style="text-align:center">函数名称</th><th style="text-align:center">功能</th><th style="text-align:center">样例</th></tr></thead><tbody><tr><td style="text-align:center">tf.zeros</td><td style="text-align:center">产生全0的数组</td><td style="text-align:center">tf.zeros([2,3],int32)-&gt;[[0,0,0],[0,0,0]]</td></tr><tr><td style="text-align:center">tf.ones</td><td style="text-align:center">产生全1的数组</td><td style="text-align:center">tf.ones([2,3],int32)-&gt;[[1,1,1],[1,1,1]]</td></tr><tr><td style="text-align:center">tf.fill</td><td style="text-align:center">产生一个全部为给定数字的数组</td><td style="text-align:center">tf.fill([2,3],9)-&gt;[[9,9,9],[9,9,9]]</td></tr><tr><td style="text-align:center">tf.constant</td><td style="text-align:center">产生一个给定值的常量</td><td style="text-align:center">tf.constant([1,2,3])-&gt;[1,2,3]</td></tr></tbody></table><p>声明了变量之后，程序的第二步会声明一个会话（session）。并通过会话计算结果。</p><p>在真正开始计算之前，必须对变量进行初始化：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">init_op = tf.global_variables_initializer()  </div><div class="line">sess.run(init_op)</div></pre></td></tr></table></figure></p><p>变量分为需要优化的参数（比如神经网络中的参数）和其他参数。<br><code>trainable = True</code>，则该变量会加入<code>GraphKeys.TRAINABLE_VARIABLES</code>集合。</p><p>维度（shape）和类型（type）是变量最重要的两个属性。</p><h3 id="3-4-4-通过tensorflow训练神经网络模型"><a href="#3-4-4-通过tensorflow训练神经网络模型" class="headerlink" title="3.4.4 通过tensorflow训练神经网络模型"></a>3.4.4 通过tensorflow训练神经网络模型</h3><p>监督学习的思想。</p><p>神经网络优化算法中，最常用的是反向传播算法。</p><pre><code>x = tf.constant([[0.7, 0.9]])</code></pre><p>常量表示样例导致计算图特变大。使用<strong>placeholder机制</strong>提供输入数据。</p><p>在placeholder定义的时候，这个位置上的数据类型是需要指定的。和其他张量一样，placeholder的类型不可以被改变。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">x = tf.placeholder(tf.float32, shape=(<span class="number">1</span>, <span class="number">2</span>), name=<span class="string">"input"</span>)</div><div class="line">a = tf.matmul(x, w1)</div><div class="line">y = tf.matmul(a, w2)</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line"></div><div class="line">init_op = tf.global_variables_initializer()</div><div class="line">sess.run(init_op)</div><div class="line"></div><div class="line">print(sess.run(y, feed_dict=&#123;x: [[<span class="number">0.7</span>, <span class="number">0.9</span>]]&#125;))</div></pre></td></tr></table></figure></p><p>feed_dict时一个字典（map），在字典中需要给出每个用到的placeholder的取值，否则运行会报错。</p><p>输入的数据一般是一个batch，不止一个，placeholder也支持输入多个数据。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">x = tf.placeholder(tf.float32, shape=(<span class="number">3</span>, <span class="number">2</span>), name=<span class="string">"input"</span>)</div><div class="line">a = tf.matmul(x, w1)</div><div class="line">y = tf.matmul(a, w2)</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line"><span class="comment">#使用tf.global_variables_initializer()来初始化所有的变量</span></div><div class="line">init_op = tf.global_variables_initializer()  </div><div class="line">sess.run(init_op)</div><div class="line"></div><div class="line">print(sess.run(y, feed_dict=&#123;x: [[<span class="number">0.7</span>,<span class="number">0.9</span>],[<span class="number">0.1</span>,<span class="number">0.4</span>],[<span class="number">0.5</span>,<span class="number">0.8</span>]]&#125;))</div></pre></td></tr></table></figure></p><p>在得到一个batch的前向传播结果之后，需要<strong>定义一个损失函数</strong>来刻画当前的预测值与真实答案之间的差距。然后通过反向传播算法来调整网络参数之间的取值使得差距可以被缩小。</p><h3 id="3-4-5-完整的神经网络样例程序"><a href="#3-4-5-完整的神经网络样例程序" class="headerlink" title="3.4.5 完整的神经网络样例程序"></a>3.4.5 完整的神经网络样例程序</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">from</span> numpy.random <span class="keyword">import</span> RandomState</div><div class="line"></div><div class="line"><span class="comment"># 1. 定义神经网络的参数，输入和输出节点。</span></div><div class="line">batch_size = <span class="number">8</span></div><div class="line">w1 = tf.Variable(tf.random_normal([<span class="number">2</span>, <span class="number">3</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</div><div class="line">w2 = tf.Variable(tf.random_normal([<span class="number">3</span>, <span class="number">1</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</div><div class="line">x = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, <span class="number">2</span>), name=<span class="string">"x-input"</span>)</div><div class="line">y_ = tf.placeholder(tf.float32, shape=(<span class="keyword">None</span>, <span class="number">1</span>), name=<span class="string">'y-input'</span>)</div><div class="line"></div><div class="line"><span class="comment"># 2. 定义前向传播过程，损失函数及反向传播算法。</span></div><div class="line">a = tf.matmul(x, w1)</div><div class="line">y = tf.matmul(a, w2)</div><div class="line"><span class="comment"># tf.clip_by_value(A, min, max)：输入一个张量A，把A中的每一个元素的值都压缩在min和max之间。小于min的让它等于min，大于max的元素的值等于max。</span></div><div class="line">cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, <span class="number">1e-10</span>, <span class="number">1.0</span>)))</div><div class="line">train_step = tf.train.AdamOptimizer(<span class="number">0.001</span>).minimize(cross_entropy)</div><div class="line"></div><div class="line"><span class="comment"># 3. 生成模拟数据集。</span></div><div class="line">rdm = RandomState(<span class="number">1</span>)</div><div class="line">dataset_size = <span class="number">128</span></div><div class="line">X = rdm.rand(dataset_size, <span class="number">2</span>)</div><div class="line">Y = [[int(x1 + x2 &lt; <span class="number">1</span>)] <span class="keyword">for</span> (x1, x2) <span class="keyword">in</span> X]</div><div class="line"></div><div class="line"><span class="comment"># 4. 创建一个会话来运行TensorFlow程序。</span></div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    init_op = tf.global_variables_initializer()</div><div class="line">    sess.run(init_op)</div><div class="line"></div><div class="line">    <span class="comment"># 输出目前（未经训练）的参数取值。</span></div><div class="line">    print(<span class="string">"w1:"</span>, sess.run(w1))</div><div class="line">    print(<span class="string">"w2:"</span>, sess.run(w2))</div><div class="line">    print(<span class="string">"\n"</span>)</div><div class="line"></div><div class="line">    <span class="comment"># 训练模型。</span></div><div class="line">    STEPS = <span class="number">5000</span>  <span class="comment"># 设定训练的轮数</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(STEPS):</div><div class="line">        start = (i * batch_size) % <span class="number">128</span></div><div class="line">        end = (i * batch_size) % <span class="number">128</span> + batch_size</div><div class="line">        sess.run(train_step, feed_dict=&#123;x: X[start:end], y_: Y[start:end]&#125;)</div><div class="line">        <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</div><div class="line">            total_cross_entropy = sess.run(cross_entropy, feed_dict=&#123;x: X, y_: Y&#125;)</div><div class="line">            print(<span class="string">"After %d training step(s), cross entropy on all data is %g"</span> % (i, total_cross_entropy))</div><div class="line"></div><div class="line">    <span class="comment"># 输出训练后的参数取值。</span></div><div class="line">    print(<span class="string">"\n"</span>)</div><div class="line">    print(<span class="string">"w1:"</span>, sess.run(w1))</div><div class="line">    print(<span class="string">"w2:"</span>, sess.run(w2))</div></pre></td></tr></table></figure><p>输出为：</p><p>训练之前的神经网络的参数值：</p><blockquote><p>w1: [[-0.81131822  1.48459876  0.06532937]<br> [-2.4427042   0.0992484   0.59122431]]</p><p>w2: [[-0.81131822]<br> [ 1.48459876]<br> [ 0.06532937]]</p></blockquote><p>可以发现，随着训练的进行，交叉熵是逐渐减小的。交叉熵越小说明预测的结果和真实的结果差距越小。</p><blockquote><p>After 0 training step(s), cross entropy on all data is 0.0674925</p><p>After 1000 training step(s), cross entropy on all data is 0.0163385</p><p>After 2000 training step(s), cross entropy on all data is 0.00907547</p><p>After 3000 training step(s), cross entropy on all data is 0.00714436</p><p>After 4000 training step(s), cross entropy on all data is 0.00578471<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div></pre></td><td class="code"><pre><div class="line">训练之后的神经网络的参数值：</div><div class="line">&gt; </div><div class="line">&gt; w1: [[-1.9618274   2.58235407  1.68203783]</div><div class="line">&gt;  [-3.46817183  1.06982327  2.11789012]]</div><div class="line">&gt;  </div><div class="line">&gt; w2: [[-1.82471502]</div><div class="line">&gt;  [ 2.68546653]</div><div class="line">&gt;  [ 1.41819513]]</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"># 第4章 深层神经网络</div><div class="line"></div><div class="line">## 4.1 深度学习与深层神经网络</div><div class="line"></div><div class="line">### 4.1.1 线性模型的局限性</div><div class="line">### 4.1.2 激活函数实现去线性化</div><div class="line"></div><div class="line">激活函数：tf.nn.relu、tf.sigmoid和tf.tanh。</div><div class="line"></div><div class="line">### 4.1.3 多层网络解决异或运算</div><div class="line"></div><div class="line">单层感知机无法模拟异或运算。加入了隐含层之后，就可以解决异或问题。</div><div class="line"></div><div class="line">## 4.2损失函数的定义</div><div class="line"></div><div class="line">### 4.2.1 经典损失函数</div><div class="line"></div><div class="line">交叉熵(cross entropy)。用q来表示p的交叉熵为：</div><div class="line">$$H(p,q)=-\sum_x p(x)\text&#123;log&#125; q(x)$$</div><div class="line"></div><div class="line">p代表的是正确答案，q代表的是预测值。交叉熵刻画的是两个概率分布的距离，也就是说交叉熵越小，两个概率分布越接近。</div><div class="line"></div><div class="line">`softmax`回归：将神经网络的输出变成一个概率分布。</div><div class="line"></div><div class="line">交叉熵的代码实现：</div><div class="line"></div><div class="line">cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))</div><div class="line"></div><div class="line"></div><div class="line">其中，`tf.clip_by_value`的用法</div><div class="line"></div><div class="line">`tf.clip_by_value(A, min, max)：`输入一个张量A，把A中的每一个元素的值都压缩在`min`和`max`之间。小于`min`的让它等于`min`，大于`max`的元素的值等于`max`。</div><div class="line"></div><div class="line">import tensorflow as tf;  </div><div class="line">import numpy as np;  </div><div class="line">  </div><div class="line">A = np.array([[1,1,2,4], [3,4,8,5]])  </div><div class="line">  </div><div class="line">with tf.Session() as sess:  </div><div class="line">    print sess.run(tf.clip_by_value(A, 2, 5)) </div><div class="line"></div><div class="line">输出：</div><div class="line"></div><div class="line">&gt; [[2 2 2 4]</div><div class="line">&gt; </div><div class="line">&gt;  [3 4 5 5]]</div><div class="line"></div><div class="line">`tf.log`是对张量中所有元素依次求对数。</div><div class="line"></div><div class="line">`*`操作是元素之间直接相乘，矩阵乘法是`tf.matmul`。</div><div class="line"></div><div class="line">上面三个计算得到的结果是nxm的矩阵。</div><div class="line"></div><div class="line">`tf.reduce_mean`的用法。</div><div class="line"></div><div class="line">v = tf.constant([[1.0, 2.0, 3.0, 4.0], [4.0, 5.0, 6.0, 7.0]])</div><div class="line">sess = tf.Session()</div><div class="line">init_op = tf.global_variables_initializer()</div><div class="line">sess.run(init_op)</div><div class="line">print(tf.reduce_mean(v).eval(session=sess))</div><div class="line"># 程序输出为：4.0 = sum/8</div><div class="line"></div><div class="line">### 4.2.2 自定义损失函数</div><div class="line">当然tensorflow也支持自定义损失函数。</div><div class="line">## 4.3 神经网络优化算法</div><div class="line">假设用$\theta$表示神经网络中的参数，$J(\theta)$表示在给定的参数取值下，训练集上损失函数的大小，那么整个优化过程可以抽象为：寻找一个参数$\theta$，使得$J(\theta)$最小。</div><div class="line"></div><div class="line">对于参数$\theta$，其梯度为$\frac&#123;\partial&#125;&#123;\partial\theta&#125;J(\theta)$。有了梯度，还需要学习率$\eta $(learning rate)来控制每次参数更新的幅度。</div><div class="line">因此，参数更新的公式为：</div><div class="line">$$\theta_&#123;n+1&#125; = \theta_n -  \eta \frac&#123;\partial&#125;&#123;\partial\theta&#125;J(\theta)$$</div><div class="line"></div><div class="line">需要注意的是梯度下降算法并不能保证达到全局最优解，此外还存在计算时间过长的问题。</div><div class="line"></div><div class="line">为了加速训练过程，可以使用随机梯度下降(stochastic gradient descent)算法。每一轮迭代中随机优化某一条训练数据的损失函数。</div><div class="line"></div><div class="line">在实际应用中，采用折中的方法：**每次计算一小部分训练数据的损失函数**。这一小部分数据被称为&lt;font color=AA00AA&gt;**batch**&lt;/font&gt;。</div><div class="line"></div><div class="line">## 4.4 神经网络进一步优化</div><div class="line">### 4.4.1 学习率的设置</div><div class="line"></div><div class="line">假设我们要最小化函数  $y=x^2$, 选择初始点   $x_0=5$。</div><div class="line">#### 1. 学习率为1时</div><div class="line">```python</div><div class="line">import tensorflow as tf</div><div class="line">TRAINING_STEPS = 10</div><div class="line">LEARNING_RATE = 1</div><div class="line">x = tf.Variable(tf.constant(5, dtype=tf.float32), name=&quot;x&quot;)</div><div class="line">y = tf.square(x)</div><div class="line"></div><div class="line">train_op = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(y)</div><div class="line"></div><div class="line">with tf.Session() as sess:</div><div class="line">    sess.run(tf.global_variables_initializer())</div><div class="line">    for i in range(TRAINING_STEPS):</div><div class="line">        sess.run(train_op)</div><div class="line">        x_value = sess.run(x)</div><div class="line">        print &quot;After %s iteration(s): x%s is %f.&quot;% (i+1, i+1, x_value)</div></pre></td></tr></table></figure></p></blockquote><p>结果是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">After 1 iteration(s): x1 is -5.000000.</div><div class="line">After 2 iteration(s): x2 is 5.000000.</div><div class="line">After 3 iteration(s): x3 is -5.000000.</div><div class="line">After 4 iteration(s): x4 is 5.000000.</div><div class="line">After 5 iteration(s): x5 is -5.000000.</div><div class="line">After 6 iteration(s): x6 is 5.000000.</div><div class="line">After 7 iteration(s): x7 is -5.000000.</div><div class="line">After 8 iteration(s): x8 is 5.000000.</div><div class="line">After 9 iteration(s): x9 is -5.000000.</div><div class="line">After 10 iteration(s): x10 is 5.000000.</div></pre></td></tr></table></figure></p><p>学习率为1的时候，x在5和-5之间震荡。</p><h4 id="2-学习率为0-001时"><a href="#2-学习率为0-001时" class="headerlink" title="2. 学习率为0.001时"></a>2. 学习率为0.001时</h4><p>将上述代码中的学习率设为0.001（很小），如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">LEARNING_RATE = <span class="number">0.001</span></div></pre></td></tr></table></figure></p><p>运行结果为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">After 1 iteration(s): x1 is 4.990000.</div><div class="line">After 101 iteration(s): x101 is 4.084646.</div><div class="line">After 201 iteration(s): x201 is 3.343555.</div><div class="line">After 301 iteration(s): x301 is 2.736923.</div><div class="line">After 401 iteration(s): x401 is 2.240355.</div><div class="line">After 501 iteration(s): x501 is 1.833880.</div><div class="line">After 601 iteration(s): x601 is 1.501153.</div><div class="line">After 701 iteration(s): x701 is 1.228794.</div><div class="line">After 801 iteration(s): x801 is 1.005850.</div><div class="line">After 901 iteration(s): x901 is 0.823355.</div></pre></td></tr></table></figure></p><p>学习率为0.001的时候，下降速度过慢，在901轮时才收敛到0.823355。</p><h4 id="3-使用指数衰减的学习率"><a href="#3-使用指数衰减的学习率" class="headerlink" title="3. 使用指数衰减的学习率"></a>3. 使用指数衰减的学习率</h4><p>将上述代码中的学习率设为指数衰减的方式，如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">LEARNING_RATE = tf.train.exponential_decay(<span class="number">0.1</span>, global_step, <span class="number">1</span>, <span class="number">0.96</span>, staircase=<span class="keyword">True</span>)</div></pre></td></tr></table></figure></p><p>运行结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">After 1 iteration(s): x1 is 4.000000, learning rate is 0.096000.</div><div class="line">After 11 iteration(s): x11 is 0.690561, learning rate is 0.063824.</div><div class="line">After 21 iteration(s): x21 is 0.222583, learning rate is 0.042432.</div><div class="line">After 31 iteration(s): x31 is 0.106405, learning rate is 0.028210.</div><div class="line">After 41 iteration(s): x41 is 0.065548, learning rate is 0.018755.</div><div class="line">After 51 iteration(s): x51 is 0.047625, learning rate is 0.012469.</div><div class="line">After 61 iteration(s): x61 is 0.038558, learning rate is 0.008290.</div><div class="line">After 71 iteration(s): x71 is 0.033523, learning rate is 0.005511.</div><div class="line">After 81 iteration(s): x81 is 0.030553, learning rate is 0.003664.</div><div class="line">After 91 iteration(s): x91 is 0.028727, learning rate is 0.002436.</div></pre></td></tr></table></figure></p><p>使用指数衰减的学习率，在迭代初期得到较高的下降速度，可以在较小的训练轮数下取得不错的收敛程度。</p><h3 id="4-4-2-过拟合问题"><a href="#4-4-2-过拟合问题" class="headerlink" title="4.4.2 过拟合问题"></a>4.4.2 过拟合问题</h3><p>为了避免过拟合，一个非常常用的方法是正则化(regularization)，加入刻画模型复杂程度的指标$R(w)$，优化时优化$J(\theta)+\lambda R(w) $。</p><p>常用的正则化方法有：L1正则化和L2正则化。<br>$$R(w) =||w||_1 =\sum_i|w_i|$$<br>$$R(w) =||w||_2^2 =\sum_i|w_i^2|$$</p><p>无论哪一种正则化的方式，其思想都是通过限制权重的大小，使得模型不能任意拟合训练数据中的随机噪声。</p><p>区别在于，L1正则化会使得参数变得更加稀疏，而L2正则化则不会；此外，L1正则化的计算公式不可导，而L2正则化公式可导。</p>]]></content:encoded>
      
      <comments>http://wangwlj.com/2017/12/28/tensorflow_base/#disqus_thread</comments>
    </item>
    
    <item>
      <title>基于TensorFlow的简单语音识别</title>
      <link>http://wangwlj.com/2017/12/28/TensorFlow_speech_commands/</link>
      <guid>http://wangwlj.com/2017/12/28/TensorFlow_speech_commands/</guid>
      <pubDate>Thu, 28 Dec 2017 14:24:03 GMT</pubDate>
      <description>
      
        &lt;h2 id=&quot;简单语音识别教程&quot;&gt;&lt;a href=&quot;#简单语音识别教程&quot; class=&quot;headerlink&quot; title=&quot;简单语音识别教程&quot;&gt;&lt;/a&gt;简单语音识别教程&lt;/h2&gt;&lt;p&gt;虽然真正的语音和音频识别系统要复杂得多，但是像MNIST（入门级的CV数据集）一样，本教程应该会让你对所涉技术有一个基本的了解。&lt;/p&gt;
&lt;p&gt;完成本教程后，你将可以尝试创建一个模型，将一秒钟的音频剪辑去噪，并且能识别如下单词： &lt;code&gt;“yes”，“no”，“up”，“down”，&amp;quot;left&amp;quot;，&amp;quot;right&amp;quot;，&amp;quot;on&amp;quot;，&amp;quot;off&amp;quot;，&amp;quot;stop&amp;quot;，or &amp;quot;go&amp;quot;&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;你也可以在Android应用程序中运行该模型。&lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="简单语音识别教程"><a href="#简单语音识别教程" class="headerlink" title="简单语音识别教程"></a>简单语音识别教程</h2><p>虽然真正的语音和音频识别系统要复杂得多，但是像MNIST（入门级的CV数据集）一样，本教程应该会让你对所涉技术有一个基本的了解。</p><p>完成本教程后，你将可以尝试创建一个模型，将一秒钟的音频剪辑去噪，并且能识别如下单词： <code>“yes”，“no”，“up”，“down”，&quot;left&quot;，&quot;right&quot;，&quot;on&quot;，&quot;off&quot;，&quot;stop&quot;，or &quot;go&quot;</code>。</p><p>你也可以在Android应用程序中运行该模型。</p><a id="more"></a><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>你要确保已经安装了TensorFlow，由于该版本下载了超过1GB的训练数据，因此你需要电脑有足够的内存，另外网速要快，训练过程可能需要几个小时。</p><h2 id="出错与解决"><a href="#出错与解决" class="headerlink" title="出错与解决"></a>出错与解决</h2><h3 id="找不到audio-ops"><a href="#找不到audio-ops" class="headerlink" title="找不到audio_ops"></a>找不到audio_ops</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Traceback (most recent call last):</div><div class="line">  File <span class="string">"train.py"</span>, line <span class="number">79</span>, <span class="keyword">in</span> &lt;module&gt;</div><div class="line">    <span class="keyword">import</span> input_data</div><div class="line">  File <span class="string">"/home/philglau/speech_commands/input_data.py"</span>, line <span class="number">35</span>, <span class="keyword">in</span> &lt;module&gt;</div><div class="line">    <span class="keyword">from</span> tensorflow.contrib.framework.python.ops <span class="keyword">import</span> audio_ops <span class="keyword">as</span> contrib_audio</div><div class="line">ImportError: cannot <span class="keyword">import</span> name <span class="string">'audio_ops'</span></div></pre></td></tr></table></figure><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>这个’audio_ops’只在TensorFlow1.4版本中有，所以，如果不是1.4的版本，一般都会有这个错误。</p><p>此时的解决方案，一是更新TensorFlow版本，二是使用如下命令安装tf-nightly即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install tf-nightly</div></pre></td></tr></table></figure><p>详见参考连接三。</p><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>要开始训练过程，请访问<a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="external">TensorFlow源代码树</a>下载并运行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python tensorflow/examples/speech_commands/train.py</div></pre></td></tr></table></figure><p>训练过程将从下载“ 语音命令”数据集开始，该数据集由65000个WAVE音频文件组成，其中有30个不同的单词。</p><p>这些数据是由Google收集的，并根据CCBY许可证发布。存档超过1GB，所以下载可能需要一段时间，但你应该能看到进度日志，一旦下载完成，你就不用再次执行此步骤了。</p><p>下载完成后，你将看到如下所示的日志记录信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">I0730 16:53:44.766740 55030 train.py:176] Training from step: 1</div><div class="line"></div><div class="line">I0730 16:53:47.289078 55030 train.py:217] Step #1: rate 0.001000, accuracy 7.0%, cross entropy 2.611571</div></pre></td></tr></table></figure><p>这表明初始化过程已经完成，循环训练已经开始。你会看到它输出每个训练步骤的信息。</p><p>步骤分解：</p><p>Step #1表明我们正在循环训练的第一步。在这种情况下，总共将有18000个步骤，所以你可以查看步骤号码，了解其完成程度有多接近。</p><p>rate 0.001000是控制网络权重更新速度的学习率。早期的这个数字是相对较高的（0.001），但是对于后来的训练周期，它会减少10倍到0.0001。</p><p><code>accuracy 7.0%</code>在这个训练步骤中正确地预测了有多少classes。value函数往往波动很大，但随着训练的进行，平均值会增加。该模型输出一个数字数组，每个标签一个，每个数字是该类输入的预测可能性。</p><p>通过选择具有最高分数的条目来选择预测的标签，分数总是在零和一之间。</p><p><code>cross entropy 2.611571</code>是我们用来指导培训过程的损失功能的结果。这是通过比较当前训练运动与正确标签的分数向量获得的分数，这在训练期间应该向下倾斜。</p><p>经过一百步，你应该看到这样的一行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">I0730 16:54:41.813438 55030 train.py:252] Saving to &quot;/tmp/speech_commands_train/conv.ckpt-100&quot;</div></pre></td></tr></table></figure></p><p>这是将当前训练的权重保存到checkpoint文件中。如果你的训练脚本中断，可以查找最后保存的checkpoint，然后：<br><code>--start_checkpoint=/tmp/speech_commands_train/conv.ckpt-100</code>使用命令行参数重新启动脚本， 从那里开始。</p><h2 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h2><p>四百步后，将记录以下信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">I0730 16:57:38.073667 55030 train.py:243] Confusion Matrix:</div><div class="line"></div><div class="line">[[258 0  0  0  0 0  0 0  0  0 0 0]</div><div class="line"></div><div class="line">[  7  6  26 94  7 49 1 15 40 2 0 11]</div><div class="line"></div><div class="line">[ 10  1 107 80 13 22 0 13 10 1 0  4]</div><div class="line"></div><div class="line">[ 1  3  16 163  6 48 0  5 10 1 0  17]</div><div class="line"></div><div class="line">[ 15 1  17 114 55 13 0  9 22 5 0  9]</div><div class="line"></div><div class="line">[ 1  1  6  97  3  87 1 12 46 0 0  10]</div><div class="line"></div><div class="line">[ 8  6 86  84 13  24 1  9  9 1 0  6]</div><div class="line"></div><div class="line">[ 9  3 32 112  9  26 1 36 19 0 0  9]</div><div class="line"></div><div class="line">[ 8  2 12  94  9  52 0  6 72 0 0  2]</div><div class="line"></div><div class="line">[ 16 1 39  74 29  42 0  6 37 9 0  3]</div><div class="line"></div><div class="line">[ 15 6 17  71 50  37 0  6 32 2 1  9]</div><div class="line"></div><div class="line">[ 11 1  6 151 5   42 0  8 16 0 0 20]]</div></pre></td></tr></table></figure></p><p>第一部分是<strong>混淆矩阵</strong>。要了解这是什么意思，你首先需要知道正在使用的标签，在这种情况下，它们分别表示为<code>静音、未知yes、no、up、down、left、right、on、off、stop、go</code>。</p><p>第一行是所有的静音剪辑，第二个剪辑是未知的单词，第三个“yes”等。</p><p>该矩阵可以比单个准确率得分更有用，因为它可以很好地总结出网络发生的错误。在此示例中，你可以看到除了初始条目之外，第一行中的所有条目都为零。</p><p>因为第一行实际上都是静音的片段，所以这意味着它们都没有被错误的标注为文字，所以我们没有任何静音的否定。这表明网络已经越来越好地区分了静音与谈话。</p><p><strong>一个完美的模型将产生一个混淆矩阵，其中所有的条目都是从对角线穿过中心的零点</strong>。一旦你确定了可以通过添加更多数据来解决问题，该模型的方差可以帮助你了解模型怎样最容易混淆。</p><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>混淆矩阵之后，你会看到如下一行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">I0730 16:57:38.073777 55030 train.py:245] Step 400: Validation accuracy = 26.3% (N=3093)</div></pre></td></tr></table></figure></p><p>将数据集分为三类是很好的做法。最大的（大约是数据的80％）用于训练网络，一个较小的集（10％ “validation”）被保留用于评估训练中的准确性，另一组10％，“testing”）用于在训练完成后评估准确度。</p><p>通过将数据集分类为训练集、验证集、测试集，你可以确保该模型适用于之前从未见过的数据。测试集是一个额外的保障措施，以确保不仅仅是以适用于训练和验证集拟合调整模型。</p><p>训练脚本将数据集自动分成这三个类别，上面的记录行显示了在验证集上运行时的模型准确率。理想情况下，这应该与训练准确性相当接近。如果训练准确性增加但验证不是这样，这表明过度拟合正在发生，你的模型只是学习关于训练剪辑的东西，而不是真正的训练模式。</p><h2 id="Tensorboard"><a href="#Tensorboard" class="headerlink" title="Tensorboard"></a>Tensorboard</h2><p>使用Tensorboard可以看出训练进展。默认情况下，脚本将事件保存到/ tmp / retrain_logs，可以通过运行以下命令来加载它们：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tensorboard --logdir /tmp/retrain_logs</div></pre></td></tr></table></figure></p><p>然后在浏览器中导航到<code>http：// localhost：6006</code>，将看到显示模型进度的图表。</p><h2 id="完成训练"><a href="#完成训练" class="headerlink" title="完成训练"></a>完成训练</h2><p>经过几个小时的训练（取决于你的电脑快慢），脚本应该已经完成了所有18000个步骤。它将识别出最终的混淆矩阵，以及准确率分数，全部运行在测试集上。使用默认设置，准确率在85％到90％之间。</p><p>因为音频识别在移动设备上特别有用，接下来我们将其导出为，在移动平台上易于使用的格式。要执行此操作，请运行以下命令行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">python tensorflow/examples/speech_commands/freeze.py</div><div class="line"></div><div class="line">--start_checkpoint=/tmp/speech_commands_train/conv.ckpt-18000</div><div class="line"></div><div class="line">--output_file=/tmp/my_frozen_graph.pb</div></pre></td></tr></table></figure></p><p>创建固定模型后，可以使用<code>label_wav.py</code>脚本进行测试，如下所示：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">python tensorflow/examples/speech_commands/label_wav.py</div><div class="line"></div><div class="line">--graph=/tmp/my_frozen_graph.pb</div><div class="line"></div><div class="line">--labels=/tmp/speech_commands_train/conv_labels.txt</div><div class="line"></div><div class="line">--wav=/tmp/speech_dataset/left/a5d485dc_nohash_0.wav</div></pre></td></tr></table></figure></p><p>可以识别出三个标签：</p><p>left (score = 0.81477)</p><p>right (score = 0.14139)</p><p>_unknown_ (score = 0.03808)</p><p>更多内容请查看论文：<a href="http://suo.im/3PW89b" target="_blank" rel="external">http://suo.im/3PW89b</a></p><h2 id="在Android应用程序中运行模型"><a href="#在Android应用程序中运行模型" class="headerlink" title="在Android应用程序中运行模型"></a>在Android应用程序中运行模型</h2><p>查看此模型在真实应用程序中如何工作的最简单的方法是，下载预构建的<a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android#prebuilt-components" target="_blank" rel="external">Android演示应用程序</a>并将其安装在手机上。</p><p>你会看到“TF Speech”出现在应用程序列表中，打开它将显示我们刚刚训练过单词列表，从“yes”和“no”开始。</p><p>你还可以自己构建此应用程序，因为它是开源的， 并可作为github上TensorFlow<a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android#building-in-android-studio-using-the-tensorflow-aar-from-jcenter" target="_blank" rel="external">存储库的一部分使用</a>。<br>默认情况下，它从tensorflow.org下载一个预先训练的模型，但你可以轻松地用自己训练的模型替换它。</p><p>如果你自己创建的话，你需要确保SpeechActivity Java<a href="http://suo.im/2fWbai" target="_blank" rel="external">源文件</a>中的 SAMPLE_RATE，SAMPLE_DURATION符合你训练时的默认设置所做的任何更改。</p><p>你还会看到一个Java版本的<a href="http://suo.im/31vKvx" target="_blank" rel="external">Rec<br>ognizeCommands模块</a>。</p><p>这与本教程中的C++版本非常相似。如果你调整了参数，还可以在SpeechActivity中进行更新，以获得与服务器测试相同的结果。</p><p>演示应用程序，根据你在固定模型复制到模型中的标签文本文件，自动更新其用户界面列表，可以轻松地尝试不同的模型，而无需进行任何代码更改。如果你更改路径，需要update LABEL_FILENAME，MODEL_FILENAME添加到文件。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.tensorflow.org/versions/master/tutorials/audio_recognition" target="_blank" rel="external">TensorFlow官网教程：Simple Audio Recognition</a></li><li><a href="http://www.sohu.com/a/167209693_798050" target="_blank" rel="external">中文翻译参考</a></li><li><a href="https://stackoverflow.com/questions/45952387/anaconda-install-of-tensorflow-missing-audio-ops-from-contrib-framework" target="_blank" rel="external">Tensorflow missing ‘audio_ops’ from contrib framework</a></li></ul>]]></content:encoded>
      
      <comments>http://wangwlj.com/2017/12/28/TensorFlow_speech_commands/#disqus_thread</comments>
    </item>
    
    <item>
      <title>VS2015 设置调试时不加载符号</title>
      <link>http://wangwlj.com/2017/12/27/CPP_VS2015_noPDB/</link>
      <guid>http://wangwlj.com/2017/12/27/CPP_VS2015_noPDB/</guid>
      <pubDate>Wed, 27 Dec 2017 13:53:16 GMT</pubDate>
      <description>
      
        &lt;p&gt;&lt;img src=&quot;https://images2.imgbox.com/1c/a2/uWHMn9oN_o.png&quot; alt=&quot;调试加载界面&quot;&gt;&lt;br&gt;人生苦短，消除等待！！&lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<p><img src="https://images2.imgbox.com/1c/a2/uWHMn9oN_o.png" alt="调试加载界面"><br>人生苦短，消除等待！！</p><a id="more"></a><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>用VS2015打开代码文件，按下F5进行调试，当电脑接入网络后系统会<strong>自动从Microsoft符号服务器加载PDB符号文件</strong>，而且是每次都会加载。如下图所示：<br><img src="https://images2.imgbox.com/1c/a2/uWHMn9oN_o.png" alt="调试加载界面"></p><p>此加载符号过程使得调试变得非常慢。</p><p>通过查阅得知，此类的pdb调试器在编写代码时对于新手来说，根本用不到。也就是说完全可以不需要加载。</p><p>那么如何避免VS2013调试时自动加载符号呢？</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><ol><li><p>打开VS的【工具】-【选项】：<br><img src="https://images2.imgbox.com/bc/8e/PXMTNcYk_o.png" alt="工具选项"></p></li><li><p>选择其中的【调试】-【符号】，并 取消勾选“Microsoft符号服务器” ：<br><img src="https://images2.imgbox.com/eb/35/XrMdw2M8_o.png" alt="取消勾选"></p></li><li><p>确定并退出即可，此后再次按F5进行调试。</p></li></ol><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><p><a href="https://jingyan.baidu.com/article/fea4511a1a1040f7bb91251a.html" target="_blank" rel="external">VS2013代码调试：如何避免调试时加载符号</a></p></li><li><p><a href="http://blog.csdn.net/u010186001/article/details/52759945" target="_blank" rel="external">vs2015加载符号慢，请问怎么解决</a></p></li></ol>]]></content:encoded>
      
      <comments>http://wangwlj.com/2017/12/27/CPP_VS2015_noPDB/#disqus_thread</comments>
    </item>
    
    <item>
      <title>机器学习技法笔记01：最佳分类超平面</title>
      <link>http://wangwlj.com/2017/12/26/ML_taiwan_01/</link>
      <guid>http://wangwlj.com/2017/12/26/ML_taiwan_01/</guid>
      <pubDate>Tue, 26 Dec 2017 02:24:06 GMT</pubDate>
      <description>
      
        &lt;h2 id=&quot;Large-Margin-Separating-Hyperplane&quot;&gt;&lt;a href=&quot;#Large-Margin-Separating-Hyperplane&quot; class=&quot;headerlink&quot; title=&quot;Large-Margin Separating Hyperplane&quot;&gt;&lt;/a&gt;Large-Margin Separating Hyperplane&lt;/h2&gt;&lt;p&gt;题目翻译为中文的意思大体上是 最大余量分类超平面。本节主要讲解如何确定该最佳分类超平面。&lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<h2 id="Large-Margin-Separating-Hyperplane"><a href="#Large-Margin-Separating-Hyperplane" class="headerlink" title="Large-Margin Separating Hyperplane"></a>Large-Margin Separating Hyperplane</h2><p>题目翻译为中文的意思大体上是 最大余量分类超平面。本节主要讲解如何确定该最佳分类超平面。</p><a id="more"></a><p>首先，我们回顾一下之前讲过的Linear Classfication ：有$\circ$和$\times$，我们用一条直线将$\circ$和$\times$分开，或者在高维空间中使用超平面将其分开。数学上，将资料拿来计算一个加权和，根据和的正负预测$\circ$和$\times$。</p><p>现在，给定一个线性可分的资料，则会有很多条线将和分开，但是下图中的那条线会更好呢？</p><p><img src="/2017/12/26/ML_taiwan_01/ML01.png" alt=""></p><p>PLA(Perceptron learning algorithm,For binary classification解决是非问题)会选哪一条线与PLA看到的错误有关，因此PLA得到哪一条线不定。从之前的理论来看，三条线似乎也没什么区别，例如从VC Bound来看：<br>$$E_{out}(w)\leqslant E_{in}(w) + \Omega(H) $$</p><p>其中$E_{in}(w)$为训练样本上的错误率，三条线都满足；$\Omega(H)$为复杂度，都是线，因此复杂度都为<code>d+1</code>。但是我们的直觉告诉我们最右边是最好的线。</p><p>一种原始的解释：<br>假设我们已经拿到原始资料，即图上的点，但是在测试的时候我们拿到跟原始资料相近的资料(测量误差、资料收集等造成)，下图中灰色的x。所以，测试资料可能会和训练资料有点出入。</p><p>假设我们绝对相信我们的训练资料，若果有误差，则我们人为最好的预测为将测试资料预测的与训练资料很接近(不完全一样)。</p><p><img src="/2017/12/26/ML_taiwan_01/ML02.png" alt=""></p><p>上图中左边与右边最大的差别就在于<strong>对测量误差的容忍度</strong>，点距离线越远则容忍度越好(<code>tolerate more noise</code>)，进而可以避免过拟合(<code>more robust to overfitting</code>)。</p><p>或者换个角度，看这条线有多胖（能涨出去多少），倾向于选择胖的线。</p><p><img src="/2017/12/26/ML_taiwan_01/ML03.png" alt=""></p><blockquote><p>robustness = fatness: distance to closest xn<br>比较胖的线是比较好的。</p><p>goal: find fattest separating hyperplane<br>在分类正确的基础上，找出最胖、最强壮(鲁棒)的线。</p></blockquote><p><strong>目标</strong>是：<br>我们要找出一条线，首先这条线可以将$\circ$和$\times$分开(线性可分)，然后取最胖的一条线，即计算所有点到线的距离，取其中最小的距离。也就是下面的公式所描述的：<br><img src="/2017/12/26/ML_taiwan_01/ML04.png" alt=""></p><p><code>fatness: formally called margin</code>：<br>最胖的线，术语上叫“margin”，余量，留白的多少。</p><p><code>correctness: yn = sign(w^T x_n)</code><br>算出来的分数是正的还是负的，相乘是同号(分类正确)就可以。</p><p><code>goal: find largest-margin separating hyperplane</code>：寻找边界最宽，能够完全分开的线（超平面）。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="http://blog.csdn.net/nysyxxg/article/details/52843827" target="_blank" rel="external">台大林轩田《机器学习基石》学习笔记5：线性模型一（PLA/pocket、Linearregression ）</a></li><li><a href="http://blog.csdn.net/xiong452980729/article/details/52234270" target="_blank" rel="external">机器学习技法(林軒田)笔记之一</a></li><li>机器学习技法(林軒田)视频与讲稿。</li></ol>]]></content:encoded>
      
      <comments>http://wangwlj.com/2017/12/26/ML_taiwan_01/#disqus_thread</comments>
    </item>
    
    <item>
      <title>C++ Primer学习笔记：(一/二)从基本类型开始</title>
      <link>http://wangwlj.com/2017/12/25/CPP_01_02/</link>
      <guid>http://wangwlj.com/2017/12/25/CPP_01_02/</guid>
      <pubDate>Mon, 25 Dec 2017 02:31:35 GMT</pubDate>
      <description>
      
        &lt;p&gt;本文介绍了C++的基础知识点。包括但不限于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;顶层const与底层const&lt;/li&gt;
&lt;li&gt;constexpr&lt;/li&gt;
&lt;li&gt;auto&lt;/li&gt;
&lt;li&gt;decltype&lt;/li&gt;
&lt;li&gt;struct&lt;/li&gt;
&lt;li&gt;头文件保护符&lt;/li&gt;
&lt;/ul&gt;
      
      </description>
      
      <content:encoded><![CDATA[<p>本文介绍了C++的基础知识点。包括但不限于：</p><ul><li>顶层const与底层const</li><li>constexpr</li><li>auto</li><li>decltype</li><li>struct</li><li>头文件保护符</li></ul><a id="more"></a><h1 id="第一章-开始"><a href="#第一章-开始" class="headerlink" title="第一章 开始"></a>第一章 开始</h1><h2 id="include指令-P6-1-2"><a href="#include指令-P6-1-2" class="headerlink" title="include指令(P6,1.2)"></a>include指令(P6,1.2)</h2><p>通常情况下<code>#include</code>指令必须在所有函数之外。include和它想包含的头文件名字必须在同一行里，不然会报错。</p><p>一般情况下我们把include指令放在源文件代码内容的最前面，当你在源文件中使用<code>#include</code>声明了一个头文件，效果相当于你把整个头文件黏贴到对应的那一行上。</p><h2 id="编译器-P14-1-4"><a href="#编译器-P14-1-4" class="headerlink" title="编译器(P14,1.4)"></a>编译器(P14,1.4)</h2><p>编译器的一部分工作是寻找程序文本中的错误。<br>常见错误类型：</p><ul><li>语法错误(syntax error)</li><li>类型错误(type error)</li><li>声明错误(declaration error)</li></ul><p><strong>“编辑-编译-调试”（edit-compile-debug）</strong>周期。</p><h2 id="文件重定向-P19-1-5"><a href="#文件重定向-P19-1-5" class="headerlink" title="文件重定向(P19,1.5)"></a>文件重定向(P19,1.5)</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span> addItems &lt;infile &gt;outfile</div></pre></td></tr></table></figure><h2 id="专业术语-P23"><a href="#专业术语-P23" class="headerlink" title="专业术语(P23)"></a>专业术语(P23)</h2><ol><li>花括号 curly brace</li><li>内置类型 built-in type</li><li>形参列表 parameter list</li><li>字符串字面值常量 string literal</li><li>操作符 manipulator</li><li>变量 variable</li><li>初始化 initialize</li><li>注释 comments</li><li>集成开发环境 Integrated Developed Environment,IDE</li><li>条件 condition</li><li>赋值 assignment</li><li>表达式 expression</li><li>语法错误 syntax error</li><li>方法（类方法） method</li></ol><h1 id="第二章-变量和基本类型"><a href="#第二章-变量和基本类型" class="headerlink" title="第二章 变量和基本类型"></a>第二章 变量和基本类型</h1><h2 id="C-语言关于类型的规定-P30-2-1-1"><a href="#C-语言关于类型的规定-P30-2-1-1" class="headerlink" title="C++语言关于类型的规定(P30,2.1.1)"></a>C++语言关于类型的规定(P30,2.1.1)</h2><p>C++语言的基本类型的设定与硬件紧密相关，因此很多类型的内存尺寸也都只是给了一个范围，其实各家IDE（LLVM，GCC，Visaul C++）的实现都是在范围内，具体的实现细节都是不确定的。</p><p>其中bool最小尺寸未定义，char最小尺寸是8位，wchar_t和char16_t的最小尺寸都是16位，char32_t的最小尺寸是32位，int的最小尺寸是16位，long和long long的最小尺寸分别是32位和64位，对于浮点型数据的表现尺寸是按照精度计算的，其中float的最小尺寸精度是小数点后6位(通常占内存32bytes)，double（通常占内存 64bytes）和long double(通常占内存 96~128bytes)的最小尺寸精度则是小数点后10位(实际可能比这个精度要大一些，比如float小数点后有效位为7，double为16)。</p><p>int不得小于short,long不得小于int,long long不得小于long。float,double,long double也应该是精度递增（或者相同）的关系。</p><p>要特别注意的是，<strong>扩展的字符类型</strong>(char16_t，char32_t，wchar_t)<strong>和布尔类型都没有带符号和无符号之分</strong>（尽管它们也确实属于算数类型）。</p><h2 id="类型转换-P32-2-1-2"><a href="#类型转换-P32-2-1-2" class="headerlink" title="类型转换(P32,2.1.2)"></a>类型转换(P32,2.1.2)</h2><p>程序自动执行的类型转换操作发生在程序里IDE预期我们使用A类型但是实际上我们使用B类型的时候，B类型的对象会自动转换为A类型的，如果没法转换，程序就会报错。赋值操作中就可能发生这样的情况。</p><p>我们先看赋值操作里表达式里面发生的自动转换，赋值操作A=B中，等号左边的A被叫做<strong>左值</strong>，B被叫做<strong>右值</strong>，程序期待事情是你给定的右值和左值类型完全相同。如果不相同，这里就会发生<strong>强制的类型转换</strong>，即把B的类型转化为A的类型。如果把一个超出左值类型表达范围的数赋值给左值，左值又是一个无符号类型，比如<code>unsigned char c=-1;</code>这时-1（整型，负的），右值会转化为无符号字符型，初始值对无符号类型表示数值总数取模，然后求余数，这个余数就是转化后的数。</p><p>因为C++没有明确规定有符号类型的数应该如何表示，因此如果把一个超出左值类型表达范围的数赋值给左值，左值又是一个有符号类型，这种行为的结果是不一定的，因为C++标准委员会没有规定这样做之后到底会发生什么，因此各个IDE可能会有不同的实现。我们把这种不确定造成结果的行为叫做<strong>未定义行为</strong>。</p><p><strong>建议：避免无法预知和依赖于环境的行为</strong>。</p><p><strong>提示：切勿混用带符号类型和无符号类型</strong>。</p><h2 id="转义序列-P36，2-1-3"><a href="#转义序列-P36，2-1-3" class="headerlink" title="转义序列(P36，2.1.3)"></a>转义序列(P36，2.1.3)</h2><p>字符的转义序列可以为<code>\</code>后面加上最多3个8进制数字（如果多于3个不会引发报错，多出的部分会被当成字符），或者<code>\x</code>后面加上最多两个16进制数字（多出会报错）。数字转换成10进制后的大小不得超过字符集的限定范围。一般的字面值转义无此限制，不过，一般的字面值的类型是不确定的。10进制数字类型字面值会被转换为能够容纳这个数的带符号整数类型，其他进制中它们则会被转换为能容纳它们的占内存最小的类型的值。</p><p>在最新的C++14标准中，数字字面值里还允许以0b或者0B开头，后面加上二进制数成为二进制字面值。如0B101，代表数字5；0b11，代表数字3。</p><p>指定字面值的常量：当使用一个长整型字面值时，请使用大写字母<code>L</code>来标记，因为小写字母<code>l</code>和数字<code>1</code>太容易混淆了。</p><h2 id="变量-P38"><a href="#变量-P38" class="headerlink" title="变量(P38)"></a>变量(P38)</h2><h3 id="列表初始化"><a href="#列表初始化" class="headerlink" title="列表初始化"></a>列表初始化</h3><p>C++11标准：列表初始化(list initialization)，用一组花括号来初始化变量。下面的第三种：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> units_sold = <span class="number">0</span>;</div><div class="line"><span class="keyword">int</span> units_sold = &#123;<span class="number">0</span>&#125;;</div><div class="line"><span class="keyword">int</span> units_sold&#123;<span class="number">0</span>&#125;;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">units_sold</span><span class="params">(<span class="number">0</span>)</span></span>;</div></pre></td></tr></table></figure></p><h3 id="变量声明和定义的关系"><a href="#变量声明和定义的关系" class="headerlink" title="变量声明和定义的关系"></a>变量声明和定义的关系</h3><p><strong>变量能且只能被定义一次，但是可以被多次声明。</strong>声明变量：在变量名前添加关键字<code>extern</code>，而且不要显示地初始化。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">extern</span> <span class="keyword">int</span> i;        <span class="comment">// 仅仅是声明</span></div><div class="line"><span class="keyword">extern</span> <span class="keyword">int</span> i = <span class="number">0</span>;     <span class="comment">// 声明且定义</span></div><div class="line"></div><div class="line"><span class="keyword">int</span> v;             <span class="comment">// 声明且定义</span></div><div class="line"><span class="keyword">int</span> a = <span class="number">0</span>;        <span class="comment">// 声明且定义</span></div></pre></td></tr></table></figure></p><p>在函数体内部，如果试图初始化一个由extern关键字标记的变量，将引发错误。</p><p>补：</p><blockquote><p>extern外部变量声明其实是在IDE进行编译的时候告诉IDE，这有一个外部变量你要去别的地方找。因此我们应该掌握编译链接这套流程才能够更加方便的会用extern。假设有一个头文件a.h，这个头文件里面定义了int aaa=0;还有一个源文件b.cpp。这个b.cpp里面使用了extern int aaa;这样的语句，那么这个b.cpp是编译不了的。因为头文件如果不被别的源文件引用，是不参与被编译为obj的过程的，一旦它不参与这个过程，它里面声明的aaa这个全局变量其实就不存在，因此在b.cpp里面外部生命一个不存在的变量自然就是非法的。另外，使用extern也要和static做区分并考量它在别的文件中会不会造成内存污染等问题。这里应该掌握分离式编译的编译和链接特性再使用extern比较好。</p></blockquote><p><strong>静态类型</strong>(P42)</p><h3 id="指针与引用"><a href="#指针与引用" class="headerlink" title="指针与引用"></a>指针与引用</h3><p><strong>初始化所有指针</strong>： 初始化为nullptr或0。</p><p><strong>void *指针</strong>(P50)：特殊的指针类型，可以存放任意对象的地址。我们对该指针中到底是个什么类型的对象并不了解。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> *p1,p2;</div></pre></td></tr></table></figure><p>其中，p1是指向int的指针，p2是int。(强调变量具有的复合类型。)</p><p><strong>指向指针的指针</strong>：通过<code>*</code>的个数可以区分指针的级别，即：<code>**</code>表示指向指针的指针，<code>***</code>表示指向指针的指针的指针。</p><p><strong>指向指针的引用</strong>(P52)：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> i = <span class="number">42</span>;</div><div class="line"><span class="keyword">int</span> *p;</div><div class="line"><span class="keyword">int</span> *&amp;r = p; <span class="comment">//r是对指针p的引用</span></div><div class="line"></div><div class="line">r = &amp;i; <span class="comment">//r引用了一个指针，因此给r赋值&amp;i就是令p指向i</span></div><div class="line">*r = <span class="number">0</span>; <span class="comment">//解引用r得到i，也就是p指向的对象，将i的值改为0</span></div></pre></td></tr></table></figure></p><p><font color="00cc00"><strong>面对一条比较复杂的指针或者引用的声明语句时，从右向左阅读有助于弄清楚它的真实含义</strong></font>。<br>离变量名最近的符号（此例中是<code>&amp;r</code>的符号<code>&amp;</code>）对<strong>变量的类型有最直接的影响</strong>，因此<code>r</code>是一个引用。声明符的其余部分用以确定<code>r</code>引用的类型是是什么，此例中的符号<code>*</code>说明<code>r</code>引用的是一个指针。最后，声明的基本数据类型部分指出<code>r</code>引用的是一个<code>int</code>指针。</p><h2 id="顶层const-P57-2-4-3"><a href="#顶层const-P57-2-4-3" class="headerlink" title="顶层const(P57,2.4.3)"></a>顶层const(P57,2.4.3)</h2><p>顶层const是对const而言的，“顶层”可以用来修饰<code>const</code>状态的形容词。一个<code>const</code>使对象本身的值固定，这个<code>const</code>就被称为顶层const;一个<code>const</code>是对象指向或引用的对象成为固定值，这个const就被称为底层const。</p><p>顶层和底层const对拷贝来说密切相关，有相同底层const资格的两个对象才能够互相拷贝，而且顶层const声明变量之后不允许再次改变const的值。<br><code>int p,const int *a＝&amp;p;</code>这种语句中的const就是底层const。<br>像<code>int v1=9;const int *p=&amp;v1;int *p2=p;</code>这种语句如果能够通过编译，那么我们就可以使用p2的性质改变p1指向的常量的值，但是常量的值是不能够被改变的，因此这种变相改变常量的值的表达式都是错误的。可以通过分析const级别得到表达式中常量是否被更改，从而判断语句的正确性。</p><p>说到底，顶层底层说的是对拷贝控制的约束。总的规则就是“不能改变常量的值”。因此“拷入和拷出的对象都要有相同的底层const资格，或者两个对象数据类型必须能转换”，例如，有<code>int *p1,const int *p2;</code>。p1没有底层const,p2有底层const。p1=p2;这时<code>const int*</code>不能转换成<code>int *</code>(如果转换，就违反了“不能改变常量的值这一约束条件”)，因此<code>p1=p2;</code>不合法。<code>p2=p1;``int *</code>能够转换成<code>const int *</code>,因此<code>p2=p1</code>合法。</p><h2 id="constexpr-P58-2-4-4"><a href="#constexpr-P58-2-4-4" class="headerlink" title="constexpr(P58,2.4.4)"></a>constexpr(P58,2.4.4)</h2><p>我们在了解<code>constexpr</code>之前，应该先了解<strong>常量表达式</strong>。所谓常量就是固定的量，那么常量表达式就是值固定不变的表达式，这里“值固定不变”，指的是程序编译阶段，常量表达式的值就能被确定下来之后也不能对其进行任何种方式的修改。因此这个固定，是编译之后固定的。像<code>cout&lt;&lt;1234&lt;&lt;endl;</code>中的1234，就是常量表达式，显然，字面值是常量表达式。</p><p><code>constexpr</code>的作用之一就是帮助程序员在IDE的提示下查看一个赋值语句是不是常量表达式。使用的方式包含在声明语句里面，形如<code>constexpr 变量类型 变量名=右值;</code>如果右值是一个常量，这条语句就是正确的。在所有函数体外声明的全局变量的地址就符合“在编译期间能确定，编译后值不被改变”这两个条件，因此也属于常量。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">constexpr</span> <span class="keyword">int</span> mf = <span class="number">20</span>; <span class="comment">// 20是常量表达式</span></div><div class="line"><span class="keyword">constexpr</span> <span class="keyword">int</span> limit = mf + <span class="number">1</span>; <span class="comment">// mf+1是常量表达式</span></div><div class="line"><span class="keyword">constexpr</span> <span class="keyword">int</span> sz = size(); <span class="comment">//只有当size是一个constexpr函数时，才是一条正确的语句。</span></div></pre></td></tr></table></figure></p><p>另外，用constexpr声明的指针(比如，<code>constexpr int *p=&amp;v1;</code>中的<code>*p</code>，相当于<code>int *const p=&amp;v1;</code>)都是顶层const，即指针本身值固定。但是指针指向的内容是可以变的。引用也一样。</p><p><strong>定义于函数体之外的变量的地址是固定的，可以用来初始化constexpr指针</strong>。</p><p>当你使用constexpr定义引用变量的时候，这个变量引用的对象只能是全局基本数据类型（引用类型除外的）变量（因为要求的内存地址必须是固定不变的）。constexpr引用的结果和正常的引用的结果是一致的，因为引用本身就是固定不变的，因此相当于顶层const修饰的constexpr对引用类型类说没有特殊的意义。 </p><h2 id="类型别名-P61-2-4-4"><a href="#类型别名-P61-2-4-4" class="headerlink" title="类型别名(P61,2.4.4)"></a>类型别名(P61,2.4.4)</h2><p>使用<code>typedef int zhengxing;</code>这种对简单的类型名进行替换的方式无疑是非常直观并且好理解的，但是在涉及到复杂的类型名的时候往往会出现各种各样的问题。</p><p>比如<code>typedef char *Pstring;</code>这条语句是不是就意味着我们看到<code>Pstring</code>就可以用<code>char *</code>替换呢。其实并不是，实际上类型别名不只是替换的规则，而是要复杂很多。</p><p>比如我们遇到<code>const Pstring a;</code>的时候，按照替换的规则，这条语句就相当于<code>const char * a;</code>这里的const这种情况下是底层const，但是结果并不是这样的，这条语句正确的等同语句应该是<code>char *const a;</code>是一个顶层const，即指针本身是一个常量。让我们来分析一下为什么是这个样子，而不是简单的替换就行了。<code>typedef char *Pstring；</code>这条语句就是说<code>Pstring</code>是一个类型别名，它是什么类型的类型别名呢？Pstring是 指向char的指针的类型别名，也就是说，这个类型修饰的对象必须是一个指针，这个指针也必须指向char而不能指向别的什么东西，比如，不能指向<code>const char</code>。我们再看看<code>const Pstring a;</code>这个语句，首先a一定是指向char的指针。所以这个前面的const应该是用来修饰这个指针本身。也就是说，这个指针是<strong>常量指针</strong>而非指向常量的指针。这一点非常重要。</p><p><code>const char * a</code>这个语句里面，实际上类型是<code>const char</code>，<code>*</code>是声明符的一部分。我们说过，定义一个变量由两部分组成，类型名和声明符，声明符可以是<code>*</code>或者<code>&amp;</code>加上变量名的形式。而类型别名只是给类型一个别名，至于声明符是怎样的，不在它修饰的范围内。因此在有const的情况下，就可以看出来这两者之间的区别还是很明显的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">typedef</span> <span class="keyword">char</span> *pstring;</div><div class="line"><span class="keyword">const</span> pstring cstr = <span class="number">0</span>; <span class="comment">//cstr是指向char的常量指针</span></div><div class="line"><span class="keyword">const</span> pstring *ps; <span class="comment">//ps是一个指针，它的对象是指向char的常量指针。</span></div></pre></td></tr></table></figure><p>pstring实际上是指向char的指针，因此，const pstring就是指向char的常量指针。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">const char *cstr = 0; //是对const pstring的错误理解</div></pre></td></tr></table></figure></p><p>数据类型就变成了<code>char</code>，<code>*</code>成为了声明符的一部分。这样改写的结果是，<code>const char</code>成了基本数据类型。cstr是一个指针，指向了常量字符。</p><h2 id="auto类型声明符-P61-2-5-2"><a href="#auto类型声明符-P61-2-5-2" class="headerlink" title="auto类型声明符(P61,2.5.2)"></a>auto类型声明符(P61,2.5.2)</h2><p>C++11中引入的auto主要有两种用途：自动类型推断和返回值占位。auto在C++98中的标识临时变量的语义，由于使用极少且多余，在C++11中已被删除。前后两个标准的auto，完全是两个概念。</p><p><code>auto</code>变量通过初始化语句，计算出右值的类型，并推导出左值的类型。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> i=<span class="number">0</span>, &amp;r = i;</div><div class="line"><span class="keyword">auto</span> a = r; <span class="comment">// a是一个整数（r是i的别名，而i是一个整数）</span></div></pre></td></tr></table></figure></p><p>这个过程中auto将会忽视顶层const和引用类型，可用<code>const auto &amp;a=i;</code>这种方式显式地指出了：指出要推导的结果是带顶层指针属性的或者是引用属性的。</p><p>auto推导多个值时，这些值的类型必须是一样的。因为auto是利用初始化赋值，因此它的行为基本上也和初始化有关。</p><p>关于auto的更多用法：<a href="http://blog.csdn.net/zxh2075/article/details/9235591" target="_blank" rel="external">【C++11】新特性——auto的使用</a></p><h2 id="decltype类型指示符-P62-2-5-3"><a href="#decltype类型指示符-P62-2-5-3" class="headerlink" title="decltype类型指示符(P62,2.5.3)"></a>decltype类型指示符(P62,2.5.3)</h2><p>有时候会遇到这种情况：希望从表达式的类型推断出要定义的变量的类型，但是不想用该表达式的值初始化变量。为此，C++11新标准引入第二种类型说明符<code>decltype</code>。</p><p><code>decltype</code>不通过计算，只通过推算出变量应有的值，表达式本身应有的值和函数的返回值来<strong>推导类型</strong>。</p><p>对于变量类型，<code>decltype</code>保留顶层const和引用的属性。对于表达式，<strong>解引用表达式(如:<code>int i=1; int *p=&amp;i; decltype (*p) a=i;</code>中的<code>*p</code>,对p解引用是<code>int &amp;</code>类型的)和带括号的表达式，（如：<code>decltype ((a+1)) c=i;</code>）的结果都将是引用类型</strong>。因为decltype通过处理表达式得到结果，因此更详细的内容在<em>第四章</em>将会被提到。有的表达式返回左值，有的表达式返回右值，返回左值的表达式在decltype类型推导下得到的将是引用的结果。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> i = <span class="number">42</span>,*p = &amp;i, &amp;r = i;</div><div class="line"><span class="keyword">decltype</span>(r + <span class="number">0</span>) b; <span class="comment">//正确，加法结果为int，因此b是一个（未初始化的）int</span></div><div class="line"><span class="keyword">decltype</span>(*p) c; <span class="comment">//错误，c是int&amp;，必须初始化</span></div><div class="line"><span class="keyword">decltype</span>((i)) d; <span class="comment">//错误，c是int&amp;，必须初始化</span></div><div class="line"><span class="keyword">decltype</span>(i) e; <span class="comment">//正确，e是一个（未初始化的）int</span></div></pre></td></tr></table></figure></p><blockquote><p><strong>decltype((variable)) (注意是双层括号)的结果永远是引用</strong>，而decltype(variable)结果只有当variable本身就是一个引用时才是引用。</p></blockquote><p>补：</p><ol><li><p>一般情况下，出现数组名的表达式时会把数组名转换为<strong>指针</strong>，而用decltype一个数组名时，其返回类型是<strong>该数组的类型</strong>，如有int ia[10]，则<code>decltype(ia) da</code>，此时da也为包含10个int元素的数组。用于函数时也一样，不会自动把函数名转换为指针，而是返回该函数类型。</p></li><li><p>如果作用于一个取地址运算符，则为指向指针的指针，如有int p，则<code>decltype(&amp;p)</code>的结果是<code>int **</code>类型。</p></li></ol><h2 id="用关键字struct自定义数据结构"><a href="#用关键字struct自定义数据结构" class="headerlink" title="用关键字struct自定义数据结构"></a>用关键字struct自定义数据结构</h2><p>使用struct关键字定义类的形式如<code>struct 类名｛数据成员类型1 数据成员名1；数据成员类型2 数据成员名2;｝;</code>，C++11规定可以给类内成员提供类内初始值用于初始化用我们自定义类创建的对象实例中的成员的值。形式如下：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">MyClass</span></span></div><div class="line"><span class="class">&#123;</span></div><div class="line">    <span class="keyword">int</span> student=<span class="number">0</span>;</div><div class="line">    <span class="keyword">float</span> numbers=<span class="number">1</span>;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p><blockquote><p> 很多新手程序员忘记在类定义的最后加上分号。</p></blockquote><h2 id="头文件保护符"><a href="#头文件保护符" class="headerlink" title="头文件保护符"></a>头文件保护符</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> SALES_DATA_H</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> SALES_DATA_H</span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Sales_data</span>&#123;</span></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> bookNo;</div><div class="line">    <span class="keyword">unsigned</span> units_sold = <span class="number">0</span>;</div><div class="line">    <span class="keyword">double</span> revenue = <span class="number">0.0</span>;</div><div class="line">&#125;;</div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div></pre></td></tr></table></figure><p>头文件保护符依赖于预处理变量。如<code>#define DEBUG</code>，此时<code>DEBUG</code>就是预处理器变量。预处理变量无视C++语言中关于作用域的规则。</p><blockquote><p>头文件保护符很简单， 程序员只要<strong>习惯性加上</strong>就可以了，没必要太在乎你的程序到底需不需要。</p></blockquote><h2 id="专业术语"><a href="#专业术语" class="headerlink" title="专业术语"></a>专业术语</h2><p>1.算数类型 arithmetic type<br>2.整型 integral type<br>3.转换 convert<br>4.不可打印 nonprintable<br>5.转义序列 escape sequence<br>6.类型说明符 type specifier<br>7.分离式编译 separate compilation<br>8.声明 declaration<br>9.声明符 declarator<br>10.静态类型 statically typed<br>11.类型检查 type checking<br>12.标识符 identifier<br>13.内层作用域 inner scope<br>14.复合类型 compound type<br>15.左值引用 lvalue reference<br>16.预处理 preprocessor<br>17.临时量 temporary<br>18.指向常量的指针 pointer to const<br>19.常量指针 const pointer<br>20.字面值类型 literal type<br>21.类型别名 type alias<br>22.类内初始值 in-class initializer<br>23.预处理器 preprocessor<br>24.头文件保护符 header guard</p>]]></content:encoded>
      
      <comments>http://wangwlj.com/2017/12/25/CPP_01_02/#disqus_thread</comments>
    </item>
    
    <item>
      <title>photoshop白色背景图片转换为透明背景</title>
      <link>http://wangwlj.com/2017/12/21/ps_white2transparent/</link>
      <guid>http://wangwlj.com/2017/12/21/ps_white2transparent/</guid>
      <pubDate>Thu, 21 Dec 2017 13:45:58 GMT</pubDate>
      <description>
      
        &lt;p&gt;1.打开Adobe Photoshop以及待处理的图片，如果图层上有“锁”的标志，就双击进行解锁；&lt;br&gt;&lt;img src=&quot;https://images2.imgbox.com/4e/6d/W7BRQIVn_o.png&quot; alt=&quot;1&quot;&gt;&lt;/p&gt;
      
      </description>
      
      <content:encoded><![CDATA[<p>1.打开Adobe Photoshop以及待处理的图片，如果图层上有“锁”的标志，就双击进行解锁；<br><img src="https://images2.imgbox.com/4e/6d/W7BRQIVn_o.png" alt="1"></p><a id="more"></a><p>2.在图层上右击，选择最上方的“混合选项”；<br><img src="https://images2.imgbox.com/40/79/k93NwYyF_o.png" alt=""></p><p>3.在混合选项中的本图层中，拖动右侧的白色小三角，向左滑动至适当位置。<br><img src="https://images2.imgbox.com/e4/a0/9gpxW33B_o.png" alt=""></p><p>4.效果展示。滑动之前的效果：<br><img src="https://images2.imgbox.com/93/b7/CRkJk51e_o.jpg" alt=""><br>滑动之后的效果：<br><img src="https://images2.imgbox.com/64/5c/lcI8vPjg_o.jpg" alt=""></p><p>5.存储。选择“文件”中的“存储为”；<br><img src="https://images2.imgbox.com/90/bf/osDfROqU_o.png" alt=""></p><p>在弹出窗口中选择保存类型为“PNG”格式，保存即可。也可以根据需要，选择合适的格式。<br><img src="https://images2.imgbox.com/18/da/M04vdmM2_o.png" alt=""></p><p>最后附上全文的<a href="https://wx3.sinaimg.cn/mw1024/c38a0784ly1fmop679zh6j215z2sn7wh.jpg" target="_blank" rel="external">图片链接</a>。</p>]]></content:encoded>
      
      <comments>http://wangwlj.com/2017/12/21/ps_white2transparent/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
