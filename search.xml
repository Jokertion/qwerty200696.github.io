<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[windows下的部分小技巧整理]]></title>
    <url>%2F2017%2F12%2F29%2Fpractical_tricks%2F</url>
    <content type="text"><![CDATA[本文主要是电脑使用中的一些小技巧的整理。主要包括： 电脑常用的部分快捷键 批处理乱码问题 Photoshop文字添加、删除与旋转 VMbox虚拟机问题 电脑操作打开“我的电脑”的快捷键winkey +E :打开我的电脑（资源管理器）。winkey指的是键盘上刻有windows徽标的键，就是左边ctrl 和alt中间那个(window标志)。 其他常用键组合： winkey + d :这是高手最常用的第一快捷组合键。这个快捷键组合可以将桌面上的所有窗口瞬间最小化，无论是聊天的窗口还是游戏的窗口……只要再次按下这个组合键，刚才的所有窗口都回来了，而且激活的也正是你最小化之前在使用的窗口！ winkey + r :在我们的文章中，你经常会看到这样的操作提示:“点击‘开始→运行’，打开‘运行’对话框……”。其实，还有一个更简单的办法，就是按winkey + r！ alt + tab 或者 winkey + tab:如果打开的窗口太多，这个组合键就非常有用了，它可以在一个窗口中显示当前打开的所有窗口的名称和图标，选中自己希望要打开的窗口，松开这个组合键就可以了。而alt+tab+shift键则可以反向显示当前打开的窗口。 ALT + F4 ：关闭当前应用程序 PRINT SCREEN :将当前屏幕以图象方式拷贝到剪贴板 更多快捷键可参考：https://zhidao.baidu.com/question/100107981.html 复制一个当前文件夹窗口的快捷键Ctrl + N 批量查看照片尺寸在空白的地方右击，选择查看——详细信息; 照片就以列表的形式摆放了，但没有尺寸大小的信息~ 再次在空白处右击，选择排列方式——更多， 将滑块往下滑动，找到尺寸，打上勾，按确定~ 照片的尺寸信息就出现了~ 若没有理解清楚，详细图文教程可参考：如何批量查看照片的尺寸 awesomiumProcess是什么进程在Windows任务管理器中的相应进程上右键–打开文件位置，发现是MarkDownPad2自带的程序。 推广一下，就是手动查看进程中是否存在可疑程序。。。 批处理批处理脚本bat中文乱码面对这个情况是编码不同问题，所以在最开始就应该把编码修正，支持中文的编码是ANSI。 我们第一步是新建一个txt文件。用记事本打开，将原来的bat文件内容拷贝过来，然后选择“文件”=&gt;“另存为”。 cmd中的编码方式为ANSI，若中文不是此编码方式则会出现乱码。所以我们在编码的时候选择“ANSI”。 photoshopps修改图片上的文字删去文字先选择图层，再选择一个区域后，按delete删除。 取消当前图层的选区： ctrl + D参考自：ps取消选区快捷键 添加横的文字选择添加文本的按钮输入文字，但是不可以旋转（我要变成竖直的文字）。 按组合键Ctrl + T或者点击编辑菜单下的【自由变换】，进入文字调整。具体参考：ps怎么旋转一个字体 vbox虚拟机无法启动E_FAIL (0x80004005)版本问题。回退到4.3.12之前。新版本问题多多。具体参考：Oracle VM VirtualBox 虚拟机 启动报错代码:E_FAIL (0x80004005) VirtualBox显示模式切换热键初用VirtualBox, 几个显示切换快捷键还是要记一下的: Right Ctrl + F – 切换到全屏模式Right Ctrl + L – 切换到无缝模式Right Ctrl + C – 切换到比例模式Right Ctrl + Home – 显示控制菜单 无缝模式是灰色的，怎么办安装增强模式。相当于VMware里面的”VMware Tools”。]]></content>
      <categories>
        <category>Photoshop</category>
      </categories>
      <tags>
        <tag>Photoshop</tag>
        <tag>VMbox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的部分tricks整理]]></title>
    <url>%2F2017%2F12%2F29%2Fpython_tricks%2F</url>
    <content type="text"><![CDATA[本文整理了本人遇到的一些tricks。主要包括： pycharm快捷键整理 爬虫中的日志记录(logging)、取消SSL警告、字符过滤(re.sub)与查找(find)、文件删除(os)与文件保存(pickle)、词云(wordcloud)的使用 图像处理的部分基本操作(PIL,numpy)。 0 pycharm 快捷键注释/反注释 Ctrl+斜杠，也就是 Ctrl + / 注释与反注释都是这个组合键。 块注释Ctrl+Shift+斜杠 格式化代码ctrl + alt + F: 格式化代码(用了JetBrains的IDE之后就习惯性地格式化一下)，代码规范化。 复制当前行Ctrl + D复制当前行 另起一行shift + enter : 向下另起一行，光标在行内任意位置都能另起一行，且不破坏当行结构ctrl + alt + enter : 向上另起一行 查看注释Ctrl + q: help 查注释，查询documentation 搜索功能ctrl + shift + a : 搜索功能: 搜索IDE功能，比如想看看这个文件的历史，就键入history 可以找到 Local history 万能提示键ctrl + alt + space: 万能提示键(在Keymap中搜索basic可以找到并修改它)PyCharm的会根据上下文提供补全。 run相关的快捷键根据具体设置可能略有差异，笔者采用的是VS风格（可在File-&gt;Settings-&gt;Keymap中设置）的快捷键。ctrl + F9 : run the current file （跑当前页面的程序）F9 : resume the program (中断后)重新开始程序ctrl + F5: run the specific program(直接跑上一个程序)F5： debug（弹出debug目录，自行选择运行的文件）alt + shift + F10 : 运行程序（弹出run目录） 其他技巧ctrl + shift + 数字键 与 ctrl + 数字键 : 书签功能Ctrl + 鼠标点击 ： 查看内置函数啥的alt + 上下箭头 : preview/next method (def/class)debug的时候可以在断点打开Python console然后改变量值Ctrl+ B和shift + →，查看源码时很方便，至少在vim下看库的源码没那么容易。对Python程序员而言，看源码很重要shift + F6 : 重命名，这太重要了，vim没有吧。即使有，那它也没法重构Flask和Django的template下的指令吧。 1 python信息同时输出到控制台与文件1.1 问题python编程中，往往需要将结果用print等输出，如果希望输出既可以显示到IDE的屏幕上，也能存到文件中（如txt）中，该怎么办呢？ 1.2 解决方案可通过日志logging模块输出信息到文件或屏幕。但可能要设置log的level或输出端，对于同时需要记录debug error等信息的较为合适，官方教程推荐学习用更规范的logger来操作。例如,可参考来自官网的这段代码。12345import logging logging.basicConfig(filename='log_examp.log',level=logging.DEBUG) logging.debug('This message should go to the log file') logging.info('So should this') logging.warning('And this, too') 其中的level=logging.DEBUG会显示Debug调试信息，若想显示普通的输出信息，可以换成level=logging.INFO。 程度 使用场景 DEBUG 获得诊断问题是具体的信息 INFO 确认程序是否按正常工作 WARNING 在程序还正常运行时获取发生的意外的信息，这可能会在之后引发异常（例如磁盘空间不足） ERROR 获取程序某些功能无法正常调用这类严重异常的信息 CRITICAL 获取程序无法继续运行的这类最严重异常信息 1.3 改变默认输出信息的格式1234import logging# output format: output time - logging level - log messageslogging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s')logging.warning('This message will appear in python console.') 在python console中直接打印以下输出： 12016-8-2 2:59:11, 510 - WARNING - This message will appear in python console 2 Python中将打印输出导向日志文件利用sys.stdout将print行导向到你定义的日志文件中，例如： 123456789101112131415161718import sys# make a copy of original stdout routestdout_backup = sys.stdout# define the log file that receives your log infolog_file = open("message.log", "w")# redirect print output to log filesys.stdout = log_fileprint "Now all print info will be written to message.log"# any command line that you will execute...log_file.close()# restore the output to initial patternsys.stdout = stdout_backupprint "Now this will be presented on screen" 这样子只会打印到日志文件，而控制台没有输出了，笔者一般不采用这种方法。 3 python3使用requests请求HTTPS取消SSL验证警告3.1 问题描述使用requests库请求HTTPS时,因为忽略证书验证,导致每次运行时都会报错（警告）:12D:\python\Python35\lib\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings InsecureRequestWarning) 3.2 解决方法 虽然这并不影响结果的正确，但是这个提示一直存在，看着是真的别扭，尤其需要输出到报告或者是日志的时候。代码加入下面两行，取消这个警告。 添加如下的这两行代码： 123from requests.packages.urllib3.exceptions import InsecureRequestWarning requests.packages.urllib3.disable_warnings(InsecureRequestWarning) python3也可以的。我的pycharm中会显示找不到该库，不过没问题，依旧可以跑，应该是pycharm本身的问题。 4. python过滤中文、英文标点特殊符号4.1 垃圾邮件过滤实例下面是一封垃圾邮件的过滤实例： 1&quot;想做/ 兼_职/学生_/ 的 、加,我Q： 1 5. 8 0. ！！？？ 8 6 。0. 2。 3 有,惊,喜,哦&quot; 邮件中的“！？。、”都是中文的，而“/.”是英文的 下面是采用re正则项过滤方式： 123456import retemp = "想做/ 兼_职/学生_/ 的 、加,我Q： 1 5. 8 0. ！！？？ 8 6 。0. 2。 3 有,惊,喜,哦"temp = temp.decode("utf8") string = re.sub("[\s+\.\!\/_,$%^*(+\"\']+|[+——！，。？、~@#￥%……&amp;*（）]+", "", temp) # 将temp中若存在的前面的这一长串替换为空的。print(string) 4.2 目录名称过滤实例此外，比如说目录命名时，也需要过滤掉/|等，如下：12dirName = re.sub("[\s+\.\!\/_,$%^*(+\"\'?]+|[+——！，。？、~@#￥%……&amp;*（）]+", "", dirName)os.mkdir(dirName) 5. Markdown之表格table的处理插入表格代码如下：12345678910&lt;table class="table table-bordered table-striped table-condensed"&gt; &lt;tr&gt; &lt;td&gt;北京&lt;/td&gt; &lt;td&gt;雾霾&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;深圳&lt;/td&gt; &lt;td&gt;暴雨&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; 发现table加了个class属性，如果只是table标签 将不起作用。 table-bordered：带圆角边框和竖线 table-striped：奇偶行颜色不同 table-condensed：压缩行距 除了以上另外还有其他可供选择： 1、如果需要表头跟内容不一样，可以将&lt;td&gt;表头内容&lt;/td&gt;换成&lt;th&gt;表头内容&lt;/th&gt;。 2、如果表格内文需要换行，可以在要换行的内容后加入&lt;br&gt;，后面的内容就会跑到下一行。 3、如果内文中有代码，需要特别显示，可使用：&lt;code&gt;代码&lt;/code&gt;。 4、如果表格中有需要设为斜体的内容，可使用：&lt;I&gt;要设为斜体的内容&lt;/I&gt;。 5、如果有跨行或者跨列的单元格，可用&lt;th colspan=&quot;跨列数&quot;&gt;内容&lt;/th&gt;或rowspan。 6、如果要调整某一列的宽度，可使用：&lt;th width=&quot;宽度值或百分比&quot;&gt;表头内容&lt;/th&gt;。 6. 用numpy打开图像和保存图像123456789# -*- coding: utf-8 -*- from PIL import Image from pylab import * from PCV.tools import imtools import numpy im = array(Image.open('C:/pic/train2/1.jpg').convert('L')) # 打开图像，并转成灰度图像 img11=Image.fromarray(uint8(im)) img11.save("C:/pic/train2/10.jpg")# 保存灰度图像 补充用opencv打开和保存图像： 12345#coding=utf-8 import cv2 img = cv2.imread("C:/pic/train1/2.jpg", 0) cv2.imwrite('C:/pic/1/5.jpg',img) 7. PIL.Image转换为OpenCV支持的Image格式可参考：http://www.mobibrw.com/2017/7381 后来放弃了。不太方便。 8. 使用pickle把数据保存到文件8.1 实例一使用pickle模块从文件中重构python对象。1234567891011import pprint, picklepkl_file = open('data.pkl', 'rb')data1 = pickle.load(pkl_file)pprint.pprint(data1)data2 = pickle.load(pkl_file)pprint.pprint(data2)pkl_file.close() 8.2 实例二其中，friend是从网页获得的数据，先保存下来，以备后续处理。1234567# 获取好友列表friends = itchat.get_friends(update=True)[0:]output = open('data.pkl', 'wb')# Pickle dictionary using protocol 0.pickle.dump(friends, output)output.close() 读取保存的文件，用于后续处理。 1234import pickle, repkl_file = open('data.pkl', 'rb')friends = pickle.load(pkl_file) 9. 解决Python词云库wordcloud不显示中文的问题9.1 安装安装命令： pip install wordcloud 9.2 解决方案实例代码：123456789101112131415161718192021222324252627282930313233343536373839# -*- coding: utf-8 -*-from wordcloud import WordCloudimport matplotlib.pyplot as plttext = '''文案 文案The 抱抱 Zen of LOVE 抱抱 Python, 快乐 by Tim Peters公众号 公众号 Python 最好的 语言 语言一辈子 is better LOVE than 一辈子.喵小姐 is 爱你 than implicit.爱你 喵小姐蟹先生 is 爱你 than complex.一辈子 is 蟹先生 than complicated.二中 is 喵小姐 我想你了 than nested. 二中 蟹先生清湖 is 胜于 than 清湖.思旺 counts. 想你Special 喵小姐 我想你了 aren't special enough 思旺 break 思旺 rules.别生气 practicality beats 厨艺好.Errors should 我想你了 never pass 小龙虾 silently. 运营别生气 explicitly 好不好. LOVEIn the face of ambiguity, 程序员 the 厨艺好 to guess.龙华 龙华There 快乐 should be one-- 我想你了 and preferably 红烧肉 only one 小龙虾--obvious way to do it.运营Although 共享单车 way may not 我想你了 be obvious at first unless you're Dutch. 新媒体 地铁Now is better 红烧肉 than never.程序员 Although 共享单车 is often 高铁 than 东莞 now. 高铁 地铁If the implementation 想你 is hard to explain, it's a bad idea. 想你了If 成都 implementation is 想你 easy to explain, it may be a good idea.Namespaces are 端午one 端午 honking great idea -- 成都 do more of those! 想你了深圳 晚安 深圳 新媒体'''# the font from github: https://github.com/adobe-fontsfont = r'C:\Windows\Fonts\simfang.ttf'wc = WordCloud(collocations=False, font_path=font, width=1400, height=1400, margin=2).generate(text.lower())plt.imshow(wc)plt.axis("off")plt.show()wc.to_file('show_Chinese.png') # 把词云保存下来 10. PIL库图片基本操作1.打开图片12import Imageimg=Image.open("code.jpg") 注：有些图片名称是包含中文的，就需要在“”前加上u，例：1img=Image.open(u"阿布.jpg") 2.展示图片 1img.show() 3.保存图片1img.save("img1.png","png") 说明：img为一个图片，存为一个名叫img1的图片，格式为png。后面的png不写也可以，直接按照文件名的后缀.png存为相应格式了。 4.旋转图片rotate fixedIm=img.rotate(90) fixedIm.save(&quot;fixedIm.png&quot;,&quot;png&quot;) 说明：fixedIm=img.rotate(90)，将图片img逆时针旋转90度，存到fixedIm中。 更多操作可参考:http://www.cnblogs.com/meitian/p/3699223.html python删除文件1234567import os # 删除文件： os.remove()#删除空目录： os.rmdir() # 递归删除空目录： os.removedirs() 递归删除目录和文件（类似DOS命令DeleteTree）：12345678910# Delete everything reachable from the directory named in 'top',# assuming there are no symbolic links.# CAUTION: This is dangerous! For example, if top == '/', it# could delete all your disk files.import osfor root, dirs, files in os.walk(top, topdown=False): for name in files: os.remove(os.path.join(root, name)) for name in dirs: os.rmdir(os.path.join(root, name)) 参考自：python 删除文件 Python3 find()方法描述find()方法检测字符串中是否包含子字符串str，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，如果指定范围内如果包含指定索引值，返回的是索引值在字符串中的起始位置。如果不包含索引值，返回-1。 语法find()方法语法： str.find(str, beg=0, end=len(string)) 参数str：指定检索的字符串beg：开始索引，默认为0。end：结束索引，默认为字符串的长度。 返回值如果包含子字符串返回开始的索引值，否则返回-1。 实例以下实例展示了find()方法的实例(Python 3.0+)： 12345678#!/usr/bin/python3 str1 = "Runoob example....wow!!!"str2 = "exam"; print (str1.find(str2))print (str1.find(str2, 5))print (str1.find(str2, 10)) 以上实例输出结果如下： 7 7 -1 实例(Python 3.0+)12345678&gt;&gt;&gt;info = 'abca'&gt;&gt;&gt; print(info.find('a')) # 从下标0开始，查找在字符串里第一个出现的子串，返回结果：00&gt;&gt;&gt; print(info.find('a', 1)) # 从下标1开始，查找在字符串里第一个出现的子串：返回结果33&gt;&gt;&gt; print(info.find('3')) # 查找不到返回-1-1&gt;&gt;&gt; 参考资料 python 信息同时输出到控制台与文件 Python中将打印输出导向日志文件 python requests报错InsecureRequestWarning的解决方案 Python requests移除SSL认证，控制台输出InsecureRequestWarning取消方法 python 过滤中文、英文标点特殊符号 Markdown之表格table的处理 用numpy打开图像和保存图像 pickle模块的基本使用 词云库wordcloud显示中文 Python3 find()方法]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pycharm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow基础篇与搭建深层神经网络]]></title>
    <url>%2F2017%2F12%2F28%2Ftensorflow_base%2F</url>
    <content type="text"><![CDATA[本文是 Tensorflow：实战Google深度学习框架的第三章与第四章。 第3章 TensorFlow入门0.1 查看已安装tensorflow版本由于tensorflow版本不同,可能一些函数的调用也有变换,这时候可能需要查看tensorflow版本,可以在终端输入查询命令如下:123python //windows下cmd进入python环境，linux下终端类似import tensorflow as tftf.__version__ 查询tensorflow安装路径为:1tf.__path__ 参考自：查看已安装tensorflow版本 0.2 Tensorflow：实战Google深度学习框架 源码下载 Tensorflow：实战Google深度学习框架 caicloud/tensorflow-tutorial 3.2 TensorFlow数据模型——张量3.2.1 张量的概念一个张量中主要保存了三个属性：名字（name）、维度（shape）、类型（type）。 3.2.2 张量的使用两大类。 一是对中间结果的引用。 二是用来获得计算的结果。tf.Session().run(result) 3.3 TensorFlow运行模型——会话3.3.1 创建和关闭会话# 创建一个会话。 sess = tf.Session() # 使用会话得到之前计算的结果。 print(sess.run(result)) # 关闭会话使得本次运行中使用到的资源可以被释放。 sess.close() 3.3.2 使用with statement 来创建会话with tf.Session() as sess: print(sess.run(result)) # 下面的两个命令有相同的功能。 print(sess.run(result)) print(result.eval(session=sess)) 3.3.3 指定默认会话sess = tf.Session() # 下面的两个命令有相同的功能。 print(sess.run(result)) print(result.eval(session=sess)) 3.3.4 通过ConfigProto配置会话config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True) sess1 = tf.InteractiveSession(config=config) sess2 = tf.Session(config=config) 3.4 TensorFlow实现神经网络3.4.2 前向传播算法简介tf.matmul 矩阵乘法 3.4.3 神经网络参数与tensorflow变量weights = tf.Variable(tf.random_normal([2, 3], stddev=2)) 产生一个[2,3]的矩阵，矩阵中元素是均值为0，方差为2的随机数。 1.TensorFlow随机数生成函数 函数名称 随机数分布 主要参数 tf.random_normal 正态分布 平均值、标准差、取值类型 tf.truncated_normal 正太分布,但如果随机出来的值离平均值超过2个标准差，那么这个数将会被重新随机 平均值、标准差、取值类型 tf.random_uniform 平均分布 最小、最大取值、取值类型 tf.random_gramma Gramma分布 形状参数alpha、尺度参数beta、取值类型 2.TensorFlow常数生成函数 函数名称 功能 样例 tf.zeros/td&gt; 产生全0的数组 tf.zeros([2,3],int32)-&gt;[[0,0,0],[0,0,0]] tf.ones 产生全1的数组 tf.ones([2,3],int32)-&gt;[[1,1,1],[1,1,1]] tf.fill 产生一个全部为给定数字的数组 tf.fill([2,3],9)-&gt;[[9,9,9],[9,9,9]] tf.constant 产生一个给定值的常量 tf.constant([1,2,3])-&gt;[1,2,3] 声明了变量之后，程序的第二步会声明一个会话（session）。并通过会话计算结果。 在真正开始计算之前，必须对变量进行初始化： init_op = tf.global_variables_initializer() sess.run(init_op) 变量分为需要优化的参数（比如神经网络中的参数）和其他参数。trainable = True，则该变量会加入GraphKeys.TRAINABLE_VARIABLES集合。 维度（shape）和类型（type）是变量最重要的两个属性。 3.4.4 通过tensorflow训练神经网络模型监督学习的思想。 神经网络优化算法中，最常用的是反向传播算法。 x = tf.constant([[0.7, 0.9]]) 常量表示样例导致计算图特变大。使用placeholder机制提供输入数据。 在placeholder定义的时候，这个位置上的数据类型是需要指定的。和其他张量一样，placeholder的类型不可以被改变。 x = tf.placeholder(tf.float32, shape=(1, 2), name=&quot;input&quot;) a = tf.matmul(x, w1) y = tf.matmul(a, w2) sess = tf.Session() init_op = tf.global_variables_initializer() sess.run(init_op) print(sess.run(y, feed_dict={x: [[0.7, 0.9]]})) feed_dict时一个字典（map），在字典中需要给出每个用到的placeholder的取值，否则运行会报错。 输入的数据一般是一个batch，不止一个，placeholder也支持输入多个数据。 x = tf.placeholder(tf.float32, shape=(3, 2), name=&quot;input&quot;) a = tf.matmul(x, w1) y = tf.matmul(a, w2) sess = tf.Session() #使用tf.global_variables_initializer()来初始化所有的变量 init_op = tf.global_variables_initializer() sess.run(init_op) print(sess.run(y, feed_dict={x: [[0.7,0.9],[0.1,0.4],[0.5,0.8]]})) 在得到一个batch的前向传播结果之后，需要定义一个损失函数来刻画当前的预测值与真实答案之间的差距。然后通过反向传播算法来调整网络参数之间的取值使得差距可以被缩小。 3.4.5 完整的神经网络样例程序import tensorflow as tf from numpy.random import RandomState # 1. 定义神经网络的参数，输入和输出节点。 batch_size = 8 w1 = tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1)) w2 = tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1)) x = tf.placeholder(tf.float32, shape=(None, 2), name=&quot;x-input&quot;) y_ = tf.placeholder(tf.float32, shape=(None, 1), name=&apos;y-input&apos;) # 2. 定义前向传播过程，损失函数及反向传播算法。 a = tf.matmul(x, w1) y = tf.matmul(a, w2) # tf.clip_by_value(A, min, max)：输入一个张量A，把A中的每一个元素的值都压缩在min和max之间。小于min的让它等于min，大于max的元素的值等于max。 cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0))) train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy) # 3. 生成模拟数据集。 rdm = RandomState(1) dataset_size = 128 X = rdm.rand(dataset_size, 2) Y = [[int(x1 + x2 &lt; 1)] for (x1, x2) in X] # 4. 创建一个会话来运行TensorFlow程序。 with tf.Session() as sess: init_op = tf.global_variables_initializer() sess.run(init_op) # 输出目前（未经训练）的参数取值。 print(&quot;w1:&quot;, sess.run(w1)) print(&quot;w2:&quot;, sess.run(w2)) print(&quot;\n&quot;) # 训练模型。 STEPS = 5000 # 设定训练的轮数 for i in range(STEPS): start = (i * batch_size) % 128 end = (i * batch_size) % 128 + batch_size sess.run(train_step, feed_dict={x: X[start:end], y_: Y[start:end]}) if i % 1000 == 0: total_cross_entropy = sess.run(cross_entropy, feed_dict={x: X, y_: Y}) print(&quot;After %d training step(s), cross entropy on all data is %g&quot; % (i, total_cross_entropy)) # 输出训练后的参数取值。 print(&quot;\n&quot;) print(&quot;w1:&quot;, sess.run(w1)) print(&quot;w2:&quot;, sess.run(w2)) 输出为： 训练之前的神经网络的参数值： w1: [[-0.81131822 1.48459876 0.06532937] [-2.4427042 0.0992484 0.59122431]] w2: [[-0.81131822] [ 1.48459876] [ 0.06532937]] 可以发现，随着训练的进行，交叉熵是逐渐减小的。交叉熵越小说明预测的结果和真实的结果差距越小。 After 0 training step(s), cross entropy on all data is 0.0674925 After 1000 training step(s), cross entropy on all data is 0.0163385 After 2000 training step(s), cross entropy on all data is 0.00907547 After 3000 training step(s), cross entropy on all data is 0.00714436 After 4000 training step(s), cross entropy on all data is 0.00578471 训练之后的神经网络的参数值： w1: [[-1.9618274 2.58235407 1.68203783] [-3.46817183 1.06982327 2.11789012]] w2: [[-1.82471502] [ 2.68546653] [ 1.41819513]] 第4章 深层神经网络4.1 深度学习与深层神经网络4.1.1 线性模型的局限性4.1.2 激活函数实现去线性化激活函数：tf.nn.relu、tf.sigmoid和tf.tanh。 4.1.3 多层网络解决异或运算单层感知机无法模拟异或运算。加入了隐含层之后，就可以解决异或问题。 4.2损失函数的定义4.2.1 经典损失函数交叉熵(cross entropy)。用q来表示p的交叉熵为：$$H(p,q)=-\sum_x p(x)\text{log} q(x)$$ p代表的是正确答案，q代表的是预测值。交叉熵刻画的是两个概率分布的距离，也就是说交叉熵越小，两个概率分布越接近。 softmax回归：将神经网络的输出变成一个概率分布。 交叉熵的代码实现： cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0))) 其中，tf.clip_by_value的用法 tf.clip_by_value(A, min, max)：输入一个张量A，把A中的每一个元素的值都压缩在min和max之间。小于min的让它等于min，大于max的元素的值等于max。 import tensorflow as tf; import numpy as np; A = np.array([[1,1,2,4], [3,4,8,5]]) with tf.Session() as sess: print sess.run(tf.clip_by_value(A, 2, 5)) 输出： [[2 2 2 4] [3 4 5 5]] tf.log是对张量中所有元素依次求对数。 *操作是元素之间直接相乘，矩阵乘法是tf.matmul。 上面三个计算得到的结果是nxm的矩阵。 tf.reduce_mean的用法。 v = tf.constant([[1.0, 2.0, 3.0, 4.0], [4.0, 5.0, 6.0, 7.0]]) sess = tf.Session() init_op = tf.global_variables_initializer() sess.run(init_op) print(tf.reduce_mean(v).eval(session=sess)) # 程序输出为：4.0 = sum/8 4.2.2 自定义损失函数当然tensorflow也支持自定义损失函数。 4.3 神经网络优化算法假设用$\theta$表示神经网络中的参数，$J(\theta)$表示在给定的参数取值下，训练集上损失函数的大小，那么整个优化过程可以抽象为：寻找一个参数$\theta$，使得$J(\theta)$最小。 对于参数$\theta$，其梯度为$\frac{\partial}{\partial\theta}J(\theta)$。有了梯度，还需要学习率$\eta $(learning rate)来控制每次参数更新的幅度。因此，参数更新的公式为：$$\theta_{n+1} = \theta_n - \eta \frac{\partial}{\partial\theta}J(\theta)$$ 需要注意的是梯度下降算法并不能保证达到全局最优解，此外还存在计算时间过长的问题。 为了加速训练过程，可以使用随机梯度下降(stochastic gradient descent)算法。每一轮迭代中随机优化某一条训练数据的损失函数。 在实际应用中，采用折中的方法：每次计算一小部分训练数据的损失函数。这一小部分数据被称为batch。 4.4 神经网络进一步优化4.4.1 学习率的设置假设我们要最小化函数 $y=x^2$, 选择初始点 $x_0=5$。 1. 学习率为1时1234567891011121314import tensorflow as tfTRAINING_STEPS = 10LEARNING_RATE = 1x = tf.Variable(tf.constant(5, dtype=tf.float32), name="x")y = tf.square(x)train_op = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(y)with tf.Session() as sess: sess.run(tf.global_variables_initializer()) for i in range(TRAINING_STEPS): sess.run(train_op) x_value = sess.run(x) print "After %s iteration(s): x%s is %f."% (i+1, i+1, x_value) 结果是：12345678910After 1 iteration(s): x1 is -5.000000.After 2 iteration(s): x2 is 5.000000.After 3 iteration(s): x3 is -5.000000.After 4 iteration(s): x4 is 5.000000.After 5 iteration(s): x5 is -5.000000.After 6 iteration(s): x6 is 5.000000.After 7 iteration(s): x7 is -5.000000.After 8 iteration(s): x8 is 5.000000.After 9 iteration(s): x9 is -5.000000.After 10 iteration(s): x10 is 5.000000. 学习率为1的时候，x在5和-5之间震荡。 2. 学习率为0.001时将上述代码中的学习率设为0.001（很小），如下：1LEARNING_RATE = 0.001 运行结果为：12345678910After 1 iteration(s): x1 is 4.990000.After 101 iteration(s): x101 is 4.084646.After 201 iteration(s): x201 is 3.343555.After 301 iteration(s): x301 is 2.736923.After 401 iteration(s): x401 is 2.240355.After 501 iteration(s): x501 is 1.833880.After 601 iteration(s): x601 is 1.501153.After 701 iteration(s): x701 is 1.228794.After 801 iteration(s): x801 is 1.005850.After 901 iteration(s): x901 is 0.823355. 学习率为0.001的时候，下降速度过慢，在901轮时才收敛到0.823355。 3. 使用指数衰减的学习率将上述代码中的学习率设为指数衰减的方式，如下：1LEARNING_RATE = tf.train.exponential_decay(0.1, global_step, 1, 0.96, staircase=True) 运行结果：12345678910After 1 iteration(s): x1 is 4.000000, learning rate is 0.096000.After 11 iteration(s): x11 is 0.690561, learning rate is 0.063824.After 21 iteration(s): x21 is 0.222583, learning rate is 0.042432.After 31 iteration(s): x31 is 0.106405, learning rate is 0.028210.After 41 iteration(s): x41 is 0.065548, learning rate is 0.018755.After 51 iteration(s): x51 is 0.047625, learning rate is 0.012469.After 61 iteration(s): x61 is 0.038558, learning rate is 0.008290.After 71 iteration(s): x71 is 0.033523, learning rate is 0.005511.After 81 iteration(s): x81 is 0.030553, learning rate is 0.003664.After 91 iteration(s): x91 is 0.028727, learning rate is 0.002436. 使用指数衰减的学习率，在迭代初期得到较高的下降速度，可以在较小的训练轮数下取得不错的收敛程度。 4.4.2 过拟合问题为了避免过拟合，一个非常常用的方法是正则化(regularization)，加入刻画模型复杂程度的指标$R(w)$，优化时优化$J(\theta)+\lambda R(w) $。 常用的正则化方法有：L1正则化和L2正则化。$$R(w) =||w||_1 =\sum_i|w_i|$$$$R(w) =||w||_2^2 =\sum_i|w_i^2|$$ 无论哪一种正则化的方式，其思想都是通过限制权重的大小，使得模型不能任意拟合训练数据中的随机噪声。 区别在于，L1正则化会使得参数变得更加稀疏，而L2正则化则不会；此外，L1正则化的计算公式不可导，而L2正则化公式可导。]]></content>
      <categories>
        <category>TensorFlow系列</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于TensorFlow的简单语音识别]]></title>
    <url>%2F2017%2F12%2F28%2FTensorFlow_speech_commands%2F</url>
    <content type="text"><![CDATA[简单语音识别教程重要的是要知道，真正的语音和音频识别系统要复杂得多，但是像MNIST（入门级的CV数据集）一样，它应该会让你对所涉技术有一个基本的了解。 完成本教程后，你将可以尝试创建一个模型，将一秒钟的音频剪辑去噪，识别单词有“yes”，“no”，“up”，“down”，”left”，”right”，”on”，”off”，”stop”，or “go”。 你也可以在Android应用程序中运行该模型。 准备你要确保已经安装了TensorFlow，由于该版本下载了超过1GB的训练数据，因此你需要电脑有足够的内存，另外网速要快，训练过程可能需要几个小时。 出错与解决找不到audio_ops123456Traceback (most recent call last): File "train.py", line 79, in &lt;module&gt; import input_data File "/home/philglau/speech_commands/input_data.py", line 35, in &lt;module&gt; from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audioImportError: cannot import name 'audio_ops' 解决方案这个’audio_ops’只在TensorFlow1.4版本中有，所以，如果不是1.4的版本，一般都会有这个错误。 此时的解决方案，一是更新TensorFlow版本，二是使用如下命令安装tf-nightly即可。 1pip install tf-nightly 详见参考连接三。 训练要开始训练过程，请访问TensorFlow源代码树下载并运行： 1python tensorflow/examples/speech_commands/train.py 训练过程将从下载“ 语音命令”数据集开始，该数据集由65000个WAVE音频文件组成，其中有30个不同的单词。 这些数据是由Google收集的，并根据CCBY许可证发布。存档超过1GB，所以下载可能需要一段时间，但你应该能看到进度日志，一旦下载完成，你就不用再次执行此步骤了。 下载完成后，你将看到如下所示的日志记录信息： 123I0730 16:53:44.766740 55030 train.py:176] Training from step: 1I0730 16:53:47.289078 55030 train.py:217] Step #1: rate 0.001000, accuracy 7.0%, cross entropy 2.611571 这表明初始化过程已经完成，循环训练已经开始。你会看到它输出每个训练步骤的信息。 步骤分解： Step #1表明我们正在循环训练的第一步。在这种情况下，总共将有18000个步骤，所以你可以查看步骤号码，了解其完成程度有多接近。 rate 0.001000是控制网络权重更新速度的学习率。早期的这个数字是相对较高的（0.001），但是对于后来的训练周期，它会减少10倍到0.0001。 accuracy 7.0%在这个训练步骤中正确地预测了有多少classes。value函数往往波动很大，但随着训练的进行，平均值会增加。该模型输出一个数字数组，每个标签一个，每个数字是该类输入的预测可能性。 通过选择具有最高分数的条目来选择预测的标签，分数总是在零和一之间。 cross entropy 2.611571是我们用来指导培训过程的损失功能的结果。这是通过比较当前训练运动与正确标签的分数向量获得的分数，这在训练期间应该向下倾斜。 经过一百步，你应该看到这样的一行：1I0730 16:54:41.813438 55030 train.py:252] Saving to &quot;/tmp/speech_commands_train/conv.ckpt-100&quot; 这是将当前训练的权重保存到checkpoint文件中。如果你的训练脚本中断，可以查找最后保存的checkpoint，然后：--start_checkpoint=/tmp/speech_commands_train/conv.ckpt-100使用命令行参数重新启动脚本， 从那里开始。 混淆矩阵四百步后，将记录以下信息：12345678910111213141516171819202122232425I0730 16:57:38.073667 55030 train.py:243] Confusion Matrix:[[258 0 0 0 0 0 0 0 0 0 0 0][ 7 6 26 94 7 49 1 15 40 2 0 11][ 10 1 107 80 13 22 0 13 10 1 0 4][ 1 3 16 163 6 48 0 5 10 1 0 17][ 15 1 17 114 55 13 0 9 22 5 0 9][ 1 1 6 97 3 87 1 12 46 0 0 10][ 8 6 86 84 13 24 1 9 9 1 0 6][ 9 3 32 112 9 26 1 36 19 0 0 9][ 8 2 12 94 9 52 0 6 72 0 0 2][ 16 1 39 74 29 42 0 6 37 9 0 3][ 15 6 17 71 50 37 0 6 32 2 1 9][ 11 1 6 151 5 42 0 8 16 0 0 20]] 第一部分是混淆矩阵。要了解这是什么意思，你首先需要知道正在使用的标签，在这种情况下，它们分别表示为静音、未知yes、no、up、down、left、right、on、off、stop、go。 第一行是所有的静音剪辑，第二个剪辑是未知的单词，第三个“yes”等。 该矩阵可以比单个准确率得分更有用，因为它可以很好地总结出网络发生的错误。在此示例中，你可以看到除了初始条目之外，第一行中的所有条目都为零。 因为第一行实际上都是静音的片段，所以这意味着它们都没有被错误的标注为文字，所以我们没有任何静音的否定。这表明网络已经越来越好地区分了静音与谈话。 一个完美的模型将产生一个混淆矩阵，其中所有的条目都是从对角线穿过中心的零点。一旦你确定了可以通过添加更多数据来解决问题，该模型的方差可以帮助你了解模型怎样最容易混淆。 验证混淆矩阵之后，你会看到如下一行：1I0730 16:57:38.073777 55030 train.py:245] Step 400: Validation accuracy = 26.3% (N=3093) 将数据集分为三类是很好的做法。最大的（大约是数据的80％）用于训练网络，一个较小的集（10％ “validation”）被保留用于评估训练中的准确性，另一组10％，“testing”）用于在训练完成后评估准确度。 通过将数据集分类为训练集、验证集、测试集，你可以确保该模型适用于之前从未见过的数据。测试集是一个额外的保障措施，以确保不仅仅是以适用于训练和验证集拟合调整模型。 训练脚本将数据集自动分成这三个类别，上面的记录行显示了在验证集上运行时的模型准确率。理想情况下，这应该与训练准确性相当接近。如果训练准确性增加但验证不是这样，这表明过度拟合正在发生，你的模型只是学习关于训练剪辑的东西，而不是真正的训练模式。 Tensorboard使用Tensorboard可以看出训练进展。默认情况下，脚本将事件保存到/ tmp / retrain_logs，可以通过运行以下命令来加载它们：1tensorboard --logdir /tmp/retrain_logs 然后在浏览器中导航到http：// localhost：6006，将看到显示模型进度的图表。 完成训练经过几个小时的训练（取决于你的电脑快慢），脚本应该已经完成了所有18000个步骤。它将识别出最终的混淆矩阵，以及准确率分数，全部运行在测试集上。使用默认设置，准确率在85％到90％之间。 因为音频识别在移动设备上特别有用，接下来我们将其导出为，在移动平台上易于使用的格式。要执行此操作，请运行以下命令行：12345python tensorflow/examples/speech_commands/freeze.py--start_checkpoint=/tmp/speech_commands_train/conv.ckpt-18000--output_file=/tmp/my_frozen_graph.pb 创建固定模型后，可以使用label_wav.py脚本进行测试，如下所示：1234567python tensorflow/examples/speech_commands/label_wav.py--graph=/tmp/my_frozen_graph.pb--labels=/tmp/speech_commands_train/conv_labels.txt--wav=/tmp/speech_dataset/left/a5d485dc_nohash_0.wav 可以识别出三个标签： left (score = 0.81477) right (score = 0.14139) _unknown_ (score = 0.03808) 更多内容请查看论文：http://suo.im/3PW89b 在Android应用程序中运行模型查看此模型在真实应用程序中如何工作的最简单的方法是，下载预构建的Android演示应用程序并将其安装在手机上。 你会看到“TF Speech”出现在应用程序列表中，打开它将显示我们刚刚训练过单词列表，从“yes”和“no”开始。 你还可以自己构建此应用程序，因为它是开源的， 并可作为github上TensorFlow存储库的一部分使用。默认情况下，它从tensorflow.org下载一个预先训练的模型，但你可以轻松地用自己训练的模型替换它。 如果你自己创建的话，你需要确保SpeechActivity Java源文件中的 SAMPLE_RATE，SAMPLE_DURATION符合你训练时的默认设置所做的任何更改。 你还会看到一个Java版本的RecognizeCommands模块。 这与本教程中的C++版本非常相似。如果你调整了参数，还可以在SpeechActivity中进行更新，以获得与服务器测试相同的结果。 演示应用程序，根据你在固定模型复制到模型中的标签文本文件，自动更新其用户界面列表，可以轻松地尝试不同的模型，而无需进行任何代码更改。如果你更改路径，需要update LABEL_FILENAME，MODEL_FILENAME添加到文件。 参考资料 TensorFlow官网教程：Simple Audio Recognition 中文翻译参考 Tensorflow missing ‘audio_ops’ from contrib framework]]></content>
      <categories>
        <category>TensorFlow系列</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
        <tag>TensorFlow</tag>
        <tag>speech recognition</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VS2015 设置调试时不加载符号]]></title>
    <url>%2F2017%2F12%2F27%2FCPP_VS2015_noPDB%2F</url>
    <content type="text"><![CDATA[问题描述用VS2015打开代码文件，按下F5进行调试，当电脑接入网络后系统会自动从Microsoft符号服务器加载PDB符号文件，而且是每次都会加载。如下图所示： 此加载符号过程使得调试变得非常慢。 通过查阅得知，此类的pdb调试器在编写代码时对于新手来说，根本用不到。也就是说完全可以不需要加载。 那么如何避免VS2013调试时自动加载符号呢？ 解决方案 打开VS的【工具】-【选项】： 选择其中的【调试】-【符号】，并 取消勾选“Microsoft符号服务器” ： 确定并退出即可，此后再次按F5进行调试。 参考资料 VS2013代码调试：如何避免调试时加载符号 vs2015加载符号慢，请问怎么解决]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>VS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习技法笔记01：最佳分类超平面]]></title>
    <url>%2F2017%2F12%2F26%2FML_taiwan_01%2F</url>
    <content type="text"><![CDATA[Large-Margin Separating Hyperplane题目翻译为中文的意思大体上是 最大余量分类超平面。本节主要讲解如何确定该最佳分类超平面。 首先，我们回顾一下之前讲过的Linear Classfication ：有$\circ$和$\times$，我们用一条直线将$\circ$和$\times$分开，或者在高维空间中使用超平面将其分开。数学上，将资料拿来计算一个加权和，根据和的正负预测$\circ$和$\times$。 现在，给定一个线性可分的资料，则会有很多条线将和分开，但是下图中的那条线会更好呢？ PLA(Perceptron learning algorithm,For binary classification解决是非问题)会选哪一条线与PLA看到的错误有关，因此PLA得到哪一条线不定。从之前的理论来看，三条线似乎也没什么区别，例如从VC Bound来看：$$E_{out}(w)\leqslant E_{in}(w) + \Omega(H) $$ 其中$E_{in}(w)$为训练样本上的错误率，三条线都满足；$\Omega(H)$为复杂度，都是线，因此复杂度都为d+1。但是我们的直觉告诉我们最右边是最好的线。 一种原始的解释：假设我们已经拿到原始资料，即图上的点，但是在测试的时候我们拿到跟原始资料相近的资料(测量误差、资料收集等造成)，下图中灰色的x。所以，测试资料可能会和训练资料有点出入。 假设我们绝对相信我们的训练资料，若果有误差，则我们人为最好的预测为将测试资料预测的与训练资料很接近(不完全一样)。 上图中左边与右边最大的差别就在于对测量误差的容忍度，点距离线越远则容忍度越好(tolerate more noise)，进而可以避免过拟合(more robust to overfitting)。 或者换个角度，看这条线有多胖（能涨出去多少），倾向于选择胖的线。 robustness = fatness: distance to closest xn比较胖的线是比较好的。 goal: find fattest separating hyperplane在分类正确的基础上，找出最胖、最强壮(鲁棒)的线。 目标是：我们要找出一条线，首先这条线可以将$\circ$和$\times$分开(线性可分)，然后取最胖的一条线，即计算所有点到线的距离，取其中最小的距离。也就是下面的公式所描述的： fatness: formally called margin：最胖的线，术语上叫“margin”，余量，留白的多少。 correctness: yn = sign(w^T x_n)算出来的分数是正的还是负的，相乘是同号(分类正确)就可以。 goal: find largest-margin separating hyperplane：寻找边界最宽，能够完全分开的线（超平面）。 参考资料 台大林轩田《机器学习基石》学习笔记5：线性模型一（PLA/pocket、Linearregression ） 机器学习技法(林軒田)笔记之一 机器学习技法(林軒田)视频与讲稿。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ Primer学习笔记：(一/二)从基本类型开始]]></title>
    <url>%2F2017%2F12%2F25%2FCPP_01_02%2F</url>
    <content type="text"><![CDATA[第一章 开始include指令(P6,1.2)通常情况下#include指令必须在所有函数之外。include和它想包含的头文件名字必须在同一行里，不然会报错。 一般情况下我们把include指令放在源文件代码内容的最前面，当你在源文件中使用#include声明了一个头文件，效果相当于你把整个头文件黏贴到对应的那一行上。 编译器(P14,1.4)编译器的一部分工作是寻找程序文本中的错误。常见错误类型： 语法错误(syntax error) 类型错误(type error) 声明错误(declaration error) “编辑-编译-调试”（edit-compile-debug）周期。 文件重定向(P19,1.5)1$ addItems &lt;infile &gt;outfile 专业术语(P23) 花括号 curly brace 内置类型 built-in type 形参列表 parameter list 字符串字面值常量 string literal 操作符 manipulator 变量 variable 初始化 initialize 注释 comments 集成开发环境 Integrated Developed Environment,IDE 条件 condition 赋值 assignment 表达式 expression 语法错误 syntax error 方法（类方法） method 第二章 变量和基本类型C++语言关于类型的规定(P30,2.1.1)C++语言的基本类型的设定与硬件紧密相关，因此很多类型的内存尺寸也都只是给了一个范围，其实各家IDE（LLVM，GCC，Visaul C++）的实现都是在范围内，具体的实现细节都是不确定的。 其中bool最小尺寸未定义，char最小尺寸是8位，wchar_t和char16_t的最小尺寸都是16位，char32_t的最小尺寸是32位，int的最小尺寸是16位，long和long long的最小尺寸分别是32位和64位，对于浮点型数据的表现尺寸是按照精度计算的，其中float的最小尺寸精度是小数点后6位(通常占内存32bytes)，double（通常占内存 64bytes）和long double(通常占内存 96~128bytes)的最小尺寸精度则是小数点后10位(实际可能比这个精度要大一些，比如float小数点后有效位为7，double为16)。 int不得小于short,long不得小于int,long long不得小于long。float,double,long double也应该是精度递增（或者相同）的关系。 要特别注意的是，扩展的字符类型(char16_t，char32_t，wchar_t)和布尔类型都没有带符号和无符号之分（尽管它们也确实属于算数类型）。 类型转换(P32,2.1.2)程序自动执行的类型转换操作发生在程序里IDE预期我们使用A类型但是实际上我们使用B类型的时候，B类型的对象会自动转换为A类型的，如果没法转换，程序就会报错。赋值操作中就可能发生这样的情况。 我们先看赋值操作里表达式里面发生的自动转换，赋值操作A=B中，等号左边的A被叫做左值，B被叫做右值，程序期待事情是你给定的右值和左值类型完全相同。如果不相同，这里就会发生强制的类型转换，即把B的类型转化为A的类型。如果把一个超出左值类型表达范围的数赋值给左值，左值又是一个无符号类型，比如unsigned char c=-1;这时-1（整型，负的），右值会转化为无符号字符型，初始值对无符号类型表示数值总数取模，然后求余数，这个余数就是转化后的数。 因为C++没有明确规定有符号类型的数应该如何表示，因此如果把一个超出左值类型表达范围的数赋值给左值，左值又是一个有符号类型，这种行为的结果是不一定的，因为C++标准委员会没有规定这样做之后到底会发生什么，因此各个IDE可能会有不同的实现。我们把这种不确定造成结果的行为叫做未定义行为。 建议：避免无法预知和依赖于环境的行为。 提示：切勿混用带符号类型和无符号类型。 转义序列(P36，2.1.3)字符的转义序列可以为\后面加上最多3个8进制数字（如果多于3个不会引发报错，多出的部分会被当成字符），或者\x后面加上最多两个16进制数字（多出会报错）。数字转换成10进制后的大小不得超过字符集的限定范围。一般的字面值转义无此限制，不过，一般的字面值的类型是不确定的。10进制数字类型字面值会被转换为能够容纳这个数的带符号整数类型，其他进制中它们则会被转换为能容纳它们的占内存最小的类型的值。 在最新的C++14标准中，数字字面值里还允许以0b或者0B开头，后面加上二进制数成为二进制字面值。如0B101，代表数字5；0b11，代表数字3。 指定字面值的常量：当使用一个长整型字面值时，请使用大写字母L来标记，因为小写字母l和数字1太容易混淆了。 变量(P38)列表初始化C++11标准：列表初始化(list initialization)，用一组花括号来初始化变量。下面的第三种：1234int units_sold = 0;int units_sold = &#123;0&#125;;int units_sold&#123;0&#125;;int units_sold(0); 变量声明和定义的关系变量能且只能被定义一次，但是可以被多次声明。声明变量：在变量名前添加关键字extern，而且不要显示地初始化。12345extern int i; // 仅仅是声明extern int i = 0; // 声明且定义int v; // 声明且定义int a = 0; // 声明且定义 在函数体内部，如果试图初始化一个由extern关键字标记的变量，将引发错误。 补： extern外部变量声明其实是在IDE进行编译的时候告诉IDE，这有一个外部变量你要去别的地方找。因此我们应该掌握编译链接这套流程才能够更加方便的会用extern。假设有一个头文件a.h，这个头文件里面定义了int aaa=0;还有一个源文件b.cpp。这个b.cpp里面使用了extern int aaa;这样的语句，那么这个b.cpp是编译不了的。因为头文件如果不被别的源文件引用，是不参与被编译为obj的过程的，一旦它不参与这个过程，它里面声明的aaa这个全局变量其实就不存在，因此在b.cpp里面外部生命一个不存在的变量自然就是非法的。另外，使用extern也要和static做区分并考量它在别的文件中会不会造成内存污染等问题。这里应该掌握分离式编译的编译和链接特性再使用extern比较好。 静态类型(P42) 指针与引用初始化所有指针： 初始化为nullptr或0。 void *指针(P50)：特殊的指针类型，可以存放任意对象的地址。我们对该指针中到底是个什么类型的对象并不了解。 1int *p1,p2; 其中，p1是指向int的指针，p2是int。(强调变量具有的复合类型。) 指向指针的指针：通过*的个数可以区分指针的级别，即：**表示指向指针的指针，***表示指向指针的指针的指针。 指向指针的引用(P52)：123456int i = 42;int *p;int *&amp;r = p; //r是对指针p的引用r = &amp;i; //r引用了一个指针，因此给r赋值&amp;i就是令p指向i*r = 0; //解引用r得到i，也就是p指向的对象，将i的值改为0 面对一条比较复杂的指针或者引用的声明语句时，从右向左阅读有助于弄清楚它的真实含义。离变量名最近的符号（此例中是&amp;r的符号&amp;）对变量的类型有最直接的影响，因此r是一个引用。声明符的其余部分用以确定r引用的类型是是什么，此例中的符号*说明r引用的是一个指针。最后，声明的基本数据类型部分指出r引用的是一个int指针。 顶层const(P57,2.4.3)顶层const是对const而言的，“顶层”可以用来修饰const状态的形容词。一个const使对象本身的值固定，这个const就被称为顶层const;一个const是对象指向或引用的对象成为固定值，这个const就被称为底层const。 顶层和底层const对拷贝来说密切相关，有相同底层const资格的两个对象才能够互相拷贝，而且顶层const声明变量之后不允许再次改变const的值。int p,const int *a＝&amp;p;这种语句中的const就是底层const。像int v1=9;const int *p=&amp;v1;int *p2=p;这种语句如果能够通过编译，那么我们就可以使用p2的性质改变p1指向的常量的值，但是常量的值是不能够被改变的，因此这种变相改变常量的值的表达式都是错误的。可以通过分析const级别得到表达式中常量是否被更改，从而判断语句的正确性。 说到底，顶层底层说的是对拷贝控制的约束。总的规则就是“不能改变常量的值”。因此“拷入和拷出的对象都要有相同的底层const资格，或者两个对象数据类型必须能转换”，例如，有int *p1,const int *p2;。p1没有底层const,p2有底层const。p1=p2;这时const int*不能转换成int *(如果转换，就违反了“不能改变常量的值这一约束条件”)，因此p1=p2;不合法。p2=p1;``int *能够转换成const int *,因此p2=p1合法。 constexpr(P58,2.4.4)我们在了解constexpr之前，应该先了解常量表达式。所谓常量就是固定的量，那么常量表达式就是值固定不变的表达式，这里“值固定不变”，指的是程序编译阶段，常量表达式的值就能被确定下来之后也不能对其进行任何种方式的修改。因此这个固定，是编译之后固定的。像cout&lt;&lt;1234&lt;&lt;endl;中的1234，就是常量表达式，显然，字面值是常量表达式。 constexpr的作用之一就是帮助程序员在IDE的提示下查看一个赋值语句是不是常量表达式。使用的方式包含在声明语句里面，形如constexpr 变量类型 变量名=右值;如果右值是一个常量，这条语句就是正确的。在所有函数体外声明的全局变量的地址就符合“在编译期间能确定，编译后值不被改变”这两个条件，因此也属于常量。123constexpr int mf = 20; // 20是常量表达式constexpr int limit = mf + 1; // mf+1是常量表达式constexpr int sz = size(); //只有当size是一个constexpr函数时，才是一条正确的语句。 另外，用constexpr声明的指针(比如，constexpr int *p=&amp;v1;中的*p，相当于int *const p=&amp;v1;)都是顶层const，即指针本身值固定。但是指针指向的内容是可以变的。引用也一样。 定义于函数体之外的变量的地址是固定的，可以用来初始化constexpr指针。 当你使用constexpr定义引用变量的时候，这个变量引用的对象只能是全局基本数据类型（引用类型除外的）变量（因为要求的内存地址必须是固定不变的）。constexpr引用的结果和正常的引用的结果是一致的，因为引用本身就是固定不变的，因此相当于顶层const修饰的constexpr对引用类型类说没有特殊的意义。 类型别名(P61,2.4.4)使用typedef int zhengxing;这种对简单的类型名进行替换的方式无疑是非常直观并且好理解的，但是在涉及到复杂的类型名的时候往往会出现各种各样的问题。 比如typedef char *Pstring;这条语句是不是就意味着我们看到Pstring就可以用char *替换呢。其实并不是，实际上类型别名不只是替换的规则，而是要复杂很多。 比如我们遇到const Pstring a;的时候，按照替换的规则，这条语句就相当于const char * a;这里的const这种情况下是底层const，但是结果并不是这样的，这条语句正确的等同语句应该是char *const a;是一个顶层const，即指针本身是一个常量。让我们来分析一下为什么是这个样子，而不是简单的替换就行了。typedef char *Pstring；这条语句就是说Pstring是一个类型别名，它是什么类型的类型别名呢？Pstring是 指向char的指针的类型别名，也就是说，这个类型修饰的对象必须是一个指针，这个指针也必须指向char而不能指向别的什么东西，比如，不能指向const char。我们再看看const Pstring a;这个语句，首先a一定是指向char的指针。所以这个前面的const应该是用来修饰这个指针本身。也就是说，这个指针是常量指针而非指向常量的指针。这一点非常重要。 const char * a这个语句里面，实际上类型是const char，*是声明符的一部分。我们说过，定义一个变量由两部分组成，类型名和声明符，声明符可以是*或者&amp;加上变量名的形式。而类型别名只是给类型一个别名，至于声明符是怎样的，不在它修饰的范围内。因此在有const的情况下，就可以看出来这两者之间的区别还是很明显的。 123typedef char *pstring;const pstring cstr = 0; //cstr是指向char的常量指针const pstring *ps; //ps是一个指针，它的对象是指向char的常量指针。 pstring实际上是指向char的指针，因此，const pstring就是指向char的常量指针。1const char *cstr = 0; //是对const pstring的错误理解 数据类型就变成了char，*成为了声明符的一部分。这样改写的结果是，const char成了基本数据类型。cstr是一个指针，指向了常量字符。 auto类型声明符(P61,2.5.2)C++11中引入的auto主要有两种用途：自动类型推断和返回值占位。auto在C++98中的标识临时变量的语义，由于使用极少且多余，在C++11中已被删除。前后两个标准的auto，完全是两个概念。 auto变量通过初始化语句，计算出右值的类型，并推导出左值的类型。12int i=0, &amp;r = i;auto a = r; // a是一个整数（r是i的别名，而i是一个整数） 这个过程中auto将会忽视顶层const和引用类型，可用const auto &amp;a=i;这种方式显式地指出了：指出要推导的结果是带顶层指针属性的或者是引用属性的。 auto推导多个值时，这些值的类型必须是一样的。因为auto是利用初始化赋值，因此它的行为基本上也和初始化有关。 关于auto的更多用法：【C++11】新特性——auto的使用 decltype类型指示符(P62,2.5.3)有时候会遇到这种情况：希望从表达式的类型推断出要定义的变量的类型，但是不想用该表达式的值初始化变量。为此，C++11新标准引入第二种类型说明符decltype。 decltype不通过计算，只通过推算出变量应有的值，表达式本身应有的值和函数的返回值来推导类型。 对于变量类型，decltype保留顶层const和引用的属性。对于表达式，解引用表达式(如:int i=1; int *p=&amp;i; decltype (*p) a=i;中的*p,对p解引用是int &amp;类型的)和带括号的表达式，（如：decltype ((a+1)) c=i;）的结果都将是引用类型。因为decltype通过处理表达式得到结果，因此更详细的内容在第四章将会被提到。有的表达式返回左值，有的表达式返回右值，返回左值的表达式在decltype类型推导下得到的将是引用的结果。12345int i = 42,*p = &amp;i, &amp;r = i;decltype(r + 0) b; //正确，加法结果为int，因此b是一个（未初始化的）intdecltype(*p) c; //错误，c是int&amp;，必须初始化decltype((i)) d; //错误，c是int&amp;，必须初始化decltype(i) e; //正确，e是一个（未初始化的）int decltype((variable)) (注意是双层括号)的结果永远是引用，而decltype(variable)结果只有当variable本身就是一个引用时才是引用。 补： 一般情况下，出现数组名的表达式时会把数组名转换为指针，而用decltype一个数组名时，其返回类型是该数组的类型，如有int ia[10]，则decltype(ia) da，此时da也为包含10个int元素的数组。用于函数时也一样，不会自动把函数名转换为指针，而是返回该函数类型。 如果作用于一个取地址运算符，则为指向指针的指针，如有int p，则decltype(&amp;p)的结果是int **类型。 用关键字struct自定义数据结构使用struct关键字定义类的形式如struct 类名｛数据成员类型1 数据成员名1；数据成员类型2 数据成员名2;｝;，C++11规定可以给类内成员提供类内初始值用于初始化用我们自定义类创建的对象实例中的成员的值。形式如下：12345struct MyClass&#123; int student=0; float numbers=1;&#125;; 很多新手程序员忘记在类定义的最后加上分号。 头文件保护符123456789#ifndef SALES_DATA_H#define SALES_DATA_H#include &lt;string.h&gt;struct Sales_data&#123; std::string bookNo; unsigned units_sold = 0; double revenue = 0.0;&#125;;#endif 头文件保护符依赖于预处理变量。如#define DEBUG，此时DEBUG就是预处理器变量。预处理变量无视C++语言中关于作用域的规则。 头文件保护符很简单， 程序员只要习惯性加上就可以了，没必要太在乎你的程序到底需不需要。 专业术语1.算数类型 arithmetic type2.整型 integral type3.转换 convert4.不可打印 nonprintable5.转义序列 escape sequence6.类型说明符 type specifier7.分离式编译 separate compilation8.声明 declaration9.声明符 declarator10.静态类型 statically typed11.类型检查 type checking12.标识符 identifier13.内层作用域 inner scope14.复合类型 compound type15.左值引用 lvalue reference16.预处理 preprocessor17.临时量 temporary18.指向常量的指针 pointer to const19.常量指针 const pointer20.字面值类型 literal type21.类型别名 type alias22.类内初始值 in-class initializer23.预处理器 preprocessor24.头文件保护符 header guard]]></content>
      <categories>
        <category>C++ Primer</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[photoshop白色背景图片转换为透明背景]]></title>
    <url>%2F2017%2F12%2F21%2Fps_white2transparent%2F</url>
    <content type="text"><![CDATA[1.打开Adobe Photoshop以及待处理的图片，如果图层上有“锁”的标志，就双击进行解锁； 2.在图层上右击，选择最上方的“混合选项”； 3.在混合选项中的本图层中，拖动右侧的白色小三角，向左滑动至适当位置。 4.效果展示。滑动之前的效果：滑动之后的效果： 5.存储。选择“文件”中的“存储为”； 在弹出窗口中选择保存类型为“PNG”格式，保存即可。也可以根据需要，选择合适的格式。 最后附上全文的图片链接。]]></content>
      <categories>
        <category>Photoshop</category>
      </categories>
      <tags>
        <tag>Photoshop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人博客的域名注册与备案流程]]></title>
    <url>%2F2017%2F12%2F19%2Fblog_domain_register%2F</url>
    <content type="text"><![CDATA[域名注册简要说一下为什么选择万网。 看到网上的教程一般都是推荐到国外网站注册，如godaddy，Gandi，Namesilo等等。但一般都是比较早期的回答(2011-13)了，目前(2017/12)来说，仅从价格因素考虑，阿里云万网域名是普遍低于国外网站的。 万网域名注册地址：https://wanwang.aliyun.com/domain/ 另外，关于域名后缀选择问题，一般来说，首选com域名，不推荐cn域名（国内监管严格的原因？）。其次，个人博客站点可以考虑其他后缀，如net，top，me(貌似万网不支持了)，xyz等等。 选择了心仪的域名之后，购买。以阿里云为例，购买完成后，点击右上角的控制台；进入控制台后，选择左下角的域名与网站（万网）下的域名，进入域名列表界面。 可以看到，右方出现了三个选项【续费】、【解析】【管理】 点击解析，按照操作，添加解析即可。主要填写三个参数：记录类型、主机记录和记录值。 记录类型：CNAME是跳转到其他网址，我的是github博客，就直接让他跳转到github博客即可。A是指向IPV4地址。 主机记录是网址的前缀，比如说注册的网址是xxx.com，那么blog.xxx.com的主机记录就是blog，xxx.com的主机记录可以不填，也可以填上一个@ 给出我目前的解析值作为参考。第一个是为了让百度搜索引擎抓取的，每个网址的主机记录都不同，可以忽略。 域名备案我使用的是hexo+Github搭建个人博客，因此，只买了域名（也可以不买，直接使用github.io地址），没有买云服务器、虚拟主机之类的，因此无法备案。 简而言之，备案需要有服务器，然后到服务器提供商处备案即可。 阿里云官方的备案完整流程，可供备案参考：https://help.aliyun.com/knowledge_detail/36895.html]]></content>
      <categories>
        <category>博客搭建系列</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>域名</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客优化之实现来必力评论功能]]></title>
    <url>%2F2017%2F12%2F18%2Fblog_comment%2F</url>
    <content type="text"><![CDATA[评论功能概述目前博客站点使用的评论功能，多说，网易云跟贴都已经下线。Disqus也被挡在墙外，友言貌似也不行。 可用的评论系统大概有： HyperComments：https://www.hypercomments.com （来自俄罗斯的评论系统，使用谷歌账号注册。可以访问，不会用，好气，，） 来必力：https://livere.com （来自韩国，使用邮箱注册。） 畅言： http://changyan.kuaizhan.com （安装需要备案号。不太好用。） Gitment： https://github.com/imsun/gitment （有点小bug，比如说每次需要手动初始化，登录时会跳到主页。。） Valine: https://github.com/xCss/Valine (基于Leancloud的极简风评论系统，用了下，没效果，是我Next主题的原因还是？） 综上，最终采用了来必力。 注册账号打开来必力官网：https://livere.com 按套路注册（有可能注册上面要花费点功夫）。（貌似需要科学上网？之前没科学上网好像登录界面显示不了）。 安装点击上方的安装，选择免费的city版本。 并点击现在安装，出现如下界面。 复制其中的uid字段。 打开主题目录下的blog/themes/next/_config.yml配置文件，定位到livere_uid字段，粘贴上刚刚复制的UID。 至此，大功告成。 效果展示测试评论如图所示： 设置提醒当有新评论出现时，通过邮箱提醒。 点击右上角-&gt;管理页面。选择评论提醒，按照下图设置，输入邮箱、选择间隔时间。]]></content>
      <categories>
        <category>博客搭建系列</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
        <tag>来必力</tag>
        <tag>评论功能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论详解(2) 第三章函数的增长]]></title>
    <url>%2F2017%2F12%2F13%2Falgorithm_tutorial_chapter_3%2F</url>
    <content type="text"><![CDATA[本文是《算法导论》第三章：函数的增长的学习笔记。没有涉及到具体的算法。主要内容有： 五种渐近记号的表示 常用的函数与标记 3.1 渐近记号$\Theta、 \text{O}和\Omega $三种记号的图示： 先看第一幅图(a)——$\Theta$记号若存在正常量$c_1,c_2,n_0$，使得对所有$n\geqslant n_0$，有$0\leqslant c_1g(n)\leqslant f(n) \leqslant c_2g(n)$，则$f(n)$属于集合$\Theta(g(n))$，可以记为$f(n)\in \Theta(g(n))$，我们通常用$f(n)=\Theta(g(n))$表达相同的概念。 上述公式的含义：函数f(n)能“夹入”$c_1g(n)$和$c_2g(n)$之间。换句话说，对所有的$n\geqslant n_0$，函数$f(n)$在一个常量因子内等于$g(n)$，我们称$g(n)$是$f(n)$的一个渐近紧确界(asymptotically tight bound)。 实例：可以用上述的形式化定义来证明：$\frac{1}{2}n^2-3n =\Theta(n^2)$，以及$6n^3 \neq \Theta(n^2)$。 渐近正函数就是对足够大的n均为正的函数。 直觉上，一个渐近正函数的低阶项 在确定渐近确界时可以被忽略，因为对于大的n，它们是无足轻重的。 一般来说，对任意多项式$p(n)=\sum_{i=0}^d a_i n^i$，其中$a_i$为常量且$a_d&gt;0$（最高阶的系数大于零），则有$p(n)=\Theta(n_d)$。 接着看图(b)——$\text{O}$记号$\Theta$记号渐近地给出了一个函数的上界和下届。当只有一个渐近上界时，使用$\text{O}$记号。 $\text{O}(g(n))={f(n)：$存在正常量$c,n_0$，使得对所有$n\geqslant n_0$，有$0\leqslant f(n) \leqslant cg(n)}$ 我们记$f(n)=\text{O}(g(n))$表示$f(n)$是集合$\text{O}(g(n))$的成员。注意$f(n)=\Theta(g(n))$蕴含了$f(n)=\text{O}(g(n))$，因为$\Theta$记号是一个比$\text{O}$记号更强的概念。 使用$\text{O}$记号，我们常常可以仅仅通过检查算法的总体结构来描述算法的运行时间。$\text{O}$记号描述上界，对插入排序算法的最坏情况运行时间的界$\text{O}(n^2)$也适合于该算法对每个输入的运行时间。该算法对每个输入的运行时间都有一个界，这就是综合性描述。 最后看图(c)——$\Omega$记号正如$\text{O}$记号提供了渐近上界，$\Omega$记号提供了渐进下界。 $\Omega(g(n))={f(n)：$存在正常量$c,n_0$，使得对所有$n\geqslant n_0$，有$0\leqslant cg(n) \leqslant f(n)}$ 于是，由此引出了定理3.1。 定理 3.1对任意两个函数$f(n)$和$g(n)$，我们有$f(n)=\Theta(g(n))$，当且仅当$f(n)=\text{O}(g(n))$且$f(n)=\Omega(g(n))$。 当一个算法的运行时间为$\Omega(g(n))$时，我们意指不管n是什么规模，只要n足够大，对那个输入的运行时间至少是$g(n)$的常数倍。 等式和不等式中的渐近记号当渐近记号出现在某个公式中时，我们将其解释为代表某个我们不关注名称的匿名函数。 例如：$2n^2+3n+1 = 2n^2 +\Theta(n)$。 按这种方式使用渐记号可以帮助消除一个等式中无关紧要的细节与混乱。 例如：归并排序的最坏情况运行时间：$$T(n) = 2T(n/2)+\Theta(n)$$如果只对T(n)的渐近行为感兴趣，就没必要准确说明所以低阶项，它们都被理解为包含在由项$\Theta(n)$表示的匿名函数中。 在某些例子中，渐近记号出现在等式的左边，如：$$2n^2+\Theta(n) = \Theta(n^2) $$ 无论怎么选择等号左边的匿名函数，总有一种办法来选择等号右边的匿名函数使等式成立。 $\text{o}$记号$\text{o}$记号，非渐近紧确的上界。 $\text{o}(g(n))={f(n)：$对任意正常量$c&gt;0$，存在正常量$n_0&gt;0$，使得对所有$n\geqslant n_0$，有$0\leqslant f(n) &lt; cg(n)}$。 $\text{O}$记号与$\text{o}$记号类似，主要的区别 是在$f(n)=\text{O}(g(n))$中，界$0\leqslant f(n) \leqslant cg(n)$对某个常量$c&gt;0$成立，但在$f(n)=\text{o}(g(n))$中，界$0\leqslant f(n) &lt; cg(n)$对所有常量$c&gt;0$成立。 直观上，在$\text{o}$记号中，当n趋向于无穷时，函数$f(n)$相对于$g(n)$来说变得微不足道了，即：$$\lim_{n\rightarrow \infty} \frac{f(n)}{g(n)} = 0$$ $\omega$记号非渐近紧确下界。 $\omega (g(n))={f(n)：$对任意正常量$c&gt;0$，存在正常量$n_0&gt;0$，使得对所有$n\geqslant n_0$，有$0\leqslant cg(n) &lt; f(n) }$。 $$\lim_{n\rightarrow \infty} \frac{f(n)}{g(n)} = \infty $$ 渐近运算的运算性质传递性、自反性、对称性与转置对称性：而且：两个函数f和g的渐近比较关系可与实数a与b之间的比较做类比： f(n)=O(g(n)) 类似于a&lt;= b f(n)=Ω(g(n)) 类似于a&gt;= b f(n)=Θ(g(n)) 类似于a= b f(n)=o(g(n)) 类似于a&lt; b f(n)=w(g(n)) 类似于a&gt; b 三分性：虽然实数具有三分性，即对于任意两个实数a、b，下列三种情况必须有一种成立：$ab$。但是不是所有函数都可以渐近比较。 3.2 标准记号与常用函数单调性单调递增/单调递减：包含等号；严格递增/严格递减：不包含等号。 向下取整与向上取整x的向下取整：$\lfloor x \rfloor$；x的向上取整：$\lceil x \rceil$。 模运算对任意整数a和正整数n，$a\ \text{mod}\ n$ 的值就是商a/n的余数。$$a\ \text{mod}\ n = a-n\lfloor a/n\rfloor $$ 若$(a\ \text{mod}\ n)=(b\ \text{mod}\ n)$，则记$a\equiv b(\text{mod}n)$ 多项式给定一个非负整数d，n的d次多项式$p(n)$：$$p(n)=\sum_{i=0}^d a_i n^i$$其中，$a_d \neq 0 $。 多项式为渐近正的当且仅当$a_d &gt; 0 $。对于一个d次渐近正的多项式$p(n)$，有$p(n)=\Theta(n^d)$ 若对于某个常量k，有$f(n)=\text{O}(n^k)$，则称函数$f(n)$是多项式有界的。 指数对所有使得$a&gt;1$的实常量a和b，有$$\lim_{n\rightarrow \infty} \frac{n^b}{a^n} = 0$$据此可得：$$n^b = \text{o}(a^n)$$ 对数以2为底的自然数：$$\text{lg}n = \text{log}_2n$$自然对数：$$\text{ln}n = \text{log}_en$$取幂：$$\text{lg}^kn = (\text{lg}n)^k$$复合：$$\text{lg}\text{lg}n =\text{lg} (\text{lg}n)$$ 一个重要的记号约定：对数函数只适用于公式中的下一项，所以$\text{lg}n+k$意思是指$(\text{lg}n)+k$ 对于$a&gt;0,b&gt;0,c&gt;0$和n，有$$a = b^{\text{log}_ba}$$$$\text{log}_c(ab) = \text{log}_ca +\text{log}_cb$$$$\text{log}_b(a^n) = n\text{log}_ba$$$$\text{log}_ba =\frac{\text{log}_ca}{\text{log}_cb} $$$$\text{log}_b(1/a) =- \text{log}_ba $$$$\text{log}_ba =\frac{1}{\text{log}_ab} $$$$a^{\text{log}_bc} = c^{\text{log}_ba}$$其中，上述等式的对数底不为1。 对任意常量a，有$$\text{log}^bn = \text{o}(n^a)$$表示任意正的多项式函数都比任意多对数函数增长得快。 阶乘$n!$，读作“n的阶乘”。其定义为对整数$n \geqslant 0$：$$n! = \begin{cases}1 &amp; 若n=0\\n\cdot (n-1)! &amp; 若n&gt;0\end{cases}$$ 阶乘函数的一个弱上界是$n! \leqslant n^n$，因为在阶乘中，n项的每项最多为n。 斯特林(Stirling)近似公式$$n!=\sqrt{2\pi n}(\frac{n}{e})^n(1+\Theta(\frac{1}{n})) $$ 由上述公式可以证明：$$n! = o(n^n)$$$$n! = \omega(2^n)$$$$\text{lg}n! = \Theta(n\text{lg}n)$$ 多重函数记号$f^{(i)}(n)$表示f(n)重复i次作用于一个初值n上。对非负整数i，我们递归地定义：$$f^{(i)}(n)=\begin{cases}n &amp; 若i=0 \\f(f^{(i-1)}(n)) &amp; 若i&gt;0\end{cases}$$ 多重对数函数$\text{lg}^*n$表示多重对数，多重对数增长非常慢。 斐波那契数斐波那契数的递归定义：$$F_0 = 0$$$$F_1 = 1$$$$F_i = F_{i-1}+F_{i-2}, i \geqslant 2$$]]></content>
      <categories>
        <category>算法导论</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>algorithm</tag>
        <tag>函数渐近</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论详解(1) 第二章算法基础]]></title>
    <url>%2F2017%2F12%2F12%2Falgorithm_tutolrial_chapter_2%2F</url>
    <content type="text"><![CDATA[本文是《算法导论》的第二章：算法基础的笔记整理。其中主要包括两个算法： 插入排序 归并排序 第二章 算法基础伪码说明 数组A[1,…,n]长度为n的待排序序列。注意，书中的下标都是从1开始的。python中是从0开始的。 伪码中，A的长度用A.length表示。python中使用len(A)表示。 缩进表示块结构。提高代码清晰度。 while, for, repeat-until 在循环结束后，循环计数器仍然保持其值。 符号“//”后面是注释。 数组元素通过“数组名[下标]”这样的形式来访问。 复合数据通常被组织成对象，对象又由属性组成。 return允许返回多个值 按值把参数传递给过程，被调用过程接收其参数自身的副本。 布尔运算符“and”和“or”都是短路的。 2.1 插入排序插入排序的Python实现：123456789101112def insertion_sort(A): length = len(A) for j in range(1, length): key = A[j] i = j - 1 while i &gt;= 0 and A[i] &gt; key: A[i + 1] = A[i] i = i - 1 A[i + 1] = key return AA = [5, 3, 19, 1, 8, ]print(insertion_sort(A)) 对插入排序的简单理解：从第二个数开始，依次比较前面的数和key的大小，若大于key，则后移。最后将key插入到最前方停下的位置。j是遍历数组每个元素；i是每个元素前面、需要移动的最前方。 形象的解释：插入纸牌：key是当前带插入的牌，找到插入的位置，先把每个大的都往后挪一个位置出来，再把key插入到空出来的位置。 2.2 分析算法RAM（Random-access machine,RAM）模型:单处理器计算模型，指令一条接一条地执行，没有并发操作。 真实计算机如何设计，RAM模型就是如何设计的，RAM模型包含真实计算机的常见指令：算术指令（加减乘除，取余，向下取整，向上取整），数据移动指令（装入、存储和复制）和控制指令（条件与无条件转移、子程序调用与返回）。 灰色区域：真实计算机中未列出的指令。如指数运算算是常量时间的指令吗？ 答案：①一般情况下不是，如$x^y$，当x和y都是实数的时候。②在受限情况下，可以当做一个常量时间的操作。如$2^k$是一个常量的操作。 一个整数的各位左移k位等价于将该整数乘以$2^k$。 插入排序算法的分析算法需要的时间与输入规模同步增长，通常把一个程序的运行时间描述成其输入规模的函数。 输入规模的最佳概念依赖于研究的问题。 一个算法在特定输入上的运行时间是指执行的基本操作数或步数。算法的运行时间是执行每条语句的运行时间之和。 若数组已排好序，则出现最佳情况：$T(n)=an+b$若数组已反向排序（即按递减序排好序），则导致最坏情况：$T(n)=an^2+b$，是n的二次函数。 最坏情况与平均情况分析本书往往集中于只求最坏情况运行时间，即对于规模为n的任何输入，算法的最长时间。 书中给出了三个理由，在此不详述。其中一点是平均情况往往与最坏情况一样差。 增长量级最坏情况运行时间表示为：$T(n)=an^2+b$。 现在我们做出一种更简化的抽象：我们真正感兴趣的运行时间的$增长率$或$增长量级$。 2.3 设计算法2.3.1 分治法许多算法在结构上是递归的，算法依次或多次递归地调用其自身以解决紧密相关的若干子问题。 分治模式在每层递归时都有三个步骤： 分解原问题为若干子问题； 解决这些子问题，递归地求解各子问题。 合并这些子问题的解成原问题的解。 归并排序算法完全遵循分治模式。归并算法的关键在于合并。归并排序的的基本步骤如下： 把待排序的数组分为左数组和右数组 对左数组和右数组进行迭代排序 将左数组和右数组进行合并 显然这些基本步骤符合分治模式在每一层递归上的三个步骤：分解、解决、合并。 2.3.2 归并排序算法（分治算法）MERGE(A,p,q,r)：完成合并。A是一个数组，p,q,r是数组的下标，满足$p\leqslant q&lt;r$。假设A[p..q]与A[q+1..r]都已排好序，MERGE函数的目的就是合并这两个子数组形成单一的已排好序的数组A[p..r]。 形象地描述：同样以插入排序时的扑克牌为例，现在的情况是有两堆牌（两个输入堆），牌面朝上（可见，已排序），每次选取两堆中较小的放入到输出堆，牌面朝下。重复这个步骤，直到一个输入堆为空，则把另一个输入堆直接牌面朝下的放置到输出堆。 MERGE-SORT(A,p,r)排序子数组A[p,r]中的元素。若$p\geqslant r$，则该子数组最多只有一个元素，所以已经排好序，直接返回。否则，分解步骤。计算下表q，将A[p..r]分为A[p..q]和A[q+1..r]。 123456789101112131415161718192021222324252627282930313233343536373839# author: wangwljfrom math import floorMAX = 1 &lt;&lt; 31def merge(A, p, q, r): n1 = q - p + 1 n2 = r - q L = [] R = [] for i in range(0, n1): L.append(A[p + i]) # 因为我初始化为空列表，所以直接赋值的话会报错，只能以append的形式追加值。 for i in range(0, n2): R.append(A[q + i + 1]) L.append(MAX) # 使用无穷大作为哨兵 R.append(MAX) assert len(L) == n1 + 1 and len(R) == n2 + 1 i = 0 # python是从0开始 j = 0 for k in range(p, r + 1): # 需要加1，因为首尾每个都算 if L[i] &lt;= R[j]: A[k] = L[i] i += 1 else: A[k] = R[j] j += 1def merge_sort(A, p, r): if p &lt; r: q = floor((p + r) / 2) merge_sort(A, p, q) merge_sort(A, q + 1, r) # 首尾都包含了，所以要加1 merge(A, p, q, r)if __name__ == "__main__": # test function A = [1, 3, 5, 2, 4, 6, 0, -1, 5] merge_sort(A, 0, len(A) - 1) print(A) 上述代码测试成功。 2.3.2 分析分治算法假设把原问题分解为a个子问题，每个子问题的规模都是原问题的1/b。（对于归并排序，a和b都是2，然而在许多分治算法中，$a\neq b $。） 求解规模为n/b的子问题，需要$T(n/b)$的时间，所以需要花费$aT(n/b)$的时间来求解a个子问题。 下面分析归并排序n个数的最坏情况运行时间$T(n)$的递归式。 分解：分解步骤只计算子数组的中间位置，需要常量时间，因此，$D(n)=\Theta(n)$ 解决：递归地求解两个规模为n/2的子问题，将贡献$2T(n/2)$的运行时间。 合并：n个子元素的数组上的merge需要$\Theta(n)$的时间（线性复杂度），所以$C(n)=\Theta(n)$。 $D(n)$和$C(n)$相加的和，仍然是n的线性复杂度，即$\Theta(n)$。再与“解决”步骤相加，为：$$T(n) = \begin{cases} \Theta(1) &amp; 若n=1 \\ 2T(n/2)+\Theta(n) &amp; 若n&gt;1\\ \end{cases} $$ 在第四章，我们将看到“主定理”，可以用该定理来证明$T(n)$ 为$\Theta(n\text{lg}n)$。（即时间复杂度为nlgn） 运行时间为$\Theta(n\text{lg}n)$的归并排序优于运行时间为$\Theta(n^2)$的插入排序。 $T(n) =\Theta(n\text{lg}n)$的直观理解：由(d)图，每层对n等分，可以展开为lgn层(再加上原来的一层，一共lgn+1层)。每层的复杂度都是cn，所以总的复杂度为$cn\text{lg}n+cn = cn(\text{lg}n+1)$。]]></content>
      <categories>
        <category>算法导论</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
        <tag>algorithm</tag>
        <tag>插入排序</tag>
        <tag>归并排序</tag>
        <tag>分治</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一起开始机器学习吧——知乎live笔记]]></title>
    <url>%2F2017%2F12%2F12%2FStart_Machine_Learning_review%2F</url>
    <content type="text"><![CDATA[问答干货①练手项目推荐：《机器学习实战》,从零开始写机器学习算法代码，有实际的项目。有一定了解之后，去Kaggle上找竞赛做。 ②教程推荐：公开课（吴恩达、coursera等），coursera上吴恩达的公开课 ③语言推荐：python，MATLAB。很多开源工具（MXNet，Tensorflow，Keras）都有Python接口。 ④python方面，网上有很多博客，比如廖雪峰的博客，感觉只需要了解即可，会用就行；传统算法入门的话，推荐李航的《统计学习方法》,入门最合适。最近出了Bengio的《Deep learning》书，有中文翻译，前面章节全是传统算法。不推荐一上来就看大家都说的《pattern recognition and machine learning》以及《模式分类》,这两本书不适合入门。 ⑤完全零基础的入门性质的资料：视频：https://www.youtube.com/watch?v=IpGxLWOIZy4&amp;t=9s机器学习入门： http://www.cnblogs.com/subconscious/p/4107357.html ⑥数学基础课：数学（概率、线代、高数、随机过程，排名分先后） ⑦发论文经验：目前我只是有paper在投，还没有成功发过，哈哈。经验嘛，主要就是一定要敢于否定自己，我在写的paper一共两篇，每一篇都几乎改了七八次，每次都很严格地要求自己。同时，最好要把paper发给同组的人一起看看，不同的角度给你提问题，会帮助你认识到自己容易忽视的问题。视觉方面发paper其实很容易的。通常来说你需要在同一个数据集上跟最好的方法做对比。 ⑧我数学基础不太牢固 想一边看机器学习一边补数学 但有很多数学符号甚至都不认识 百度也没法搜索 你有什么建议吗？答：专业书籍都有符号索引表；学习简单的数学工具，如latex；matrix cookbook 矩阵常用的手册。 PPT干货 机器学习常用分类：监督学习、半监督学习、无监督学习、增强学习 ②无监督才是世界的本质，标注数据往往要花费大量的人力物力。没有标注这么做呢？迁移学习是可以类比无监督学习来做的事情。人是有类比能力的，计算机可以吗？我们想让它有这个能力。（就是迁移学习）通过迁移学习的方式可以部分地接近无监督学习的目标。迁移学习的好处是什么？利用已有的知识，节约新学习的成本。但需要找到两者的相似性。骑自行车-&gt;开汽车？ 不行！ 需要有相似性。深度学习算是对迁移学习的改进（我的总结）？，因为深度学习不像迁移学习需要手动提取特征。 准备工作 理论知识（高数、概率、线性代数、随机过程） 编码能力（Python, Matlab, Java） 基本入门 李航《统计学习方法》 周志华《机器学习》 吴恩达公开课 Kaggle竞赛 进阶提高 《模式分类》、《PRML》 ICML、NIPS等国际会议 做自己的研究工作 书籍资料整理：https://github.com/ty4z2008/Qix/blob/master/dl.md 入门资料：http://www.cnblogs.com/subconscious/p/4107357.html 公开课：http://open.163.com/special/opencourse/machinelearning.html Kaggle竞赛：https://www.kaggle.com/]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python爬虫实战--selenium模拟登录并自动点击]]></title>
    <url>%2F2017%2F12%2F09%2FHDHome_clawler_tutorial%2F</url>
    <content type="text"><![CDATA[python爬虫实战–selenium模拟登录网站HDH并刷魔力值任务介绍最近刚刚注册了某个网站：HDHome，该站有新手考核任务，其中有一项是需要达到魔力值5000。在魔力值获取方式中，我们看到这一项：“说谢谢 = 0.5个魔力值”，而网站存活种子数量达到16000+，也就意味着对每个种子说一下谢谢，轻松达到8000+的魔力值，于是，这个项目应运而生。 实现思路：获取种子的页面，在每个页面中找到说谢谢的按钮，并点击后，关闭。依次进行下去即可。 相似任务： 实现对某论坛的自动回复，实现自动获取所有帖子的信息等等相关操作，无论是否需要模拟登录、模拟鼠标操作还是直接解析网站元素。 selenium 牛刀小试首先导入相关的库： 123456import selenium.webdriver as webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.webdriver import ActionChainsfrom selenium.webdriver.common.keys import Keys 这是整个程序里面用到的所有内容。其中，webdriver是主浏览器，selenium都是基于整个浏览器的对象；WebDriverWait、EC、By是等待网页元素加载相关的操作；Keys是键值，如Keys.CONTROL，Keys.ENTER等等，ActionChains是用鼠标进行一系列的操作。 webdriver可用的浏览器有：123456789101112webdriver.Firefoxwebdriver.FirefoxProfilewebdriver.Chromewebdriver.ChromeOptionswebdriver.Iewebdriver.Operawebdriver.PhantomJSwebdriver.Remotewebdriver.DesiredCapabilitieswebdriver.ActionChainswebdriver.TouchActionswebdriver.Proxy 一开始我选择的是Chrome浏览器，后来改为了Firefox火狐。Chrome浏览器在执行单个元素（如验证码）截图时有坑（下文有详细说），所以后来才用的Firefox。此外，PhantomJS是匿名浏览器，没有显式的窗口。 那么，开始写程序吧。1234567driver = webdriver.Firefox()login_url = "http://hdhome.org/login.php"login_failed_url = "http://hdhome.org/takelogin.php"driver.get(login_url)while self.driver.current_url == login_url or self.driver.current_url == login_failed_url: time.sleep(10)# do something 首先，实体化浏览器driver，执行driver = webdriver.Firefox()这句的时候，就会有firefox浏览器弹出来了。当执行到driver.get(login_url)时，浏览器转到相应的网址，后面的while语句是用来等待我们手动登录的，当我们手动登录成功后，会进入到&quot;http://hdhome.org/index.php&quot;，与login_url及login_failed_url都不同。接着便可以做自己想做的事情了。 我们发现单个种子的网址是类似这样的：1single_link = "http://hdhome.org/details.php?id=&#123;&#125;&amp;hit=1".format(i) i可以从1到30000多。于是，我们可以这样写程序，依次对每个种子执行“说谢谢”操作：1234567891011121314151617def saythanks(link): driver.get(link) try: driver.find_element_by_xpath("//input[@id='saythanks']").click() print(link, " succeed\n") except: print(link, " not succeed\n") finally: time.sleep(1) pass START = 1END = 30000for i in range(START, END): link = "http://hdhome.org/details.php?id=&#123;&#125;&amp;hit=1".format(i) saythanks(link)driver.close() 其中，我们使用try、except、finally语句来尝试定位到’saythanks’说谢谢的按钮元素。由于有时候加载较慢就会找不到，或者是这个种子已经被删除了，所以也导致找不到该元素。 其中定位网页元素的方法有一下几种：123456789101112131415161718# locate single element in a page:find_element_by_idfind_element_by_namefind_element_by_xpathfind_element_by_link_textfind_element_by_partial_link_textfind_element_by_tag_namefind_element_by_class_namefind_element_by_css_selector# To find multiple elements (these methods will return a list):find_elements_by_namefind_elements_by_xpathfind_elements_by_link_textfind_elements_by_partial_link_textfind_elements_by_tag_namefind_elements_by_class_namefind_elements_by_css_selector 从上面可以看出，我们也可以用find_element_by_id(&quot;saythanks&quot;)同样可以找到说谢谢的按钮。 附上到目前为止的所有程序：GitHub地址1完整程序中加上了logging模块，将输出日志也导入到了文件，方面以后查阅。 改进一：使用多线程多标签在上述模块中，可以看到，我们按照种子的顺序依次进行相应的操作。在种子数量很多的时候，会显得很慢，于是，有了这个改进：使用多线程。 我们使用multiprocessing库。1from multiprocessing import Pool 先来看一个使用该多线程库的示例程序：123456789101112131415161718192021222324252627import timefrom multiprocessing import Pooldef run(fn): # fn: 函数参数是数据列表的一个元素 time.sleep(1) return fn * fnif __name__ == "__main__": testFL = [1, 2, 3, 4, 5, 6] print('shunxu:') # 顺序执行(也就是串行执行，单进程) s = time.time() for fn in testFL: run(fn) e1 = time.time() print("顺序执行时间：", int(e1 - s)) print('concurrent:') # 创建多个进程，并行执行 pool = Pool(5) # 创建拥有5个进程数量的进程池 # testFL:要处理的数据列表，run：处理testFL列表中数据的函数 rl = pool.map(run, testFL) pool.close() # 关闭进程池，不再接受新的进程 pool.join() # 主进程阻塞等待子进程的退出 e2 = time.time() print("并行执行时间：", int(e2 - e1)) print(rl) 于是，模仿上述程序，我们也使用多线程来执行说谢谢。说谢谢的过程其实有两步：一是打开网页，二是对每个网页定位到每个元素并点击。 如果对一、二两个步骤都执行多线程会出错，可能是由于多窗口的原因。因此我目前只对打开网页的步骤执行了多线程的操作。 上述也提到了，要同时打开多个窗口，则需要使用浏览器的多标签功能。打开一个新的标签的程序需要执行js脚本，如下：123def open_url(url): newwindow = 'window.open("&#123;&#125;")'.format(url) driver.execute_script(newwindow) 于是多线程部分的改进如下：123456789101112131415161718192021222324252627282930313233343536373839START = 25980 END = 30000 Thread_Num = 3 t = 1 for i in range(START, END, Thread_Num): pool = Pool(Thread_Num) all_links = ["http://hdhome.org/details.php?id=&#123;&#125;&amp;hit=1".format(i) for i in range(i, i + Thread_Num)] print(all_links) # noinspection PyBroadException try: rl = pool.map(open_url, all_links) pool.close() pool.join() except: print("multi thread start failed, next!!") logging.info("multi thread start failed, next!!") time.sleep(5) continue # 通过移动句柄来说谢谢 saythanks() # sleep more time.sleep(0.5) if t % 3 == 0: time.sleep(0.5) if t % 5 == 0: driver.switch_to.window(driver.window_handles[0]) driver.refresh() mystr = driver.find_elements_by_xpath('//span[@class="medium"]')[0].text bonus = re.search("\s[0-9,.]*\s", mystr).group() usrName = re.search("\s[a-zA-Z0-9]*\s", mystr).group() print(driver.current_url, "normal refresh,&#123;&#125;bonus is&#123;&#125;now...".format(usrName, bonus)) logging.info(driver.current_url + "normal refresh,&#123;&#125;bonus is&#123;&#125;now...".format(usrName, bonus)) time.sleep(1) t = t + 1 driver.quit() logging.info("&#123;&#125;: driver quit, program stop.".format( time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))) 为了不让浏览器检测到，我只是用了三个线程，可以适当的增加。saythanks()下面的部分程序是为了增加更多的延迟并且显示相应的信息。其中if t % 5 == 0:中，我们移动到主页上，进行刷新操作，然后定位到用户信息那一栏：12bonus = re.search(&quot;\s[0-9,.]*\s&quot;, mystr).group()usrName = re.search(&quot;\s[a-zA-Z0-9]*\s&quot;, mystr).group() 这个部分使用了re正则项来找出当前的魔力值以及用户名，并显示出来。 其中，说谢谢的程序也需要对多标签进行相应的改进，程序如下：123456789101112131415161718192021222324def saythanks(): while len(driver.window_handles) &gt; 1: driver.switch_to.window(driver.window_handles[-1]) # noinspection PyBroadException try: WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, "outer"))) except: driver.refresh() time.sleep(1) print(driver.current_url, " refresh ---") # noinspection PyBroadException try: driver.find_element_by_xpath("//input[@id='saythanks']").click() print(driver.current_url, " succeed") logging.info(driver.current_url + " succeed~") except: print(driver.current_url, " not succeed") logging.info(driver.current_url + " not succeed!") finally: time.sleep(1) driver.close() driver.switch_to.window(driver.window_handles[-1]) 通过在不同窗口的句柄之间移动，来依次进行说谢谢的步骤。在每个网页加载的时候，我们执行了等待的操作：1WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, "outer"))) 一直等到最外层的元素出现。我选择的”outer”这个元素，是在无论这个种子是否存在的时候都会出现的。 1driver.switch_to.window(driver.window_handles[-1]) 将窗口转移到最后打开的那个窗口。12driver.close()driver.switch_to.window(driver.window_handles[-1]) 关闭当前的个窗口，并转到当前的最后一个窗口。需要注意的是：窗口虽然关闭了，但是，driver依旧会停在那个已经失效的窗口，并不会自动的转到新的窗口（虽然在浏览器中看上去到了新的窗口），所以，需要我们自己手动的移动窗口的句柄。 这边还存在一个问题，就是多标签的时候，自动切换标签的时候，浏览器会自动弹出来。这样子便有点烦人，毕竟我们只是想让他在后台自己跑， 所以，我加上了一个虚拟窗口，使用的是pyvirtualdisplay库。 以下是pyvirtualdisplay库在ubuntu中的安装步骤：123pip install pyvirtualdisplaysudo apt install xvfbsudo apt install xserver-xephyr 下面是pyvirtualdisplay具体的使用方式：12345from pyvirtualdisplay import Displayif __name__ == &quot;__main__&quot;: display = Display(visible=1, size=(800, 600)) display.start() 把虚拟窗口放在一开始处的位置即可。也可以将visible改为0，浏览器就完全不可见了。 最后附上这个阶段的完整程序：github地址2 改进二：验证码保存+面向对象编程验证码保存：123456code = self.driver.find_element_by_xpath("//img[@alt='CAPTCHA']") img = code.screenshot_as_png img_name = "./code/code&#123;&#125;.png".format(time.strftime('%Y-%m-%d_%H%M%S', time.localtime(time.time()))) with open(img_name, 'wb') as f: f.write(img) rec_code = self.code_recog(img_name) 其中，验证码保存步骤使用了selenium自带的元素截图功能，而不是全屏截图。这边正是我从chrome浏览器改为firefox浏览器的真实原因。chrome浏览器中的元素截图不可用！会报错！故此选用firefox浏览器。 面向对象编程就是对函数使用了类，把多个函数合并到了同一个类中去。 完整程序在最后给出。 改进三：使用pyqt获得验证码图片思路是：从网页中解析到验证码的图片，然后下载到本地；接着使用pyqt弹出一个窗口，窗口中显示获取到的验证码，手动输入验证码后点击关闭。 简化了每次登录的流程，账号、密码记录在程序中自动输入，只需要手动输入验证码。 其中，基于pyqt5图形界面的窗口部分的程序如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879# CodeRecognition.pyimport sysfrom PyQt5 import QtWidgets, QtGuifrom PyQt5.QtWidgets import *from PyQt5.QtGui import *class CodeRecognition(QtWidgets.QWidget): def __init__(self, parent=None): QtWidgets.QWidget.__init__(self, parent) self.setWindowTitle("请手动输入验证码") self.resize(250, 150) self.center() # 界面初始化 self.code_edit = QLineEdit() self.label_code = QtWidgets.QLabel() self.init_interface() self.img_path = './image_3.png' self.show_code_img() # 输出的识别码 self.out_code = 'To_be_recognize' def init_interface(self): label1 = QtWidgets.QLabel('请输入验证码：', self) label2 = QtWidgets.QLabel('输入完成后点击关闭按钮即可。', self) self.code_edit.setToolTip('请输入验证码') button2 = QtWidgets.QPushButton('关闭', self) grid = QGridLayout() grid.setSpacing(0) grid.addWidget(self.label_code, 0, 0, 1, 2) grid.addWidget(label1, 1, 0) grid.addWidget(self.code_edit, 2, 0) grid.addWidget(label2, 3, 0) grid.addWidget(button2, 4, 0, 1, 2) # 关闭窗口 button2.clicked.connect(self.close) self.setLayout(grid) def center(self): # 该语句用来计算出显示器的分辨率（screen.width, screen.height） screen = QtWidgets.QDesktopWidget().screenGeometry() size = self.geometry() self.move((screen.width() - size.width()) / 2, (screen.height() - size.height()) / 2) def get_text(self): self.out_code = self.code_edit.text() # print(self.out_code) return self.out_code def show_code_img(self): img = QtGui.QPixmap(self.img_path) self.label_code.setPixmap(img) def closeEvent(self, event): code = self.get_text() if len(code) &lt; 4 or len(code) &gt;= 8: QtWidgets.QMessageBox.about(self, "验证码输入错误", "请注意：\n验证码一般为4-6位，请重新输入!") event.ignore() else: event.accept()if __name__ == "__main__": app = QtWidgets.QApplication(sys.argv) center = CodeRecognition() # 改变输入的图片。 path = "image_2.png" center.img_path = path center.show_code_img() center.show() app.exec_() rec_code = center.get_text() print("识别的验证码为：", rec_code) 之前学过qt的同学看起来应该不困难，没有学过qt的同学想要入门的话建议查看官方文档或者小甲鱼论坛的pyqt连接。 最后附上完整的程序：github地址3]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
        <tag>selenium</tag>
        <tag>HDHome</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python-基础篇]]></title>
    <url>%2F2017%2F11%2F27%2Fpython_base_NJU_1%2F</url>
    <content type="text"><![CDATA[本文是学习南京大学Python玩转数据基础篇的笔记整理。内容较为简洁，仅供参考。 python类型基本类型 整型/长整型： 长度与机器有关。长整型：整型值后面加上L。 布尔型：True、False。 浮点型：数学中的实数。可以用科学计数法表示。 float 复数型：虚数部分用j。 x = 2.4+ 5j Out[9]: (2.4+5j) type(x) Out[10]: complex 复数可以对实数和复数部分分离。imag、real。 复数的共轭：conjugate() x.real Out[11]: 2.4 x.imag Out[12]: 5.0 x.conjugate() Out[13]: (2.4-5j) 序列类型字符串，列表[]，元组() 字符串： 三种表示方式：单引号，双引号，三引号。 可以使用索引操作符。 映设类型字典： 大括号{}鉴别； 类似于哈希表的键值对。 python运算算术运算+ - × / 取余 % 乘方 ** 整除 // ----地板除 比较运算数值的比较：按值的大小 字符串的比较：按ASCII码值的大小 逻辑运算not and or 字符运算r / R, ---原始字符串 u / U 位运算&lt;左移 &gt;右移 函数、模块与包函数函数可以看成类似于数学中的函数。完成一个特定功能的一段代码。如绝对值函数abs()，类型函数type()，四舍五入函数round()。 内建函数如何查看python中自带的内建函数1dir(__builtins__) 模块非内建函数如何使用呢？ 如floor()函数，不是内建函数，但包含在math的头文件中，因此只需要导入该模块即可，如下：1import math 什么是模块？模块就是一个完整的python文件。12文件：物理上的组织方式：math.py模块：逻辑上的组织方式：math Python中通常用import 模块的方式将现成模块中的函数、类重用到其他代码块中。 用help(math)打印所有math内部的函数和变量。 可以导入多个模快。可以从模块中导入指定的模块属性（把指定的名称导入）。123import ModuleNameimport ModuleName1,ModuleName2,...from Module1 import ModuleElement 包(package)包是有层次的文件目录结构。 比如说如下的目录结构定义了一个由模块和子包组成的Python应用程序执行环境：123456789101112AAA/ __init__.py bbb.py CCC/ __init__.py c1.py c2.py DDD/ __init__.py d1.py EEE/ ... 因此，我们可以这样使用该包：12import AAA.CCC.c1AAA.CCC.c1.func1(123) 或者：12from AAA.CCC.c1 import func1func1(123) 库（library）库是一组具有相关功能的模块的集合。Python的一大特色就是具有强大的标准库、以及第三方库、以及自定义的模块。 条件、循环与中断语句条件语句if语句else语句elif语句：多分支情况下使用 其中，条件语句可以嵌套使用。 循环语句for循环12for iter_var in interable_object: suite_to_repeat 可以明确循环的次数，一般用在： 遍历一个数据集的成员 在列表解析中使用 1234in[4]: [i for i in range(10)]Out[4]: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]in[5]: [i for i in range(10)if i%2==0]Out[5]: [0, 2, 4, 6, 8] 在生成器表达式中使用 12in[6]: (i for i in range(10)if i%2==0)Out[6]: &lt;generator object &lt;genexpr&gt; at 0x7f44af56f570&gt; 可用于迭代的对象（iterable object）有：String、 List、Tuple、Dictionary、File。 range语句一般与for语句配合使用。 while循环语法：12while expression: suitr_to_repeat 其中，expression是条件表达式，当expression的值为 True的时候，执行suitr_to_repeat的代码块。 break语句while循环中的break与for循环中的break。 循环中的else语句循环中的else：如果是正常结束，就执行else中的代码；break处中止，就不执行else。 自定义函数自定义函数的创建：123def function_name([arguments]): &quot;optional documentation string&quot; function_suite 其中，def下一行可以是函数文档。～～～～～要学会使用函数文档！！ 自定义函数的调用函数名加上函数运算符，一对小括号。 括号之间是所有可选的参数，即使没有参数，小括号也不能省略。 参数问题，有参数就必须加上去。除非有默认值的可以不需要。 默认参数函数的参数可以有一个默认值，如果提供有默认值，在函数定义中，默认参数以赋值语句的形式提供。 默认参数的值可以改变。 默认参数一般需要放置在参数列表的最后。默认参数后面不能有非默认参数。 关键字参数关键字参数是让调用者通过使用参数名区分参数。允许你改变参数列表中的参数顺序。 传递函数函数可以像参数一样传递给另外一个参数。1234567def addMe2Me(x): return (x+x)def self(f,y): print f(y)&gt;&gt;&gt; self(addMe2Me,2.2)4.4 lambda函数匿名函数。 12345678# 普通的函数def my_add(x,y): return x+y# 匿名函数lambda x, y : x + ymy_add = lambda x, y : x + y&gt;&gt;&gt; my_add(3,5)8 变量的作用域全局变量和局部变量函数内部就是局部变量。 函数内部可以调用全局变量，使用global语句。 当全局变量和局部变量使用的是同一个名字时，内层会屏蔽外层。 递归递归介绍递归必须有边界条件，即停止递归的条件。 如n==0 或者n==1的情况。 递归的代码更简洁，更符合自然逻辑，更容易理解。 递归的执行方式：逐层递归调用，遇到边界条件停止递归，逐层返回调用至最初层，系统资源的消耗比循环大。 汉诺塔123456789101112# Filename: Hanoi.pydef hanoi(a, b, c, n): if n == 1: print(a, '-&gt;', c) else: hanoi(a, c, b, n - 1) print(a, '-&gt;', c) hanoi(b, a, c, n - 1)hanoi("a", "b", "c", 3) 运行结果：1234567a -&gt; ca -&gt; bc -&gt; ba -&gt; cb -&gt; ab -&gt; ca -&gt; c]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DeepLab简介及其pytorch实现]]></title>
    <url>%2F2017%2F11%2F23%2FTorch_DeepLab%2F</url>
    <content type="text"><![CDATA[pytorch实现DeepLab使用pytorch搭建DeepLab。 DeepLab简介DeepLab文章的下载地址：https://arxiv.org/abs/1606.00915 该文章的主要思想之一：提出了Atrous convolution（带孔卷积）。扩大视野但不增加计算量。 所谓的带孔卷积，就是在卷积核之间加上0。rate参数为2（torch中对应的参数为dilation）的示意图如下 rate = 2就是在原卷积核相邻两个元素之间补上一个0，假设原卷积核为3x3，rate = 2的带孔卷积核的大小就为3+(3-1) × (rate-1)=5。 下图是不同rate的带孔卷积。 以rate = 12 为例，带孔卷积的核的大小为：3+(3-1)x(12-1)=25，即新卷积核的大小为：25*25。 总的来说，对于rate=r的带孔卷积，在连接着的卷积核元素间插入r-1个元素。因此，扩展后的卷积核大小为$k_{new}=k+(k-1)(r-1)$。 pytorch实现deeplab笔者主要目的是实现一下不同视野的concat过程。 在torch中，卷积函数如下：12import torch.nn as nnnn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True) 其中的dilation参数就是带孔卷积的参数（也就是tensorFlow下的rate），默认情况下为1，就是普通的卷积，所以带孔卷积只需要修改这个参数就可以了。 比如说，我们已经写好了不同的视野下的卷积，然后需要将他们的feature map叠加起来，torch中使用torch.cat(inputs, dimension=0)函数来进行叠加。torch的参数一般是四个维度的：[n_batch_size, n_feature_map, height, weight]，所以参数中的dimension = 1就是对feature map叠加。代码如下： 1x = torch.cat([x2, x3, x4, x5], dim=1) 叠加的这一步非常容易出错，原因在于，要求叠加的所有图片大小是一样的。而视野不同导致的卷积核的大小不同，也会导致最终输出的图像大小的变化，因此，需要恰当的调整zero-padding的数目来使得最终输出图像的大小保持一致。 另外稍微提一下，全连接层的输入向量大小的确定方法。全连接层是将上一步所得到的图像reshape为一个一维的向量之后，作为它的输入，因此，输入向量的长度为： in_channels = nFeatureMap * height * weight。 网络整体代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(1, 10, kernel_size=5, padding=1) self.conv2 = nn.Conv2d(10, 10, kernel_size=5, padding=1) self.conv2_drop = nn.Dropout2d() self.fc1 = nn.Linear(40 * 4 * 5 * 5, 50) self.fc2 = nn.Linear(50, 10) self.conv_rate_1 = nn.Conv2d(10, 20, kernel_size=3, dilation=2, padding=2) self.conv_rate_2 = nn.Conv2d(20, 40, kernel_size=3, dilation=3, padding=3) self.conv_rate_3 = nn.Conv2d(20, 40, kernel_size=3, dilation=4, padding=4) self.conv_rate_4 = nn.Conv2d(20, 40, kernel_size=3, dilation=5, padding=5) self.conv_rate_5 = nn.Conv2d(20, 40, kernel_size=1, padding=0) def forward(self, x): x = F.max_pool2d(F.relu(self.conv1(x)), 2) x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2)) x = self.conv_rate_1(x) x2 = self.conv_rate_2(x) x3 = self.conv_rate_3(x) x4 = self.conv_rate_4(x) x5 = self.conv_rate_5(x) # print(x.data.shape) # print(x2.data.shape) # print(x3.data.shape) # print(x4.data.shape) # print(x5.data.shape) x = torch.cat([x2, x3, x4, x5], dim=1) # for FC x = x.view(-1, self.num_flat_features(x)) # origin is 320 x = F.relu(self.fc1(x)) # fc-&gt;relu x = F.dropout(x, training=self.training) # dropout x = self.fc2(x) return F.log_softmax(x) def num_flat_features(self, x): size = x.size()[1:] # all dimensions except the batch dimension num_features = 1 for s in size: num_features *= s return num_features]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习系列：（七）深度学习中的正则化]]></title>
    <url>%2F2017%2F10%2F22%2FDL_chap_7%2F</url>
    <content type="text"><![CDATA[7.1 参数范式惩罚对目标模型J添加一个参数范数惩罚$\Omega (\theta)$，限制模型 的学习能力。正则化后的目标函数记为：$$\tilde{J}(\theta ;X,y) = J(\theta ;X,y) +\alpha \Omega (\theta)$$ 我们通常只对权重做惩罚而不对偏置做正则惩罚。 神经网络情况下，有时候希望对网络的每一层使用单独的惩罚，并分配不同的$\alpha$系数。寻找合适的多个超参数的代价很大，因此为了减少搜索空间，我们会在所以层使用相同的权重衰减。 符号约束说明：向量$w$表示所有应受范数惩罚影响的权重，而向量$\theta$表示所有参数（包括w和无须正则化的参数）。 7.1.1 $L^2$参数正则化5.2节中已经见过最简单的、最常见的$L^2$参数范数惩罚。其正则项为：$$\Omega (\theta) = \frac 12 ||w||^2_2$$ 令$w^\ast $为未正则化的目标函数取得最小训练误差时的权重向量，即$w^\ast =\text {argmin}_w J(w)$，并在$w^\ast $的邻域对目标函数做二次近似。 近似的$\hat J (\theta)$如下： $$\hat J (\theta) = J (w^\ast) + \frac 12 (w-w^\ast)^TH(w-w^\ast) $$ 其中，$H$是$J$在$w^\ast $处计算的Hessian矩阵（关于$w$）。因为$w^\ast $被定义为最优，所以该二次近似中没有一阶项。同样地，因为$w^\ast $是$J$的一个最优点，可以得出$H$是半正定。 7.1.2 $L^1$正则化7.2 作为约束的范数惩罚7.3 正则化和欠约束问题7.4 数据集增强使用更多的数据进行训练。 创建假数据并添加到训练集中。 图像：沿着训练图像每个方向平移几个像素。旋转。缩放。 数据集增强对语音识别也是有效的。 网络输入层注入噪声， 算法性能对比时，应确保算法使用同一 人工设计的数据集增强方案。 7.5 噪声鲁棒性7.6 半监督学习在半监督学习的框架下，$P(x)$产生的未标记样本和$P(x,y)$中的标记样本都用于估计$P(y|x)$或者根据x预测y。 半监督学习通常是学习一个表示：$h=f(x)$。学习表示的目的是使相同类的样本有类似的表示。 无监督学习可以为如何在空间聚集样本提供有用的线索。 模型的构建：生成模型$P(x)$或$P(x,y)$与判别模型$P(y|x)$共享参数，而不用分离无监督和监督部分。权衡监督模型准则$-\text{log}P(y|x)$和无监督(或生成)模型准则$-\text{log}P(x)$或$-\text{log}P(x,y)$。 生成模型准则表达了对 监督学习问题的特殊形式的先验知识，即$P(x)$的结构通过某种共享参宿的方式连接到$P(y|x)$。 7.7 多任务学习7.8 提前终止在训练有足够表示能力甚至会过拟合的大模型时，经常会出现：训练误差随着时间推移逐渐降低但验证集的误差会再次上升。 此时，我们只需要返回验证集误差最低的参数设置。 在每次验证集误差有所改善时，我们存储模型参数的副本。当验证集的误差在事先指定的循环次数内没有进一步改善时，算法就会终止。 这就是提前终止（early stopping）。 两个代价：一是训练步数作为超参数，训练期间需要定期评估验证集。而是需要保持最佳的参数副本。 提前终止是一个不显眼的正则化形式。 提前终止需要验证集，意味着一部分训练数据不能馈送到模型。为了更好地利用这部分数据，可以在提前终止的首次训练后，进行额外的训练。在第二轮（额外的）训练中，所有的训练数据都被包括在内。 未完待续。 7.9 参数绑定和参数共享7.10 稀疏表示7.13 Bagging和其他集成方法Bagging(bootstrap aggregating)是通过结合几个模型降低泛化误差的技术。 主要想法是分别训练几个不同的模型，然后让所有模型表决测试样例的输出。 这是机器学习的一项常规策略，被称为：模型平均（model averaging）。采用这种策略的技术被称为：集成方法。 7.12 Dropout7.13 对抗训练7.14 切面距离、正切传播和流形正切分类器]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习系列：（九）卷积网络]]></title>
    <url>%2F2017%2F10%2F20%2FDL_chap_9%2F</url>
    <content type="text"><![CDATA[9.1 卷积运算卷积的第一个参数： 输入，第二个参数： 核函数。输出有时被称为特征映射。 对于二维图像I，二维的核K。卷积可以写为： $$S(i,j) = (I\times K )(i,j) = \sum_m \sum_n I(m,n)K(i-m,j-n)$$ 卷积是可交换的。可以等价地写为： $$S(i,j) = (K\times I )(i,j) = \sum_m \sum_n I(i-m,j-n)K(m,n)$$ 卷积运算可交换性的出现时因为我们将核相对输入进行了翻转(flip)，从m增大的角度来看，输入的索引在增大，但是核的索引在减小。 互相关函数：和卷积一样，但是没有对核翻转，互相关函数的公式如下： $$S(i,j) = (I\times K )(i,j) = \sum_m \sum_n I(i+m,j+n)K(m,n)$$ 9.2 动机卷积运算的三个重要思想： 参数共享–绑定的权重。在一个模型的多个函数中使用相同的参数。 平移等变–输入改变，输出也以同样的方式改变。 9.3 池化池化函数：使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出。 最大池化函数（Max pooling）：相邻矩形区域内的最大值 其他常用的池化函数：相邻区域内的平均值，L2范数，基于距中心像素位置的加权平均函数。 局部平移不变性。 池化综合了全部邻居的反馈，这使得池化单元少于探测单元成为可能，我们可以通过综合池化区域的k个像素的统计特征而不是单个像素来实现。这种方式提高了网络的计算效率，因为下一层少了约k倍的输入。（downsampling） 9.4 卷积与池化作为一种无限强的先验先验概率分布（第5.2节）。弱先验具有较高的熵值，强先验具有较低的熵值。 一个无限强的先验需要对一些参数的概率置零并且完全禁止对这些参数赋值。 可以把卷机网络类比为全连接网络，但对于这个全连接网络的权重有一个无限强的先验。这个无限强的先验是说一个隐藏单元的权重必须和它邻居的权重相同，但可以在空间上移动。这个先验也要求除了那些处在隐藏单元的小的空间连续的接受域内的权重以外，其余的权重为零。 类似地，使用池化也是一个无限强的先验：每个单元都具有对少量平移的不变性。 卷积和池化可能导致欠拟合。 9.5 基本卷积函数的变体神经网络中的卷积是由多个并行卷积组成的计算：单个核的卷积只能提取一种类型的特征。 卷积的输入输出可以看作3维的张量，其中一个索引用于标明不同的通道，另外两个索引用于标明每一个通道上的空间坐标。 $$Z_{i,j,k}= c(K,V,s)_{i,j,k}= \sum\limits_{l,m,n}[V_{l,(j - 1) \times s + m,(k - 1) \times s + m} K_{i,l,m,n}]$$输入是观测数据V，每个元素是$V_{i,j,k}$，表示通道i中第j行第k列的值。$K_{i,j,k,l}$输出通道i的一个单元和输入通道j中的一个单元的链接强度，并且在输出单元和输入单元之间有k行l列的偏置。 三种零填充方式： 有效(valid)卷积：不适用零填充。输出的大小在每一层都会缩减。 相同(same)卷积：进行足够的零填充，保持输出和输入 全(full)卷积：每个像素咋每个方向上恰好被访问k次，最终输出的图像宽度为m+k-1。 通常零填充的最优数量处于“有效卷积”和“相同卷积”之间的某个位置。 三种卷积方式： 非共享卷积(unsahred convolution)：不横跨位置来共享参数。局部连接层没有参数共享。 平铺卷积(tiled convolution)：学习一组核，当在空间移动时它们可以循环利用。平铺卷积有t个不同的核。 标准卷积(standard convolution)：等效于t=1的平铺卷积。 9.6 结构化输出卷积神经网络可以输出高维的结构化对象，通常这个对象只是一个张量，由标准卷积层产生。 假设为$S$，其中$S_{i,j,k}$是网络的输入像素$(j,k)$属于类$i$的概率。这允许模型标记图像中的每个像素，并绘制沿着单个对象轮廓的精确掩膜。 9.7 数据类型卷积网络的优点：可以处理具有可变的空间尺度的输入。 可变尺寸的输入，仅对输入是因为包含对同种事物的不同量的观察（时间上不同长度的记录，空间上不同宽度的观察等）而导致的尺寸变化才有意义。 9.8 高效的卷积算法朴素卷积$O(w^d) $与可分离(seperable)卷积$O(w\times d) $。 9.9 随机或无监督的特征卷积网络训练中最昂贵的部分是学习特征。（输出层计算代价相对不高，池化后特征少）减少训练成本：使用那些不是由监督方式得到的特征。 三种基本策略： 简单地随机初始化它们； 手动设计它们，如设置每个核在一个特定的方向或尺度来检测边缘； 使用无监督的标准来学习核。 9.10 卷积网络的神经科学基础初级视觉皮层(primary visual cortex)。 Gabor函数(Gabor function)。 9.11 卷积网络与深度学习的历史ImageNet]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[import TensorFlow出错解决方案]]></title>
    <url>%2F2017%2F10%2F19%2Ftensorflow_import_error%2F</url>
    <content type="text"><![CDATA[出错与解决历程先介绍一下我的python环境：3.5.2 一开始是tensorflow找不到cudn的几个库，虽然问题不大。看到有教程说要升级tensorflow（ 请不要尝试升级 ），于是抱着试试看的想法，升级了tensorflow版本： pip install –trusted-host pypi.python.org –upgrade tensorflow-gpu 升级之后是1.3.0的最新版本。 接着import tensorflow的时候，出现错误： Traceback (most recent call last): File &quot;C:\Users\Admin\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py&quot;, line 18, in swig_import_helper return importlib.import_module(mname) File &quot;C:\Users\Admin\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py&quot;, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 986, in _gcd_import File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 969, in _find_and_load File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 958, in _find_and_load_unlocked File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 666, in _load_unlocked File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 577, in module_from_spec File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 906, in create_module File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 222, in _call_with_frames_removed ImportError: DLL load failed: The specified module could not be found. During handling of the above exception, another exception occurred: Traceback (most recent call last): File &quot;C:\Users\Admin\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py&quot;, line 41, in &lt;module&gt; from tensorflow.python.pywrap_tensorflow_internal import * File &quot;C:\Users\Admin\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py&quot;, line 21, in &lt;module&gt; _pywrap_tensorflow_internal = swig_import_helper() File &quot;C:\Users\Admin\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py&quot;, line 20, in swig_import_helper return importlib.import_module(&apos;_pywrap_tensorflow_internal&apos;) File &quot;C:\Users\Admin\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py&quot;, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) ImportError: No module named &apos;_pywrap_tensorflow_internal&apos; During handling of the above exception, another exception occurred: Traceback (most recent call last): File &quot;&lt;pyshell#0&gt;&quot;, line 1, in &lt;module&gt; import tensorflow as tf File &quot;C:\Users\Admin\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\__init__.py&quot;, line 24, in &lt;module&gt; from tensorflow.python import * File &quot;C:\Users\Admin\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\__init__.py&quot;, line 51, in &lt;module&gt; from tensorflow.python import pywrap_tensorflow File &quot;C:\Users\Admin\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py&quot;, line 52, in &lt;module&gt; raise ImportError(msg) ImportError: Traceback (most recent call last): File &quot;C:\Users\Admin\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py&quot;, line 18, in swig_import_helper return importlib.import_module(mname) File &quot;C:\Users\Admin\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py&quot;, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 986, in _gcd_import File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 969, in _find_and_load File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 958, in _find_and_load_unlocked File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 666, in _load_unlocked File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 577, in module_from_spec File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 906, in create_module File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 222, in _call_with_frames_removed ImportError: DLL load failed: The specified module could not be found. During handling of the above exception, another exception occurred: Traceback (most recent call last): File &quot;C:\Users\Admin\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py&quot;, line 41, in &lt;module&gt; from tensorflow.python.pywrap_tensorflow_internal import * File &quot;C:\Users\Admin\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py&quot;, line 21, in &lt;module&gt; _pywrap_tensorflow_internal = swig_import_helper() File &quot;C:\Users\Admin\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py&quot;, line 20, in swig_import_helper return importlib.import_module(&apos;_pywrap_tensorflow_internal&apos;) File &quot;C:\Users\Admin\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py&quot;, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) ImportError: No module named &apos;_pywrap_tensorflow_internal&apos; Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/install_sources#common_installation_problems for some common reasons and solutions. Include the entire stack trace above this error message when asking for help. 查找到相关解决方案： https://stackoverflow.com/questions/43942185/failed-to-load-the-native-tensorflow-runtime-python-3-5-2 按照高票回答上面做出来后，依旧无效。其中5.1步骤找“curses”，需要pip install curses (从http://www.lfd.uci.edu/~gohlke/pythonlibs/) 简直气疯了。然后，尝试下载了cuda cudnn 9.0的版本，并且加上了系统环境变量，依旧无效。 之后在贴吧http://tieba.baidu.com/p/5147977587 看到11楼说： 我也是同样的问题 是tensorflow-gpu版本不兼容的问题 之前是1.3 后来安装的的1.0.1 亲测有效 于是回退tensorflow的版本。 http://www.lfd.uci.edu/~gohlke/pythonlibs/ 下载了1.1.0版本。 Traceback (most recent call last): File &quot;D:\python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py&quot;, line 41, in &lt;module&gt; from tensorflow.python.pywrap_tensorflow_internal import * File &quot;D:\python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py&quot;, line 35, in &lt;module&gt; _pywrap_tensorflow_internal = swig_import_helper() File &quot;D:\python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py&quot;, line 30, in swig_import_helper _mod = imp.load_module(&apos;_pywrap_tensorflow_internal&apos;, fp, pathname, description) File &quot;D:\python\Python35\lib\imp.py&quot;, line 242, in load_module return load_dynamic(name, filename, file) File &quot;D:\python\Python35\lib\imp.py&quot;, line 342, in load_dynamic return _load(spec) ImportError: DLL load failed: 找不到指定的模块。 During handling of the above exception, another exception occurred: Traceback (most recent call last): File &quot;D:/python/py3_prog/TensorFlow/setup_test.py&quot;, line 4, in &lt;module&gt; import tensorflow as tf File &quot;D:\python\Python35\lib\site-packages\tensorflow\__init__.py&quot;, line 24, in &lt;module&gt; from tensorflow.python import * File &quot;D:\python\Python35\lib\site-packages\tensorflow\python\__init__.py&quot;, line 51, in &lt;module&gt; from tensorflow.python import pywrap_tensorflow File &quot;D:\python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py&quot;, line 52, in &lt;module&gt; raise ImportError(msg) ImportError: Traceback (most recent call last): File &quot;D:\python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py&quot;, line 41, in &lt;module&gt; from tensorflow.python.pywrap_tensorflow_internal import * File &quot;D:\python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py&quot;, line 35, in &lt;module&gt; _pywrap_tensorflow_internal = swig_import_helper() File &quot;D:\python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py&quot;, line 30, in swig_import_helper _mod = imp.load_module(&apos;_pywrap_tensorflow_internal&apos;, fp, pathname, description) File &quot;D:\python\Python35\lib\imp.py&quot;, line 242, in load_module return load_dynamic(name, filename, file) File &quot;D:\python\Python35\lib\imp.py&quot;, line 342, in load_dynamic return _load(spec) ImportError: DLL load failed: 找不到指定的模块。 Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/install_sources#common_installation_problems for some common reasons and solutions. Include the entire stack trace above this error message when asking for help. 提示缺少dll。在c/windows/system32中添加了一下msvcp140.dll （680kb的，不是400多kb的）问题终于解决。 dll问题具体方案：https://www.microsoft.com/en-us/download/details.aspx?id=53587下载Microsoft Visual C++ 2015 Redistributable 并安装。 更多解决办法可参考：https://github.com/tensorflow/tensorflow/issues/8385 总结一下 千万不要去更新tensorflow的版本。能用就行，不要用最新的1.3.0版本。 cuda，cudnn也不要用最新的9.0版本，就用8.0版本即可。 import tensorflow出错时，有几个方向检查：cudn/cudaa环境变量，dll库的问题，版本是否匹配：python3.5，回退tensorflow版本，回退cuda/cudnn版本。]]></content>
      <categories>
        <category>TensorFlow系列</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习中防止过拟合的方法]]></title>
    <url>%2F2017%2F10%2F18%2FDL_overfitting%2F</url>
    <content type="text"><![CDATA[0. 什么是过拟合过拟合即在训练误差很小，而泛化误差很大，因为模型可能过于的复杂，使其”记住”了训练样本，然而其泛化误差却很大。 在传统的机器学习方法中有很大防止过拟合的方法，同样这些方法很多也适合用于深度学习中，同时深度学习中又有一些独特的防止过拟合的方法，下面对其进行简单的梳理。 1. 获取更多数据让模型泛化的能力更好的最好办法就是使用更多的训练数据进行训练，但是在实践中，我们拥有的数据是有限的，解决这一问题可以人为的创造一些假数据添加到训练集中。 一个具体的例子:在AlexNet中，将$256\times 256$图像随机的截取$224\times 224$大小，增加了许多的训练样本，同时可以对图像进行左右翻转，增加样本的个数，实验的结果可以可降低1%的误差。 在神经网络中输入噪声也可以看做是数据增强的一种方式。 通俗得讲，数据集扩增即需要得到更多的符合要求的数据，即和已有的数据是独立同分布的，或者近似独立同分布的。一般有以下方法： 从数据源头采集更多数据 复制原有数据并加上随机噪声 重采样 根据当前数据集估计数据分布参数，使用该分布产生更多数据等 2.选用合适的模型2.1 网络结构 Architecture这个很好理解，减少网络的层数、神经元个数等均可以限制网络的拟合能力。 2.2 参数范数惩罚 regularization范数正则化是一种非常普遍的方法，也是最常用的方法，假如优化: $$minObj(\theta)=L(y,f(x))+\alpha G(\theta)$$ 其中L为经验风险，其为在训练样本上的误差，而G为对参数的惩罚，也叫结构风险。α是平衡两者，如果太大则对应的惩罚越大，如过太小，甚至接近与0，则没有惩罚。 最常用的范数惩罚为L1，L2正则化。 L1正则L1又被成为Lasso:$$||w||1=|w1|+|w2|+…$$ 即绝对值相加，其趋向于是一些参数为0。可以起到特征选择的作用。 L2正则L2正则化为: $$||w||_2=w12+w22+…$$ L2范数是指向量各元素的平方和然后求平方根。它有两个美称，在回归里面，有人把有它的回归叫“岭回归”（Ridge Regression），有人也叫它“权值衰减weight decay”。它的强大功效是改善机器学习里面一个非常重要的问题：过拟合。 其趋向与，使权重很小。其又成为ridge。 拟合过程中通常都倾向于让权值尽可能小，最后构造一个所有参数都比较小的模型。因为一般认为参数值小的模型比较简单，能适应不同的数据集，也在一定程度上避免了过拟合现象。可以设想一下对于一个线性回归方程，若参数很大，那么只要数据偏移一点点，就会对结果造成很大的影响；但如果参数足够小，数据偏移得多一点也不会对结果造成什么影响，专业一点的说法是『抗扰动能力强』。 这里也一句话总结下：通过L2范数，我们可以实现了对模型空间的限制，从而在一定程度上避免了过拟合。 关于更多正则化的内容可以参考《deep learning》第七章：深度学习中的正则化。 2.3 训练时间 Early stopping当随着模型的能力提升，训练集的误差会先减小再增大，这样可以提前终止算法减缓过拟合现象。 Early stopping方法的具体做法是，在每一个Epoch结束时（一个Epoch集为对所有的训练数据的一轮遍历）计算validation data的accuracy，当accuracy不再提高时，就停止训练。这种做法很符合直观感受，因为accurary都不再提高了，在继续训练也是无益的，只会提高训练的时间。那么该做法的一个重点便是怎样才认为validation accurary不再提高了呢？并不是说validation accuracy一降下来便认为不再提高了，因为可能经过这个Epoch后，accuracy降低了，但是随后的Epoch又让accuracy又上去了，所以不能根据一两次的连续降低就判断不再提高。一般的做法是，在训练的过程中，记录到目前为止最好的validation accuracy，当连续10次Epoch（或者更多次）没达到最佳accuracy时，则可以认为accuracy不再提高了。此时便可以停止迭代了（Early Stopping）。这种策略也称为“No-improvement-in-n”，n即Epoch的次数，可以根据实际情况取，如10、20、30…… 提前终止是一种很常用的缓解过拟合的方法，如在决策树的先剪枝的算法，提前终止算法，使得树的深度降低，防止其过拟合。 添加噪声给网络加噪声也有很多方法： 在输入中加噪声 在权值上加噪声 对网络的响应加噪声 3. 结合多种模型集成学习是一种比较奇特的方法，如果我们训练多个不同的模型，然后将它们的输出汇总，例如平均起来或者投票汇总，那么汇总的结果可以在一定程度上自动克服过拟合，哪怕每个模型都过拟合了。 3.1 bagging boostingBagging 是 Bootstrap Aggregating 的简称。简单理解：就是分段函数的概念：用不同的模型拟合不同部分的训练集。 其实bagging的方法是可以起到正则化的作用，因为正则化就是要减少泛化误差，而bagging的方法可以组合多个模型起到减少泛化误差的作用。在深度学习中同样可以使用此方法，但是其会增加计算和存储的成本。 由于训练网络本身就要耗费较多资源，所以一般不单独使用神经网络做bagging。 类似的还有boosting。 bagging中的模型是强模型，偏差低，方差高。目标是降低方差。在bagging中，每个模型的bias和variance近似相同，但是互相相关性不太高，因此一般不能降低Bias，而一定程度上能降低variance。典型的bagging是random forest。 boosting中每个模型是弱模型，偏差高，方差低。目标是通过平均降低偏差。boosting的基本思想就是用贪心法最小化损失函数，显然能降低偏差，但是通常模型的相关性很强，因此不能显著降低variance。典型的Boosting是adaboost，另外一个常用的并行Boosting算法是GBDT（gradient boosting decision tree）。这一类算法通常不容易出现过拟合。 3.2 Dropout正则是通过在代价函数后面加上正则项来防止模型过拟合的。而在神经网络中，有一种方法是通过修改神经网络本身结构来实现的，其名为Dropout。该方法是在对网络进行训练时用一种技巧（trick），对于如下所示的三层人工神经网络： 对于上图所示的网络，在训练开始时，随机得删除一些（可以设定为一半，也可以为1/3，1/4等）隐藏层神经元，即认为这些神经元不存在，同时保持输入层与输出层神经元的个数不变，这样便得到如下的ANN： 然后按照BP学习算法对ANN中的参数进行学习更新（虚线连接的单元不更新，因为认为这些神经元被临时删除了）。这样一次迭代更新便完成了。下一次迭代中，同样随机删除一些神经元，与上次不一样，做随机选择。这样一直进行下去，直至训练结束。 Dropout提供了一种廉价的Bagging集成近似，能够训练和评估指数级数量的神经网络。dropout可以随机的让一部分神经元失活，这样仿佛是bagging的采样过程，因此可以看做是bagging的廉价的实现。但是它们训练不太一样，因为bagging，所有的模型都是独立的，而dropout下所有模型的参数是共享的。 通常可以这样理解dropout:假设我们要判别一只猫，有一个神经元说看到有毛就是猫，但是如果我让这个神经元失活，它还能判断出来是猫的话，这样就比较具有泛化的能力，减轻了过拟合的风险。 4. Batch Normalization在Google Inception V2中所采用，是一种非常有用的正则化方法，可以让大型的卷积网络训练速度加快很多倍，同事收敛后分类的准确率也可以大幅度的提高。BN在训练某层时，会对每一个mini-batch数据进行标准化(normalization)处理，使输出规范到N(0,1)的正太分布，减少了Internal convariate shift(内部神经元分布的改变)，传统的深度神经网络在训练是，每一层的输入的分布都在改变，因此训练困难，只能选择用一个很小的学习速率，但是每一层用了BN后，可以有效的解决这个问题，学习速率可以增大很多倍。 5. 参数绑定与参数共享在卷积神经网络CNN中(计算机视觉与卷积神经网络 )，卷积层就是其中权值共享的方式，一个卷积核通过在图像上滑动从而实现共享参数，大幅度减少参数的个数，用卷积的形式是合理的，因为对于一副猫的图片来说，右移一个像素同样还是猫，其具有局部的特征。这是一种很好的缓解过拟合现象的方法。 同样在RNN中用到的参数共享，在其整条时间链上可以进行参数的共享，这样才使得其能够被训练。 6. 辅助分类节点(auxiliary classifiers)在Google Inception V1中，采用了辅助分类节点的策略，即将中间某一层的输出用作分类，并按一个较小的权重加到最终的分类结果中，这样相当于做了模型的融合，同时给网络增加了反向传播的梯度信号，提供了额外的正则化的思想。 参考资料 http://blog.csdn.net/taoyanqi8932/article/details/71101699 http://blog.csdn.net/heyongluoyao8/article/details/49429629 https://www.zhihu.com/question/26760839 https://www.zhihu.com/question/59201590 https://www.zhihu.com/question/26898675 正则化 http://blog.csdn.net/jinping_shi/article/details/52433975]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>overfitting</tag>
        <tag>过拟合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[党的十九大报告全文]]></title>
    <url>%2F2017%2F10%2F18%2FOpening_ceremony_19th_CPC%2F</url>
    <content type="text"><![CDATA[中国共产党第十九次全国代表大会开幕会今天上午9点在人民大会堂大礼堂举行。习近平代表第十八届中央委员会向党的十九大作报告。 以下是报告全文： 同志们： 现在，我代表第十八届中央委员会向大会作报告。 中国共产党第十九次全国代表大会，是在全面建成小康社会决胜阶段、中国特色社会主义进入新时代的关键时期召开的一次十分重要的大会。 大会的主题是：不忘初心，牢记使命，高举中国特色社会主义伟大旗帜，决胜全面建成小康社会，夺取新时代中国特色社会主义伟大胜利，为实现中华民族伟大复兴的中国梦不懈奋斗。 不忘初心，方得始终。中国共产党人的初心和使命，就是为中国人民谋幸福，为中华民族谋复兴。这个初心和使命是激励中国共产党人不断前进的根本动力。全党同志一定要永远与人民同呼吸、共命运、心连心，永远把人民对美好生活的向往作为奋斗目标，以永不懈怠的精神状态和一往无前的奋斗姿态，继续朝着实现中华民族伟大复兴的宏伟目标奋勇前进。 当前，国内外形势正在发生深刻复杂变化，我国发展仍处于重要战略机遇期，前景十分光明，挑战也十分严峻。全党同志一定要登高望远、居安思危，勇于变革、勇于创新，永不僵化、永不停滞，团结带领全国各族人民决胜全面建成小康社会，奋力夺取新时代中国特色社会主义伟大胜利。 一、过去五年的工作和历史性变革 十八大以来的五年，是党和国家发展进程中极不平凡的五年。面对世界经济复苏乏力、局部冲突和动荡频发、全球性问题加剧的外部环境，面对我国经济发展进入新常态等一系列深刻变化，我们坚持稳中求进工作总基调，迎难而上，开拓进取，取得了改革开放和社会主义现代化建设的历史性成就。 为贯彻十八大精神，党中央召开七次全会，分别就政府机构改革和职能转变、全面深化改革、全面推进依法治国、制定“十三五”规划、全面从严治党等重大问题作出决定和部署。五年来，我们统筹推进“五位一体”总体布局、协调推进“四个全面”战略布局，“十二五”规划胜利完成，“十三五”规划顺利实施，党和国家事业全面开创新局面。 经济建设取得重大成就。坚定不移贯彻新发展理念，坚决端正发展观念、转变发展方式，发展质量和效益不断提升。经济保持中高速增长，在世界主要国家中名列前茅，国内生产总值从五十四万亿元增长到八十万亿元，稳居世界第二，对世界经济增长贡献率超过百分之三十。供给侧结构性改革深入推进，经济结构不断优化，数字经济等新兴产业蓬勃发展，高铁、公路、桥梁、港口、机场等基础设施建设快速推进。农业现代化稳步推进，粮食生产能力达到一万二千亿斤。城镇化率年均提高一点二个百分点，八千多万农业转移人口成为城镇居民。区域发展协调性增强，“一带一路”建设、京津冀协同发展、长江经济带发展成效显著。创新驱动发展战略大力实施，创新型国家建设成果丰硕，天宫、蛟龙、天眼、悟空、墨子、大飞机等重大科技成果相继问世。南海岛礁建设积极推进。开放型经济新体制逐步健全，对外贸易、对外投资、外汇储备稳居世界前列。 全面深化改革取得重大突破。蹄疾步稳推进全面深化改革，坚决破除各方面体制机制弊端。改革全面发力、多点突破、纵深推进，着力增强改革系统性、整体性、协同性，压茬拓展改革广度和深度，推出一千五百多项改革举措，重要领域和关键环节改革取得突破性进展，主要领域改革主体框架基本确立。中国特色社会主义制度更加完善，国家治理体系和治理能力现代化水平明显提高，全社会发展活力和创新活力明显增强。 民主法治建设迈出重大步伐。积极发展社会主义民主政治，推进全面依法治国，党的领导、人民当家作主、依法治国有机统一的制度建设全面加强，党的领导体制机制不断完善，社会主义民主不断发展，党内民主更加广泛，社会主义协商民主全面展开，爱国统一战线巩固发展，民族宗教工作创新推进。科学立法、严格执法、公正司法、全民守法深入推进，法治国家、法治政府、法治社会建设相互促进，中国特色社会主义法治体系日益完善，全社会法治观念明显增强。国家监察体制改革试点取得实效，行政体制改革、司法体制改革、权力运行制约和监督体系建设有效实施。 思想文化建设取得重大进展。加强党对意识形态工作的领导，党的理论创新全面推进，马克思主义在意识形态领域的指导地位更加鲜明，中国特色社会主义和中国梦深入人心，社会主义核心价值观和中华优秀传统文化广泛弘扬，群众性精神文明创建活动扎实开展。公共文化服务水平不断提高，文艺创作持续繁荣，文化事业和文化产业蓬勃发展，互联网建设管理运用不断完善，全民健身和竞技体育全面发展。主旋律更加响亮，正能量更加强劲，文化自信得到彰显，国家文化软实力和中华文化影响力大幅提升，全党全社会思想上的团结统一更加巩固。 人民生活不断改善。深入贯彻以人民为中心的发展思想，一大批惠民举措落地实施，人民获得感显著增强。脱贫攻坚战取得决定性进展，六千多万贫困人口稳定脱贫，贫困发生率从百分之十点二下降到百分之四以下。教育事业全面发展，中西部和农村教育明显加强。就业状况持续改善，城镇新增就业年均一千三百万人以上。城乡居民收入增速超过经济增速，中等收入群体持续扩大。覆盖城乡居民的社会保障体系基本建立，人民健康和医疗卫生水平大幅提高，保障性住房建设稳步推进。社会治理体系更加完善，社会大局保持稳定，国家安全全面加强。 生态文明建设成效显著。大力度推进生态文明建设，全党全国贯彻绿色发展理念的自觉性和主动性显著增强，忽视生态环境保护的状况明显改变。生态文明制度体系加快形成，主体功能区制度逐步健全，国家公园体制试点积极推进。全面节约资源有效推进，能源资源消耗强度大幅下降。重大生态保护和修复工程进展顺利，森林覆盖率持续提高。生态环境治理明显加强，环境状况得到改善。引导应对气候变化国际合作，成为全球生态文明建设的重要参与者、贡献者、引领者。 强军兴军开创新局面。着眼于实现中国梦强军梦，制定新形势下军事战略方针，全力推进国防和军队现代化。召开古田全军政治工作会议，恢复和发扬我党我军光荣传统和优良作风，人民军队政治生态得到有效治理。国防和军队改革取得历史性突破，形成军委管总、战区主战、军种主建新格局，人民军队组织架构和力量体系实现革命性重塑。加强练兵备战，有效遂行海上维权、反恐维稳、抢险救灾、国际维和、亚丁湾护航、人道主义救援等重大任务，武器装备加快发展，军事斗争准备取得重大进展。人民军队在中国特色强军之路上迈出坚定步伐。 港澳台工作取得新进展。全面准确贯彻“一国两制”方针，牢牢掌握宪法和基本法赋予的中央对香港、澳门全面管治权，深化内地和港澳地区交流合作，保持香港、澳门繁荣稳定。坚持一个中国原则和“九二共识”，推动两岸关系和平发展，加强两岸经济文化交流合作，实现两岸领导人历史性会晤。妥善应对台湾局势变化，坚决反对和遏制“台独”分裂势力，有力维护台海和平稳定。 全方位外交布局深入展开。全面推进中国特色大国外交，形成全方位、多层次、立体化的外交布局，为我国发展营造了良好外部条件。实施共建“一带一路”倡议，发起创办亚洲基础设施投资银行，设立丝路基金，举办首届“一带一路”国际合作高峰论坛、亚太经合组织领导人非正式会议、二十国集团领导人杭州峰会、金砖国家领导人厦门会晤、亚信峰会。倡导构建人类命运共同体，促进全球治理体系变革。我国国际影响力、感召力、塑造力进一步提高，为世界和平与发展作出新的重大贡献。 全面从严治党成效卓著。全面加强党的领导和党的建设，坚决改变管党治党宽松软状况。推动全党尊崇党章，增强政治意识、大局意识、核心意识、看齐意识，坚决维护党中央权威和集中统一领导，严明党的政治纪律和政治规矩，层层落实管党治党政治责任。坚持照镜子、正衣冠、洗洗澡、治治病的要求，开展党的群众路线教育实践活动和“三严三实”专题教育，推进“两学一做”学习教育常态化制度化，全党理想信念更加坚定、党性更加坚强。贯彻新时期好干部标准，选人用人状况和风气明显好转。党的建设制度改革深入推进，党内法规制度体系不断完善。把纪律挺在前面，着力解决人民群众反映最强烈、对党的执政基础威胁最大的突出问题。出台中央八项规定，严厉整治形式主义、官僚主义、享乐主义和奢靡之风，坚决反对特权。巡视利剑作用彰显，实现中央和省级党委巡视全覆盖。坚持反腐败无禁区、全覆盖、零容忍，坚定不移“打虎”、“拍蝇”、“猎狐”，不敢腐的目标初步实现，不能腐的笼子越扎越牢，不想腐的堤坝正在构筑，反腐败斗争压倒性态势已经形成并巩固发展。 五年来的成就是全方位的、开创性的，五年来的变革是深层次的、根本性的。五年来，我们党以巨大的政治勇气和强烈的责任担当，提出一系列新理念新思想新战略，出台一系列重大方针政策，推出一系列重大举措，推进一系列重大工作，解决了许多长期想解决而没有解决的难题，办成了许多过去想办而没有办成的大事，推动党和国家事业发生历史性变革。这些历史性变革，对党和国家事业发展具有重大而深远的影响。 五年来，我们勇于面对党面临的重大风险考验和党内存在的突出问题，以顽强意志品质正风肃纪、反腐惩恶，消除了党和国家内部存在的严重隐患，党内政治生活气象更新，党内政治生态明显好转，党的创造力、凝聚力、战斗力显著增强，党的团结统一更加巩固，党群关系明显改善，党在革命性锻造中更加坚强，焕发出新的强大生机活力，为党和国家事业发展提供了坚强政治保证。 同时，必须清醒看到，我们的工作还存在许多不足，也面临不少困难和挑战。主要是：发展不平衡不充分的一些突出问题尚未解决，发展质量和效益还不高，创新能力不够强，实体经济水平有待提高，生态环境保护任重道远；民生领域还有不少短板，脱贫攻坚任务艰巨，城乡区域发展和收入分配差距依然较大，群众在就业、教育、医疗、居住、养老等方面面临不少难题；社会文明水平尚需提高；社会矛盾和问题交织叠加，全面依法治国任务依然繁重，国家治理体系和治理能力有待加强；意识形态领域斗争依然复杂，国家安全面临新情况；一些改革部署和重大政策措施需要进一步落实；党的建设方面还存在不少薄弱环节。这些问题，必须着力加以解决。 五年来的成就，是党中央坚强领导的结果，更是全党全国各族人民共同奋斗的结果。我代表中共中央，向全国各族人民，向各民主党派、各人民团体和各界爱国人士，向香港特别行政区同胞、澳门特别行政区同胞和台湾同胞以及广大侨胞，向关心和支持中国现代化建设的各国朋友，表示衷心的感谢！ 同志们！改革开放之初，我们党发出了走自己的路、建设中国特色社会主义的伟大号召。从那时以来，我们党团结带领全国各族人民不懈奋斗，推动我国经济实力、科技实力、国防实力、综合国力进入世界前列，推动我国国际地位实现前所未有的提升，党的面貌、国家的面貌、人民的面貌、军队的面貌、中华民族的面貌发生了前所未有的变化，中华民族正以崭新姿态屹立于世界的东方。 经过长期努力，中国特色社会主义进入了新时代，这是我国发展新的历史方位。 中国特色社会主义进入新时代，意味着近代以来久经磨难的中华民族迎来了从站起来、富起来到强起来的伟大飞跃，迎来了实现中华民族伟大复兴的光明前景；意味着科学社会主义在二十一世纪的中国焕发出强大生机活力，在世界上高高举起了中国特色社会主义伟大旗帜；意味着中国特色社会主义道路、理论、制度、文化不断发展，拓展了发展中国家走向现代化的途径，给世界上那些既希望加快发展又希望保持自身独立性的国家和民族提供了全新选择，为解决人类问题贡献了中国智慧和中国方案。 这个新时代，是承前启后、继往开来、在新的历史条件下继续夺取中国特色社会主义伟大胜利的时代，是决胜全面建成小康社会、进而全面建设社会主义现代化强国的时代，是全国各族人民团结奋斗、不断创造美好生活、逐步实现全体人民共同富裕的时代，是全体中华儿女勠力同心、奋力实现中华民族伟大复兴中国梦的时代，是我国日益走近世界舞台中央、不断为人类作出更大贡献的时代。 中国特色社会主义进入新时代，我国社会主要矛盾已经转化为人民日益增长的美好生活需要和不平衡不充分的发展之间的矛盾。我国稳定解决了十几亿人的温饱问题，总体上实现小康，不久将全面建成小康社会，人民美好生活需要日益广泛，不仅对物质文化生活提出了更高要求，而且在民主、法治、公平、正义、安全、环境等方面的要求日益增长。同时，我国社会生产力水平总体上显著提高，社会生产能力在很多方面进入世界前列，更加突出的问题是发展不平衡不充分，这已经成为满足人民日益增长的美好生活需要的主要制约因素。 我们必须认识到，我国社会主要矛盾的变化没有改变我们所处社会主义历史阶段的判断，我国仍处于并将长期处于社会主义初级阶段的基本国情没有变，我国是世界上最大发展中国家的国际地位没有变。全党要牢牢把握社会主义初级阶段这个基本国情，牢牢立足社会主义初级阶段这个最大实际，牢牢坚持党的基本路线这个党和国家的生命线，人民的幸福线。领导和团结全国各族人民，以经济建设为中心，坚持四项基本原则，坚持改革开放，自力更生，艰苦创业，为把我国建设成为富强、民主、文明、和谐、美丽的社会主义现代化强国而奋斗。 同志们！中国特色社会主义进入新时代，在中华人民共和国发展史上、中华民族发展史上具有重大意义，在世界社会主义发展史上、人类社会发展史上也具有重大意义。全党要坚定信心、奋发有为，让中国特色社会主义展现出更加强大的生命力！ 二、新时代中国共产党的历史使命 一百年前，十月革命一声炮响，给中国送来了马克思列宁主义。中国先进分子从马克思列宁主义的科学真理中看到了解决中国问题的出路。在近代以后中国社会的剧烈运动中，在中国人民反抗封建统治和外来侵略的激烈斗争中，在马克思列宁主义同中国工人运动的结合过程中，一九二一年中国共产党应运而生。从此，中国人民谋求民族独立、人民解放和国家富强、人民幸福的斗争就有了主心骨，中国人民就从精神上由被动转为主动。 中华民族有五千多年的文明历史，创造了灿烂的中华文明，为人类作出了卓越贡献，成为世界上伟大的民族。鸦片战争后，中国陷入内忧外患的黑暗境地，中国人民经历了战乱频仍、山河破碎、民不聊生的深重苦难。为了民族复兴，无数仁人志士不屈不挠、前仆后继，进行了可歌可泣的斗争，进行了各式各样的尝试，但终究未能改变旧中国的社会性质和中国人民的悲惨命运。 实现中华民族伟大复兴是近代以来中华民族最伟大的梦想。中国共产党一经成立，就把实现共产主义作为党的最高理想和最终目标，义无反顾肩负起实现中华民族伟大复兴的历史使命，团结带领人民进行了艰苦卓绝的斗争，谱写了气吞山河的壮丽史诗。 我们党深刻认识到，实现中华民族伟大复兴，必须推翻压在中国人民头上的帝国主义、封建主义、官僚资本主义三座大山，实现民族独立、人民解放、国家统一、社会稳定。我们党团结带领人民找到了一条以农村包围城市、武装夺取政权的正确革命道路，进行了二十八年浴血奋战，完成了新民主主义革命，一九四九年建立了中华人民共和国，实现了中国从几千年封建专制政治向人民民主的伟大飞跃。 我们党深刻认识到，实现中华民族伟大复兴，必须建立符合我国实际的先进社会制度。我们党团结带领人民完成社会主义革命，确立社会主义基本制度，推进社会主义建设，完成了中华民族有史以来最为广泛而深刻的社会变革，为当代中国一切发展进步奠定了根本政治前提和制度基础，实现了中华民族由近代不断衰落到根本扭转命运、持续走向繁荣富强的伟大飞跃。 我们党深刻认识到，实现中华民族伟大复兴，必须合乎时代潮流、顺应人民意愿，勇于改革开放，让党和人民事业始终充满奋勇前进的强大动力。我们党团结带领人民进行改革开放新的伟大革命，破除阻碍国家和民族发展的一切思想和体制障碍，开辟了中国特色社会主义道路，使中国大踏步赶上时代。 九十六年来，为了实现中华民族伟大复兴的历史使命，无论是弱小还是强大，无论是顺境还是逆境，我们党都初心不改、矢志不渝，团结带领人民历经千难万险，付出巨大牺牲，敢于面对曲折，勇于修正错误，攻克了一个又一个看似不可攻克的难关，创造了一个又一个彪炳史册的人间奇迹。 同志们！今天，我们比历史上任何时期都更接近、更有信心和能力实现中华民族伟大复兴的目标。 行百里者半九十。中华民族伟大复兴，绝不是轻轻松松、敲锣打鼓就能实现的。全党必须准备付出更为艰巨、更为艰苦的努力。 实现伟大梦想，必须进行伟大斗争。社会是在矛盾运动中前进的，有矛盾就会有斗争。我们党要团结带领人民有效应对重大挑战、抵御重大风险、克服重大阻力、解决重大矛盾，必须进行具有许多新的历史特点的伟大斗争，任何贪图享受、消极懈怠、回避矛盾的思想和行为都是错误的。全党要更加自觉地坚持党的领导和我国社会主义制度，坚决反对一切削弱、歪曲、否定党的领导和我国社会主义制度的言行；更加自觉地维护人民利益，坚决反对一切损害人民利益、脱离群众的行为；更加自觉地投身改革创新时代潮流，坚决破除一切顽瘴痼疾；更加自觉地维护我国主权、安全、发展利益，坚决反对一切分裂祖国、破坏民族团结和社会和谐稳定的行为；更加自觉地防范各种风险，坚决战胜一切在政治、经济、文化、社会等领域和自然界出现的困难和挑战。全党要充分认识这场伟大斗争的长期性、复杂性、艰巨性，发扬斗争精神，提高斗争本领，不断夺取伟大斗争新胜利。 实现伟大梦想，必须建设伟大工程。这个伟大工程就是我们党正在深入推进的党的建设新的伟大工程。历史已经并将继续证明，没有中国共产党的领导，民族复兴必然是空想。我们党要始终成为时代先锋、民族脊梁，始终成为马克思主义执政党，自身必须始终过硬。全党要更加自觉地坚定党性原则，勇于直面问题，敢于刮骨疗毒，消除一切损害党的先进性和纯洁性的因素，清除一切侵蚀党的健康肌体的病毒，不断增强党的政治领导力、思想引领力、群众组织力、社会号召力，确保我们党永葆旺盛生命力和强大战斗力。 实现伟大梦想，必须推进伟大事业。中国特色社会主义是改革开放以来党的全部理论和实践的主题，是党和人民历尽千辛万苦、付出巨大代价取得的根本成就。中国特色社会主义道路是实现社会主义现代化、创造人民美好生活的必由之路，中国特色社会主义理论体系是指导党和人民实现中华民族伟大复兴的正确理论，中国特色社会主义制度是当代中国发展进步的根本制度保障，中国特色社会主义文化是激励全党全国各族人民奋勇前进的强大精神力量。全党要更加自觉地增强道路自信、理论自信、制度自信、文化自信，既不走封闭僵化的老路，也不走改旗易帜的邪路，保持政治定力，坚持实干兴邦，始终坚持和发展中国特色社会主义。 伟大斗争，伟大工程，伟大事业，伟大梦想，紧密联系、相互贯通、相互作用，其中起决定性作用的是党的建设新的伟大工程。推进伟大工程，要结合伟大斗争、伟大事业、伟大梦想的实践来进行，确保党在世界形势深刻变化的历史进程中始终走在时代前列，在应对国内外各种风险和考验的历史进程中始终成为全国人民的主心骨，在坚持和发展中国特色社会主义的历史进程中始终成为坚强领导核心。 同志们！使命呼唤担当，使命引领未来。我们要不负人民重托、无愧历史选择，在新时代中国特色社会主义的伟大实践中，以党的坚强领导和顽强奋斗，激励全体中华儿女不断奋进，凝聚起同心共筑中国梦的磅礴力量！ 三、新时代中国特色社会主义思想和基本方略 十八大以来，国内外形势变化和我国各项事业发展都给我们提出了一个重大时代课题，这就是必须从理论和实践结合上系统回答新时代坚持和发展什么样的中国特色社会主义、怎样坚持和发展中国特色社会主义，包括新时代坚持和发展中国特色社会主义的总目标、总任务、总体布局、战略布局和发展方向、发展方式、发展动力、战略步骤、外部条件、政治保证等基本问题，并且要根据新的实践对经济、政治、法治、科技、文化、教育、民生、民族、宗教、社会、生态文明、国家安全、国防和军队、“一国两制”和祖国统一、统一战线、外交、党的建设等各方面作出理论分析和政策指导，以利于更好坚持和发展中国特色社会主义。 围绕这个重大时代课题，我们党坚持以马克思列宁主义、毛泽东思想、邓小平理论、“三个代表”重要思想、科学发展观为指导，坚持解放思想、实事求是、与时俱进、求真务实，坚持辩证唯物主义和历史唯物主义，紧密结合新的时代条件和实践要求，以全新的视野深化对共产党执政规律、社会主义建设规律、人类社会发展规律的认识，进行艰辛理论探索，取得重大理论创新成果，形成了新时代中国特色社会主义思想。 新时代中国特色社会主义思想，明确坚持和发展中国特色社会主义，总任务是实现社会主义现代化和中华民族伟大复兴，在全面建成小康社会的基础上，分两步走在本世纪中叶建成富强民主文明和谐美丽的社会主义现代化强国；明确新时代我国社会主要矛盾是人民日益增长的美好生活需要和不平衡不充分的发展之间的矛盾，必须坚持以人民为中心的发展思想，不断促进人的全面发展、全体人民共同富裕；明确中国特色社会主义事业总体布局是“五位一体”、战略布局是“四个全面”，强调坚定道路自信、理论自信、制度自信、文化自信；明确全面深化改革总目标是完善和发展中国特色社会主义制度、推进国家治理体系和治理能力现代化；明确全面推进依法治国总目标是建设中国特色社会主义法治体系、建设社会主义法治国家；明确党在新时代的强军目标是建设一支听党指挥、能打胜仗、作风优良的人民军队，把人民军队建设成为世界一流军队；明确中国特色大国外交要推动构建新型国际关系，推动构建人类命运共同体；明确中国特色社会主义最本质的特征是中国共产党领导，中国特色社会主义制度的最大优势是中国共产党领导，党是最高政治领导力量，提出新时代党的建设总要求，突出政治建设在党的建设中的重要地位。 新时代中国特色社会主义思想，是对马克思列宁主义、毛泽东思想、邓小平理论、“三个代表”重要思想、科学发展观的继承和发展，是马克思主义中国化最新成果，是党和人民实践经验和集体智慧的结晶，是中国特色社会主义理论体系的重要组成部分，是全党全国人民为实现中华民族伟大复兴而奋斗的行动指南，必须长期坚持并不断发展。全党要深刻领会新时代中国特色社会主义思想的精神实质和丰富内涵，在各项工作中全面准确贯彻落实。 （一）坚持党对一切工作的领导。党政军民学，东西南北中，党是领导一切的。必须增强政治意识、大局意识、核心意识、看齐意识，自觉维护党中央权威和集中统一领导，自觉在思想上政治上行动上同党中央保持高度一致，完善坚持党的领导的体制机制，坚持稳中求进工作总基调，统筹推进“五位一体”总体布局，协调推进“四个全面”战略布局，提高党把方向、谋大局、定政策、促改革的能力和定力，确保党始终总揽全局、协调各方。 （二）坚持以人民为中心。人民是历史的创造者，是决定党和国家前途命运的根本力量。必须坚持人民主体地位，坚持立党为公、执政为民，践行全心全意为人民服务的根本宗旨，把党的群众路线贯彻到治国理政全部活动之中，把人民对美好生活的向往作为奋斗目标，依靠人民创造历史伟业。 （三）坚持全面深化改革。只有社会主义才能救中国，只有改革开放才能发展中国、发展社会主义、发展马克思主义。必须坚持和完善中国特色社会主义制度，不断推进国家治理体系和治理能力现代化，坚决破除一切不合时宜的思想观念和体制机制弊端，突破利益固化的藩篱，吸收人类文明有益成果，构建系统完备、科学规范、运行有效的制度体系，充分发挥我国社会主义制度优越性。 （四）坚持新发展理念。发展是解决我国一切问题的基础和关键，发展必须是科学发展，必须坚定不移贯彻创新、协调、绿色、开放、共享的发展理念。必须坚持和完善我国社会主义基本经济制度和分配制度，毫不动摇巩固和发展公有制经济，毫不动摇鼓励、支持、引导非公有制经济发展，使市场在资源配置中起决定性作用，更好发挥政府作用，推动新型工业化、信息化、城镇化、农业现代化同步发展，主动参与和推动经济全球化进程，发展更高层次的开放型经济，不断壮大我国经济实力和综合国力。 （五）坚持人民当家作主。坚持党的领导、人民当家作主、依法治国有机统一是社会主义政治发展的必然要求。必须坚持中国特色社会主义政治发展道路，坚持和完善人民代表大会制度、中国共产党领导的多党合作和政治协商制度、民族区域自治制度、基层群众自治制度，巩固和发展最广泛的爱国统一战线，发展社会主义协商民主，健全民主制度，丰富民主形式，拓宽民主渠道，保证人民当家作主落实到国家政治生活和社会生活之中。 （六）坚持全面依法治国。全面依法治国是中国特色社会主义的本质要求和重要保障。必须把党的领导贯彻落实到依法治国全过程和各方面，坚定不移走中国特色社会主义法治道路，完善以宪法为核心的中国特色社会主义法律体系，建设中国特色社会主义法治体系，建设社会主义法治国家，发展中国特色社会主义法治理论，坚持依法治国、依法执政、依法行政共同推进，坚持法治国家、法治政府、法治社会一体建设，坚持依法治国和以德治国相结合，依法治国和依规治党有机统一，深化司法体制改革，提高全民族法治素养和道德素质。 （七）坚持社会主义核心价值体系。文化自信是一个国家、一个民族发展中更基本、更深沉、更持久的力量。必须坚持马克思主义，牢固树立共产主义远大理想和中国特色社会主义共同理想，培育和践行社会主义核心价值观，不断增强意识形态领域主导权和话语权，推动中华优秀传统文化创造性转化、创新性发展，继承革命文化，发展社会主义先进文化，不忘本来、吸收外来、面向未来，更好构筑中国精神、中国价值、中国力量，为人民提供精神指引。 （八）坚持在发展中保障和改善民生。增进民生福祉是发展的根本目的。必须多谋民生之利、多解民生之忧，在发展中补齐民生短板、促进社会公平正义，在幼有所育、学有所教、劳有所得、病有所医、老有所养、住有所居、弱有所扶上不断取得新进展，深入开展脱贫攻坚，保证全体人民在共建共享发展中有更多获得感，不断促进人的全面发展、全体人民共同富裕。建设平安中国，加强和创新社会治理，维护社会和谐稳定，确保国家长治久安、人民安居乐业。 （九）坚持人与自然和谐共生。建设生态文明是中华民族永续发展的千年大计。必须树立和践行绿水青山就是金山银山的理念，坚持节约资源和保护环境的基本国策，像对待生命一样对待生态环境，统筹山水林田湖草系统治理，实行最严格的生态环境保护制度，形成绿色发展方式和生活方式，坚定走生产发展、生活富裕、生态良好的文明发展道路，建设美丽中国，为人民创造良好生产生活环境，为全球生态安全作出贡献。 （十）坚持总体国家安全观。统筹发展和安全，增强忧患意识，做到居安思危，是我们党治国理政的一个重大原则。必须坚持国家利益至上，以人民安全为宗旨，以政治安全为根本，统筹外部安全和内部安全、国土安全和国民安全、传统安全和非传统安全、自身安全和共同安全，完善国家安全制度体系，加强国家安全能力建设，坚决维护国家主权、安全、发展利益。 （十一）坚持党对人民军队的绝对领导。建设一支听党指挥、能打胜仗、作风优良的人民军队，是实现“两个一百年”奋斗目标、实现中华民族伟大复兴的战略支撑。必须全面贯彻党领导人民军队的一系列根本原则和制度，确立新时代党的强军思想在国防和军队建设中的指导地位，坚持政治建军、改革强军、科技兴军、依法治军，更加注重聚焦实战，更加注重创新驱动，更加注重体系建设，更加注重集约高效，更加注重军民融合，实现党在新时代的强军目标。 （十二）坚持“一国两制”和推进祖国统一。保持香港、澳门长期繁荣稳定，实现祖国完全统一，是实现中华民族伟大复兴的必然要求。必须把维护中央对香港、澳门特别行政区全面管治权和保障特别行政区高度自治权有机结合起来，确保“一国两制”方针不会变、不动摇，确保“一国两制”实践不变形、不走样。必须坚持一个中国原则，坚持“九二共识”，推动两岸关系和平发展，深化两岸经济合作和文化往来，推动两岸同胞共同反对一切分裂国家的活动，共同为实现中华民族伟大复兴而奋斗。 （十三）坚持推动构建人类命运共同体。中国人民的梦想同各国人民的梦想息息相通，实现中国梦离不开和平的国际环境和稳定的国际秩序。必须统筹国内国际两个大局，始终不渝走和平发展道路、奉行互利共赢的开放战略，坚持正确义利观，树立共同、综合、合作、可持续的新安全观，谋求开放创新、包容互惠的发展前景，促进和而不同、兼收并蓄的文明交流，构筑尊崇自然、绿色发展的生态体系，始终做世界和平的建设者、全球发展的贡献者、国际秩序的维护者。 （十四）坚持全面从严治党。勇于自我革命，从严管党治党，是我们党最鲜明的品格。必须以党章为根本遵循，把党的政治建设摆在首位，思想建党和制度治党同向发力，统筹推进党的各项建设，抓住“关键少数”，坚持“三严三实”，坚持民主集中制，严肃党内政治生活，严明党的纪律，强化党内监督，发展积极健康的党内政治文化，全面净化党内政治生态，坚决纠正各种不正之风，以零容忍态度惩治腐败，不断增强党自我净化、自我完善、自我革新、自我提高的能力，始终保持党同人民群众的血肉联系。 以上十四条，构成新时代坚持和发展中国特色社会主义的基本方略。全党同志必须全面贯彻党的基本理论、基本路线、基本方略，更好引领党和人民事业发展。 实践没有止境，理论创新也没有止境。世界每时每刻都在发生变化，中国也每时每刻都在发生变化，我们必须在理论上跟上时代，不断认识规律，不断推进理论创新、实践创新、制度创新、文化创新以及其他各方面创新。 同志们！时代是思想之母，实践是理论之源。只要我们善于聆听时代声音，勇于坚持真理、修正错误，二十一世纪中国的马克思主义一定能够展现出更强大、更有说服力的真理力量！ 四、决胜全面建成小康社会，开启全面建设社会主义现代化国家新征程 改革开放之后，我们党对我国社会主义现代化建设作出战略安排，提出“三步走”战略目标。解决人民温饱问题、人民生活总体上达到小康水平这两个目标已提前实现。在这个基础上，我们党提出，到建党一百年时建成经济更加发展、民主更加健全、科教更加进步、文化更加繁荣、社会更加和谐、人民生活更加殷实的小康社会，然后再奋斗三十年，到新中国成立一百年时，基本实现现代化，把我国建成社会主义现代化国家。 从现在到二〇二〇年，是全面建成小康社会决胜期。要按照十六大、十七大、十八大提出的全面建成小康社会各项要求，紧扣我国社会主要矛盾变化，统筹推进经济建设、政治建设、文化建设、社会建设、生态文明建设，坚定实施科教兴国战略、人才强国战略、创新驱动发展战略、乡村振兴战略、区域协调发展战略、可持续发展战略、军民融合发展战略，突出抓重点、补短板、强弱项，特别是要坚决打好防范化解重大风险、精准脱贫、污染防治的攻坚战，使全面建成小康社会得到人民认可、经得起历史检验。 从十九大到二十大，是“两个一百年”奋斗目标的历史交汇期。我们既要全面建成小康社会、实现第一个百年奋斗目标，又要乘势而上开启全面建设社会主义现代化国家新征程，向第二个百年奋斗目标进军。 综合分析国际国内形势和我国发展条件，从二〇二〇年到本世纪中叶可以分两个阶段来安排。 第一个阶段，从二〇二〇年到二〇三五年，在全面建成小康社会的基础上，再奋斗十五年，基本实现社会主义现代化。到那时，我国经济实力、科技实力将大幅跃升，跻身创新型国家前列；人民平等参与、平等发展权利得到充分保障，法治国家、法治政府、法治社会基本建成，各方面制度更加完善，国家治理体系和治理能力现代化基本实现；社会文明程度达到新的高度，国家文化软实力显著增强，中华文化影响更加广泛深入；人民生活更为宽裕，中等收入群体比例明显提高，城乡区域发展差距和居民生活水平差距显著缩小，基本公共服务均等化基本实现，全体人民共同富裕迈出坚实步伐；现代社会治理格局基本形成，社会充满活力又和谐有序；生态环境根本好转，美丽中国目标基本实现。 第二个阶段，从二〇三五年到本世纪中叶，在基本实现现代化的基础上，再奋斗十五年，把我国建成富强民主文明和谐美丽的社会主义现代化强国。到那时，我国物质文明、政治文明、精神文明、社会文明、生态文明将全面提升，实现国家治理体系和治理能力现代化，成为综合国力和国际影响力领先的国家，全体人民共同富裕基本实现，我国人民将享有更加幸福安康的生活，中华民族将以更加昂扬的姿态屹立于世界民族之林。 同志们！从全面建成小康社会到基本实现现代化，再到全面建成社会主义现代化强国，是新时代中国特色社会主义发展的战略安排。我们要坚忍不拔、锲而不舍，奋力谱写社会主义现代化新征程的壮丽篇章！ 五、贯彻新发展理念，建设现代化经济体系 实现“两个一百年”奋斗目标、实现中华民族伟大复兴的中国梦，不断提高人民生活水平，必须坚定不移把发展作为党执政兴国的第一要务，坚持解放和发展社会生产力，坚持社会主义市场经济改革方向，推动经济持续健康发展。 我国经济已由高速增长阶段转向高质量发展阶段，正处在转变发展方式、优化经济结构、转换增长动力的攻关期，建设现代化经济体系是跨越关口的迫切要求和我国发展的战略目标。必须坚持质量第一、效益优先，以供给侧结构性改革为主线，推动经济发展质量变革、效率变革、动力变革，提高全要素生产率，着力加快建设实体经济、科技创新、现代金融、人力资源协同发展的产业体系，着力构建市场机制有效、微观主体有活力、宏观调控有度的经济体制，不断增强我国经济创新力和竞争力。 （一）深化供给侧结构性改革。建设现代化经济体系，必须把发展经济的着力点放在实体经济上，把提高供给体系质量作为主攻方向，显著增强我国经济质量优势。加快建设制造强国，加快发展先进制造业，推动互联网、大数据、人工智能和实体经济深度融合，在中高端消费、创新引领、绿色低碳、共享经济、现代供应链、人力资本服务等领域培育新增长点、形成新动能。支持传统产业优化升级，加快发展现代服务业，瞄准国际标准提高水平。促进我国产业迈向全球价值链中高端，培育若干世界级先进制造业集群。加强水利、铁路、公路、水运、航空、管道、电网、信息、物流等基础设施网络建设。坚持去产能、去库存、去杠杆、降成本、补短板，优化存量资源配置，扩大优质增量供给，实现供需动态平衡。激发和保护企业家精神，鼓励更多社会主体投身创新创业。建设知识型、技能型、创新型劳动者大军，弘扬劳模精神和工匠精神，营造劳动光荣的社会风尚和精益求精的敬业风气。 （二）加快建设创新型国家。创新是引领发展的第一动力，是建设现代化经济体系的战略支撑。要瞄准世界科技前沿，强化基础研究，实现前瞻性基础研究、引领性原创成果重大突破。加强应用基础研究，拓展实施国家重大科技项目，突出关键共性技术、前沿引领技术、现代工程技术、颠覆性技术创新，为建设科技强国、质量强国、航天强国、网络强国、交通强国、数字中国、智慧社会提供有力支撑。加强国家创新体系建设，强化战略科技力量。深化科技体制改革，建立以企业为主体、市场为导向、产学研深度融合的技术创新体系，加强对中小企业创新的支持，促进科技成果转化。倡导创新文化，强化知识产权创造、保护、运用。培养造就一大批具有国际水平的战略科技人才、科技领军人才、青年科技人才和高水平创新团队。 （三）实施乡村振兴战略。农业农村农民问题是关系国计民生的根本性问题，必须始终把解决好“三农”问题作为全党工作重中之重。要坚持农业农村优先发展，按照产业兴旺、生态宜居、乡风文明、治理有效、生活富裕的总要求，建立健全城乡融合发展体制机制和政策体系，加快推进农业农村现代化。巩固和完善农村基本经营制度，深化农村土地制度改革，完善承包地“三权”分置制度。保持土地承包关系稳定并长久不变，第二轮土地承包到期后再延长三十年。深化农村集体产权制度改革，保障农民财产权益，壮大集体经济。确保国家粮食安全，把中国人的饭碗牢牢端在自己手中。构建现代农业产业体系、生产体系、经营体系，完善农业支持保护制度，发展多种形式适度规模经营，培育新型农业经营主体，健全农业社会化服务体系，实现小农户和现代农业发展有机衔接。促进农村一二三产业融合发展，支持和鼓励农民就业创业，拓宽增收渠道。加强农村基层基础工作，健全自治、法治、德治相结合的乡村治理体系。培养造就一支懂农业、爱农村、爱农民的“三农”工作队伍。 （四）实施区域协调发展战略。加大力度支持革命老区、民族地区、边疆地区、贫困地区加快发展，强化举措推进西部大开发形成新格局，深化改革加快东北等老工业基地振兴，发挥优势推动中部地区崛起，创新引领率先实现东部地区优化发展，建立更加有效的区域协调发展新机制。以城市群为主体构建大中小城市和小城镇协调发展的城镇格局，加快农业转移人口市民化。以疏解北京非首都功能为“牛鼻子”推动京津冀协同发展，高起点规划、高标准建设雄安新区。以共抓大保护、不搞大开发为导向推动长江经济带发展。支持资源型地区经济转型发展。加快边疆发展，确保边疆巩固、边境安全。坚持陆海统筹，加快建设海洋强国。 （五）加快完善社会主义市场经济体制。经济体制改革必须以完善产权制度和要素市场化配置为重点，实现产权有效激励、要素自由流动、价格反应灵活、竞争公平有序、企业优胜劣汰。要完善各类国有资产管理体制，改革国有资本授权经营体制，加快国有经济布局优化、结构调整、战略性重组，促进国有资产保值增值，推动国有资本做强做优做大，有效防止国有资产流失。深化国有企业改革，发展混合所有制经济，培育具有全球竞争力的世界一流企业。全面实施市场准入负面清单制度，清理废除妨碍统一市场和公平竞争的各种规定和做法，支持民营企业发展，激发各类市场主体活力。深化商事制度改革，打破行政性垄断，防止市场垄断，加快要素价格市场化改革，放宽服务业准入限制，完善市场监管体制。创新和完善宏观调控，发挥国家发展规划的战略导向作用，健全财政、货币、产业、区域等经济政策协调机制。完善促进消费的体制机制，增强消费对经济发展的基础性作用。深化投融资体制改革，发挥投资对优化供给结构的关键性作用。加快建立现代财政制度，建立权责清晰、财力协调、区域均衡的中央和地方财政关系。建立全面规范透明、标准科学、约束有力的预算制度，全面实施绩效管理。深化税收制度改革，健全地方税体系。深化金融体制改革，增强金融服务实体经济能力，提高直接融资比重，促进多层次资本市场健康发展。健全货币政策和宏观审慎政策双支柱调控框架，深化利率和汇率市场化改革。健全金融监管体系，守住不发生系统性金融风险的底线。 （六）推动形成全面开放新格局。开放带来进步，封闭必然落后。中国开放的大门不会关闭，只会越开越大。要以“一带一路”建设为重点，坚持引进来和走出去并重，遵循共商共建共享原则，加强创新能力开放合作，形成陆海内外联动、东西双向互济的开放格局。拓展对外贸易，培育贸易新业态新模式，推进贸易强国建设。实行高水平的贸易和投资自由化便利化政策，全面实行准入前国民待遇加负面清单管理制度，大幅度放宽市场准入，扩大服务业对外开放，保护外商投资合法权益。凡是在我国境内注册的企业，都要一视同仁、平等对待。优化区域开放布局，加大西部开放力度。赋予自由贸易试验区更大改革自主权，探索建设自由贸易港。创新对外投资方式，促进国际产能合作，形成面向全球的贸易、投融资、生产、服务网络，加快培育国际经济合作和竞争新优势。 同志们！解放和发展社会生产力，是社会主义的本质要求。我们要激发全社会创造力和发展活力，努力实现更高质量、更有效率、更加公平、更可持续的发展！ 六、健全人民当家作主制度体系，发展社会主义民主政治 我国是工人阶级领导的、以工农联盟为基础的人民民主专政的社会主义国家，国家一切权力属于人民。我国社会主义民主是维护人民根本利益的最广泛、最真实、最管用的民主。发展社会主义民主政治就是要体现人民意志、保障人民权益、激发人民创造活力，用制度体系保证人民当家作主。 中国特色社会主义政治发展道路，是近代以来中国人民长期奋斗历史逻辑、理论逻辑、实践逻辑的必然结果，是坚持党的本质属性、践行党的根本宗旨的必然要求。世界上没有完全相同的政治制度模式，政治制度不能脱离特定社会政治条件和历史文化传统来抽象评判，不能定于一尊，不能生搬硬套外国政治制度模式。要长期坚持、不断发展我国社会主义民主政治，积极稳妥推进政治体制改革，推进社会主义民主政治制度化、规范化、法治化、程序化，保证人民依法通过各种途径和形式管理国家事务，管理经济文化事业，管理社会事务，巩固和发展生动活泼、安定团结的政治局面。 （一）坚持党的领导、人民当家作主、依法治国有机统一。党的领导是人民当家作主和依法治国的根本保证，人民当家作主是社会主义民主政治的本质特征，依法治国是党领导人民治理国家的基本方式，三者统一于我国社会主义民主政治伟大实践。在我国政治生活中，党是居于领导地位的，加强党的集中统一领导，支持人大、政府、政协和法院、检察院依法依章程履行职能、开展工作、发挥作用，这两个方面是统一的。要改进党的领导方式和执政方式，保证党领导人民有效治理国家；扩大人民有序政治参与，保证人民依法实行民主选举、民主协商、民主决策、民主管理、民主监督；维护国家法制统一、尊严、权威，加强人权法治保障，保证人民依法享有广泛权利和自由。巩固基层政权，完善基层民主制度，保障人民知情权、参与权、表达权、监督权。健全依法决策机制，构建决策科学、执行坚决、监督有力的权力运行机制。各级领导干部要增强民主意识，发扬民主作风，接受人民监督，当好人民公仆。 （二）加强人民当家作主制度保障。人民代表大会制度是坚持党的领导、人民当家作主、依法治国有机统一的根本政治制度安排，必须长期坚持、不断完善。要支持和保证人民通过人民代表大会行使国家权力。发挥人大及其常委会在立法工作中的主导作用，健全人大组织制度和工作制度，支持和保证人大依法行使立法权、监督权、决定权、任免权，更好发挥人大代表作用，使各级人大及其常委会成为全面担负起宪法法律赋予的各项职责的工作机关，成为同人民群众保持密切联系的代表机关。完善人大专门委员会设置，优化人大常委会和专门委员会组成人员结构。 （三）发挥社会主义协商民主重要作用。有事好商量，众人的事情由众人商量，是人民民主的真谛。协商民主是实现党的领导的重要方式，是我国社会主义民主政治的特有形式和独特优势。要推动协商民主广泛、多层、制度化发展，统筹推进政党协商、人大协商、政府协商、政协协商、人民团体协商、基层协商以及社会组织协商。加强协商民主制度建设，形成完整的制度程序和参与实践，保证人民在日常政治生活中有广泛持续深入参与的权利。 人民政协是具有中国特色的制度安排，是社会主义协商民主的重要渠道和专门协商机构。人民政协工作要聚焦党和国家中心任务，围绕团结和民主两大主题，把协商民主贯穿政治协商、民主监督、参政议政全过程，完善协商议政内容和形式，着力增进共识、促进团结。加强人民政协民主监督，重点监督党和国家重大方针政策和重要决策部署的贯彻落实。增强人民政协界别的代表性，加强委员队伍建设。 （四）深化依法治国实践。全面依法治国是国家治理的一场深刻革命，必须坚持厉行法治，推进科学立法、严格执法、公正司法、全民守法。成立中央全面依法治国领导小组，加强对法治中国建设的统一领导。加强宪法实施和监督，推进合宪性审查工作，维护宪法权威。推进科学立法、民主立法、依法立法，以良法促进发展、保障善治。建设法治政府，推进依法行政，严格规范公正文明执法。深化司法体制综合配套改革，全面落实司法责任制，努力让人民群众在每一个司法案件中感受到公平正义。加大全民普法力度，建设社会主义法治文化，树立宪法法律至上、法律面前人人平等的法治理念。各级党组织和全体党员要带头尊法学法守法用法，任何组织和个人都不得有超越宪法法律的特权，绝不允许以言代法、以权压法、逐利违法、徇私枉法。 （五）深化机构和行政体制改革。统筹考虑各类机构设置，科学配置党政部门及内设机构权力、明确职责。统筹使用各类编制资源，形成科学合理的管理体制，完善国家机构组织法。转变政府职能，深化简政放权，创新监管方式，增强政府公信力和执行力，建设人民满意的服务型政府。赋予省级及以下政府更多自主权。在省市县对职能相近的党政机关探索合并设立或合署办公。深化事业单位改革，强化公益属性，推进政事分开、事企分开、管办分离。 （六）巩固和发展爱国统一战线。统一战线是党的事业取得胜利的重要法宝，必须长期坚持。要高举爱国主义、社会主义旗帜，牢牢把握大团结大联合的主题，坚持一致性和多样性统一，找到最大公约数，画出最大同心圆。坚持长期共存、互相监督、肝胆相照、荣辱与共，支持民主党派按照中国特色社会主义参政党要求更好履行职能。深化民族团结进步教育，铸牢中华民族共同体意识，加强各民族交往交流交融，促进各民族像石榴籽一样紧紧抱在一起，共同团结奋斗、共同繁荣发展。全面贯彻党的宗教工作基本方针，坚持我国宗教的中国化方向，积极引导宗教与社会主义社会相适应。加强党外知识分子工作，做好新的社会阶层人士工作，发挥他们在中国特色社会主义事业中的重要作用。构建亲、清新型政商关系，促进非公有制经济健康发展和非公有制经济人士健康成长。广泛团结联系海外侨胞和归侨侨眷，共同致力于中华民族伟大复兴。 同志们！中国特色社会主义政治制度是中国共产党和中国人民的伟大创造。我们完全有信心、有能力把我国社会主义民主政治的优势和特点充分发挥出来，为人类政治文明进步作出充满中国智慧的贡献！ 七、坚定文化自信，推动社会主义文化繁荣兴盛 文化是一个国家、一个民族的灵魂。文化兴国运兴，文化强民族强。没有高度的文化自信，没有文化的繁荣兴盛，就没有中华民族伟大复兴。要坚持中国特色社会主义文化发展道路，激发全民族文化创新创造活力，建设社会主义文化强国。 中国特色社会主义文化，源自于中华民族五千多年文明历史所孕育的中华优秀传统文化，熔铸于党领导人民在革命、建设、改革中创造的革命文化和社会主义先进文化，植根于中国特色社会主义伟大实践。发展中国特色社会主义文化，就是以马克思主义为指导，坚守中华文化立场，立足当代中国现实，结合当今时代条件，发展面向现代化、面向世界、面向未来的，民族的科学的大众的社会主义文化，推动社会主义精神文明和物质文明协调发展。要坚持为人民服务、为社会主义服务，坚持百花齐放、百家争鸣，坚持创造性转化、创新性发展，不断铸就中华文化新辉煌。 （一）牢牢掌握意识形态工作领导权。意识形态决定文化前进方向和发展道路。必须推进马克思主义中国化时代化大众化，建设具有强大凝聚力和引领力的社会主义意识形态，使全体人民在理想信念、价值理念、道德观念上紧紧团结在一起。要加强理论武装，推动新时代中国特色社会主义思想深入人心。深化马克思主义理论研究和建设，加快构建中国特色哲学社会科学，加强中国特色新型智库建设。高度重视传播手段建设和创新，提高新闻舆论传播力、引导力、影响力、公信力。加强互联网内容建设，建立网络综合治理体系，营造清朗的网络空间。落实意识形态工作责任制，加强阵地建设和管理，注意区分政治原则问题、思想认识问题、学术观点问题，旗帜鲜明反对和抵制各种错误观点。 （二）培育和践行社会主义核心价值观。社会主义核心价值观是当代中国精神的集中体现，凝结着全体人民共同的价值追求。要以培养担当民族复兴大任的时代新人为着眼点，强化教育引导、实践养成、制度保障，发挥社会主义核心价值观对国民教育、精神文明创建、精神文化产品创作生产传播的引领作用，把社会主义核心价值观融入社会发展各方面，转化为人们的情感认同和行为习惯。坚持全民行动、干部带头，从家庭做起，从娃娃抓起。深入挖掘中华优秀传统文化蕴含的思想观念、人文精神、道德规范，结合时代要求继承创新，让中华文化展现出永久魅力和时代风采。 （三）加强思想道德建设。人民有信仰，国家有力量，民族有希望。要提高人民思想觉悟、道德水准、文明素养，提高全社会文明程度。广泛开展理想信念教育，深化中国特色社会主义和中国梦宣传教育，弘扬民族精神和时代精神，加强爱国主义、集体主义、社会主义教育，引导人们树立正确的历史观、民族观、国家观、文化观。深入实施公民道德建设工程，推进社会公德、职业道德、家庭美德、个人品德建设，激励人们向上向善、孝老爱亲，忠于祖国、忠于人民。加强和改进思想政治工作，深化群众性精神文明创建活动。弘扬科学精神，普及科学知识，开展移风易俗、弘扬时代新风行动，抵制腐朽落后文化侵蚀。推进诚信建设和志愿服务制度化，强化社会责任意识、规则意识、奉献意识。 （四）繁荣发展社会主义文艺。社会主义文艺是人民的文艺，必须坚持以人民为中心的创作导向，在深入生活、扎根人民中进行无愧于时代的文艺创造。要繁荣文艺创作，坚持思想精深、艺术精湛、制作精良相统一，加强现实题材创作，不断推出讴歌党、讴歌祖国、讴歌人民、讴歌英雄的精品力作。发扬学术民主、艺术民主，提升文艺原创力，推动文艺创新。倡导讲品位、讲格调、讲责任，抵制低俗、庸俗、媚俗。加强文艺队伍建设，造就一大批德艺双馨名家大师，培育一大批高水平创作人才。 （五）推动文化事业和文化产业发展。满足人民过上美好生活的新期待，必须提供丰富的精神食粮。要深化文化体制改革，完善文化管理体制，加快构建把社会效益放在首位、社会效益和经济效益相统一的体制机制。完善公共文化服务体系，深入实施文化惠民工程，丰富群众性文化活动。加强文物保护利用和文化遗产保护传承。健全现代文化产业体系和市场体系，创新生产经营机制，完善文化经济政策，培育新型文化业态。广泛开展全民健身活动，加快推进体育强国建设，筹办好北京冬奥会、冬残奥会。加强中外人文交流，以我为主、兼收并蓄。推进国际传播能力建设，讲好中国故事，展现真实、立体、全面的中国，提高国家文化软实力。 同志们！中国共产党从成立之日起，既是中国先进文化的积极引领者和践行者，又是中华优秀传统文化的忠实传承者和弘扬者。当代中国共产党人和中国人民应该而且一定能够担负起新的文化使命，在实践创造中进行文化创造，在历史进步中实现文化进步！ 八、提高保障和改善民生水平，加强和创新社会治理 全党必须牢记，为什么人的问题，是检验一个政党、一个政权性质的试金石。带领人民创造美好生活，是我们党始终不渝的奋斗目标。必须始终把人民利益摆在至高无上的地位，让改革发展成果更多更公平惠及全体人民，朝着实现全体人民共同富裕不断迈进。 保障和改善民生要抓住人民最关心最直接最现实的利益问题，既尽力而为，又量力而行，一件事情接着一件事情办，一年接着一年干。坚持人人尽责、人人享有，坚守底线、突出重点、完善制度、引导预期，完善公共服务体系，保障群众基本生活，不断满足人民日益增长的美好生活需要，不断促进社会公平正义，形成有效的社会治理、良好的社会秩序，使人民获得感、幸福感、安全感更加充实、更有保障、更可持续。 （一）优先发展教育事业。建设教育强国是中华民族伟大复兴的基础工程，必须把教育事业放在优先位置，加快教育现代化，办好人民满意的教育。要全面贯彻党的教育方针，落实立德树人根本任务，发展素质教育，推进教育公平，培养德智体美全面发展的社会主义建设者和接班人。推动城乡义务教育一体化发展，高度重视农村义务教育，办好学前教育、特殊教育和网络教育，普及高中阶段教育，努力让每个孩子都能享有公平而有质量的教育。完善职业教育和培训体系，深化产教融合、校企合作。加快一流大学和一流学科建设，实现高等教育内涵式发展。健全学生资助制度，使绝大多数城乡新增劳动力接受高中阶段教育、更多接受高等教育。支持和规范社会力量兴办教育。加强师德师风建设，培养高素质教师队伍，倡导全社会尊师重教。办好继续教育，加快建设学习型社会，大力提高国民素质。 （二）提高就业质量和人民收入水平。就业是最大的民生。要坚持就业优先战略和积极就业政策，实现更高质量和更充分就业。大规模开展职业技能培训，注重解决结构性就业矛盾，鼓励创业带动就业。提供全方位公共就业服务，促进高校毕业生等青年群体、农民工多渠道就业创业。破除妨碍劳动力、人才社会性流动的体制机制弊端，使人人都有通过辛勤劳动实现自身发展的机会。完善政府、工会、企业共同参与的协商协调机制，构建和谐劳动关系。坚持按劳分配原则，完善按要素分配的体制机制，促进收入分配更合理、更有序。鼓励勤劳守法致富，扩大中等收入群体，增加低收入者收入，调节过高收入，取缔非法收入。坚持在经济增长的同时实现居民收入同步增长、在劳动生产率提高的同时实现劳动报酬同步提高。拓宽居民劳动收入和财产性收入渠道。履行好政府再分配调节职能，加快推进基本公共服务均等化，缩小收入分配差距。 （三）加强社会保障体系建设。按照兜底线、织密网、建机制的要求，全面建成覆盖全民、城乡统筹、权责清晰、保障适度、可持续的多层次社会保障体系。全面实施全民参保计划。完善城镇职工基本养老保险和城乡居民基本养老保险制度，尽快实现养老保险全国统筹。完善统一的城乡居民基本医疗保险制度和大病保险制度。完善失业、工伤保险制度。建立全国统一的社会保险公共服务平台。统筹城乡社会救助体系，完善最低生活保障制度。坚持男女平等基本国策，保障妇女儿童合法权益。完善社会救助、社会福利、慈善事业、优抚安置等制度，健全农村留守儿童和妇女、老年人关爱服务体系。发展残疾人事业，加强残疾康复服务。坚持房子是用来住的、不是用来炒的定位，加快建立多主体供给、多渠道保障、租购并举的住房制度，让全体人民住有所居。 （四）坚决打赢脱贫攻坚战。让贫困人口和贫困地区同全国一道进入全面小康社会是我们党的庄严承诺。要动员全党全国全社会力量，坚持精准扶贫、精准脱贫，坚持中央统筹省负总责市县抓落实的工作机制，强化党政一把手负总责的责任制，坚持大扶贫格局，注重扶贫同扶志、扶智相结合，深入实施东西部扶贫协作，重点攻克深度贫困地区脱贫任务，确保到二〇二〇年我国现行标准下农村贫困人口实现脱贫，贫困县全部摘帽，解决区域性整体贫困，做到脱真贫、真脱贫。 （五）实施健康中国战略。人民健康是民族昌盛和国家富强的重要标志。要完善国民健康政策，为人民群众提供全方位全周期健康服务。深化医药卫生体制改革，全面建立中国特色基本医疗卫生制度、医疗保障制度和优质高效的医疗卫生服务体系，健全现代医院管理制度。加强基层医疗卫生服务体系和全科医生队伍建设。全面取消以药养医，健全药品供应保障制度。坚持预防为主，深入开展爱国卫生运动，倡导健康文明生活方式，预防控制重大疾病。实施食品安全战略，让人民吃得放心。坚持中西医并重，传承发展中医药事业。支持社会办医，发展健康产业。促进生育政策和相关经济社会政策配套衔接，加强人口发展战略研究。积极应对人口老龄化，构建养老、孝老、敬老政策体系和社会环境，推进医养结合，加快老龄事业和产业发展。 （六）打造共建共治共享的社会治理格局。加强社会治理制度建设，完善党委领导、政府负责、社会协同、公众参与、法治保障的社会治理体制，提高社会治理社会化、法治化、智能化、专业化水平。加强预防和化解社会矛盾机制建设，正确处理人民内部矛盾。树立安全发展理念，弘扬生命至上、安全第一的思想，健全公共安全体系，完善安全生产责任制，坚决遏制重特大安全事故，提升防灾减灾救灾能力。加快社会治安防控体系建设，依法打击和惩治黄赌毒黑拐骗等违法犯罪活动，保护人民人身权、财产权、人格权。加强社会心理服务体系建设，培育自尊自信、理性平和、积极向上的社会心态。加强社区治理体系建设，推动社会治理重心向基层下移，发挥社会组织作用，实现政府治理和社会调节、居民自治良性互动。 （七）有效维护国家安全。国家安全是安邦定国的重要基石，维护国家安全是全国各族人民根本利益所在。要完善国家安全战略和国家安全政策，坚决维护国家政治安全，统筹推进各项安全工作。健全国家安全体系，加强国家安全法治保障，提高防范和抵御安全风险能力。严密防范和坚决打击各种渗透颠覆破坏活动、暴力恐怖活动、民族分裂活动、宗教极端活动。加强国家安全教育，增强全党全国人民国家安全意识，推动全社会形成维护国家安全的强大合力。 同志们！党的一切工作必须以最广大人民根本利益为最高标准。我们要坚持把人民群众的小事当作自己的大事，从人民群众关心的事情做起，从让人民群众满意的事情做起，带领人民不断创造美好生活！ 九、加快生态文明体制改革，建设美丽中国 人与自然是生命共同体，人类必须尊重自然、顺应自然、保护自然。人类只有遵循自然规律才能有效防止在开发利用自然上走弯路，人类对大自然的伤害最终会伤及人类自身，这是无法抗拒的规律。 （一）推进绿色发展。加快建立绿色生产和消费的法律制度和政策导向，建立健全绿色低碳循环发展的经济体系。构建市场导向的绿色技术创新体系，发展绿色金融，壮大节能环保产业、清洁生产产业、清洁能源产业。推进能源生产和消费革命，构建清洁低碳、安全高效的能源体系。推进资源全面节约和循环利用，实施国家节水行动，降低能耗、物耗，实现生产系统和生活系统循环链接。倡导简约适度、绿色低碳的生活方式，反对奢侈浪费和不合理消费，开展创建节约型机关、绿色家庭、绿色学校、绿色社区和绿色出行等行动。 （二）着力解决突出环境问题。坚持全民共治、源头防治，持续实施大气污染防治行动，打赢蓝天保卫战。加快水污染防治，实施流域环境和近岸海域综合治理。强化土壤污染管控和修复，加强农业面源污染防治，开展农村人居环境整治行动。加强固体废弃物和垃圾处置。提高污染排放标准，强化排污者责任，健全环保信用评价、信息强制性披露、严惩重罚等制度。构建政府为主导、企业为主体、社会组织和公众共同参与的环境治理体系。积极参与全球环境治理，落实减排承诺。 （三）加大生态系统保护力度。实施重要生态系统保护和修复重大工程，优化生态安全屏障体系，构建生态廊道和生物多样性保护网络，提升生态系统质量和稳定性。完成生态保护红线、永久基本农田、城镇开发边界三条控制线划定工作。开展国土绿化行动，推进荒漠化、石漠化、水土流失综合治理，强化湿地保护和恢复，加强地质灾害防治。完善天然林保护制度，扩大退耕还林还草。严格保护耕地，扩大轮作休耕试点，健全耕地草原森林河流湖泊休养生息制度，建立市场化、多元化生态补偿机制。 （四）改革生态环境监管体制。加强对生态文明建设的总体设计和组织领导，设立国有自然资源资产管理和自然生态监管机构，完善生态环境管理制度，统一行使全民所有自然资源资产所有者职责，统一行使所有国土空间用途管制和生态保护修复职责，统一行使监管城乡各类污染排放和行政执法职责。构建国土空间开发保护制度，完善主体功能区配套政策，建立以国家公园为主体的自然保护地体系。坚决制止和惩处破坏生态环境行为。 同志们！生态文明建设功在当代、利在千秋。我们要牢固树立社会主义生态文明观，推动形成人与自然和谐发展现代化建设新格局，为保护生态环境作出我们这代人的努力！ 十、坚持走中国特色强军之路，全面推进国防和军队现代化 国防和军队建设正站在新的历史起点上。面对国家安全环境的深刻变化，面对强国强军的时代要求，必须全面贯彻新时代党的强军思想，贯彻新形势下军事战略方针，建设强大的现代化陆军、海军、空军、火箭军和战略支援部队，打造坚强高效的战区联合作战指挥机构，构建中国特色现代作战体系，担当起党和人民赋予的新时代使命任务。 适应世界新军事革命发展趋势和国家安全需求，提高建设质量和效益，确保到二〇二〇年基本实现机械化，信息化建设取得重大进展，战略能力有大的提升。同国家现代化进程相一致，全面推进军事理论现代化、军队组织形态现代化、军事人员现代化、武器装备现代化，力争到二〇三五年基本实现国防和军队现代化，到本世纪中叶把人民军队全面建成世界一流军队。 加强军队党的建设，开展“传承红色基因、担当强军重任”主题教育，推进军人荣誉体系建设，培养有灵魂、有本事、有血性、有品德的新时代革命军人，永葆人民军队性质、宗旨、本色。继续深化国防和军队改革，深化军官职业化制度、文职人员制度等重大政策制度改革，推进军事管理革命，完善和发展中国特色社会主义军事制度。树立科技是核心战斗力的思想，推进重大技术创新、自主创新，加强军事人才培养体系建设，建设创新型人民军队。全面从严治军，推动治军方式根本性转变，提高国防和军队建设法治化水平。 军队是要准备打仗的，一切工作都必须坚持战斗力标准，向能打仗、打胜仗聚焦。扎实做好各战略方向军事斗争准备，统筹推进传统安全领域和新型安全领域军事斗争准备，发展新型作战力量和保障力量，开展实战化军事训练，加强军事力量运用，加快军事智能化发展，提高基于网络信息体系的联合作战能力、全域作战能力，有效塑造态势、管控危机、遏制战争、打赢战争。 坚持富国和强军相统一，强化统一领导、顶层设计、改革创新和重大项目落实，深化国防科技工业改革，形成军民融合深度发展格局，构建一体化的国家战略体系和能力。完善国防动员体系，建设强大稳固的现代边海空防。组建退役军人管理保障机构，维护军人军属合法权益，让军人成为全社会尊崇的职业。深化武警部队改革，建设现代化武装警察部队。 同志们！我们的军队是人民军队，我们的国防是全民国防。我们要加强全民国防教育，巩固军政军民团结，为实现中国梦强军梦凝聚强大力量！ 十一、坚持“一国两制”，推进祖国统一 香港、澳门回归祖国以来，“一国两制”实践取得举世公认的成功。事实证明，“一国两制”是解决历史遗留的香港、澳门问题的最佳方案，也是香港、澳门回归后保持长期繁荣稳定的最佳制度。 保持香港、澳门长期繁荣稳定，必须全面准确贯彻“一国两制”、“港人治港”、“澳人治澳”、高度自治的方针，严格依照宪法和基本法办事，完善与基本法实施相关的制度和机制。要支持特别行政区政府和行政长官依法施政、积极作为，团结带领香港、澳门各界人士齐心协力谋发展、促和谐，保障和改善民生，有序推进民主，维护社会稳定，履行维护国家主权、安全、发展利益的宪制责任。 香港、澳门发展同内地发展紧密相连。要支持香港、澳门融入国家发展大局，以粤港澳大湾区建设、粤港澳合作、泛珠三角区域合作等为重点，全面推进内地同香港、澳门互利合作，制定完善便利香港、澳门居民在内地发展的政策措施。 我们坚持爱国者为主体的“港人治港”、“澳人治澳”，发展壮大爱国爱港爱澳力量，增强香港、澳门同胞的国家意识和爱国精神，让香港、澳门同胞同祖国人民共担民族复兴的历史责任、共享祖国繁荣富强的伟大荣光。 解决台湾问题、实现祖国完全统一，是全体中华儿女共同愿望，是中华民族根本利益所在。必须继续坚持“和平统一、一国两制”方针，推动两岸关系和平发展，推进祖国和平统一进程。“一个中国”原则是两岸关系的政治基础，体现一个中国原则的九二共识明确鉴定了两岸关系的根本性质，是确保两岸关系和平发展的关键。承认九二共识的历史事实、认同两岸同属一个中国，两岸双方就能开展对话协商解决两岸同胞关心的问题。台湾任何政党和团体同大陆交往也不会存在障碍。(add) 两岸同胞是命运与共的骨肉兄弟，是血浓于水的一家人。我们秉持“两岸一家亲”理念，尊重台湾现有的社会制度和台湾同胞生活方式，愿意率先同台湾同胞分享大陆发展的机遇。我们将扩大两岸经济文化交流合作，实现互利互惠，逐步为台湾同胞在大陆学习、创业、就业、生活提供与大陆同胞同等的待遇，增进台湾同胞福祉。我们将推动两岸同胞共同弘扬中华文化，促进心灵契合。 我们坚决维护国家主权和领土完整，绝不容忍国家分裂的历史悲剧重演（鼓掌）。一切分裂祖国的活动都必将遭到全体中国人坚决反对（鼓掌）。我们有坚定的意志、充分的信心、足够的能力挫败任何形式的“台独”分裂图谋（鼓掌）。我们绝不允许任何人、任何组织、任何政党、在任何时候、以任何形式、把任何一块中国领土从中国分裂出去！（鼓掌） 同志们！实现中华民族伟大复兴，是全体中国人共同的梦想。我们坚信，只要包括港澳台同胞在内的全体中华儿女顺应历史大势、共担民族大义，把民族命运牢牢掌握在自己手中，就一定能够共创中华民族伟大复兴的美好未来！ 十二、坚持和平发展道路，推动构建人类命运共同体 中国共产党是为中国人民谋幸福的政党，也是为人类进步事业而奋斗的政党。中国共产党始终把为人类作出新的更大的贡献作为自己的使命。 中国将高举和平、发展、合作、共赢的旗帜，恪守维护世界和平、促进共同发展的外交政策宗旨，坚定不移在和平共处五项原则基础上发展同各国的友好合作，推动建设相互尊重、公平正义、合作共赢的新型国际关系。 世界正处于大发展大变革大调整时期，和平与发展仍然是时代主题。世界多极化、经济全球化、社会信息化、文化多样化深入发展，全球治理体系和国际秩序变革加速推进，各国相互联系和依存日益加深，国际力量对比更趋平衡，和平发展大势不可逆转。同时，世界面临的不稳定性不确定性突出，世界经济增长动能不足，贫富分化日益严重，地区热点问题此起彼伏，恐怖主义、网络安全、重大传染性疾病、气候变化等非传统安全威胁持续蔓延，人类面临许多共同挑战。 我们生活的世界充满希望，也充满挑战。我们不能因现实复杂而放弃梦想，不能因理想遥远而放弃追求。没有哪个国家能够独自应对人类面临的各种挑战，也没有哪个国家能够退回到自我封闭的孤岛。 我们呼吁，各国人民同心协力，构建人类命运共同体，建设持久和平、普遍安全、共同繁荣、开放包容、清洁美丽的世界。要相互尊重、平等协商，坚决摒弃冷战思维和强权政治，走对话而不对抗、结伴而不结盟的国与国交往新路。要坚持以对话解决争端、以协商化解分歧，统筹应对传统和非传统安全威胁，反对一切形式的恐怖主义。要同舟共济，促进贸易和投资自由化便利化，推动经济全球化朝着更加开放、包容、普惠、平衡、共赢的方向发展。要尊重世界文明多样性，以文明交流超越文明隔阂、文明互鉴超越文明冲突、文明共存超越文明优越。要坚持环境友好，合作应对气候变化，保护好人类赖以生存的地球家园。 中国坚定奉行独立自主的和平外交政策，尊重各国人民自主选择发展道路的权利，维护国际公平正义，反对把自己的意志强加于人，反对干涉别国内政，反对以强凌弱。中国决不会以牺牲别国利益为代价来发展自己，也决不放弃自己的正当权益，任何人不要幻想让中国吞下损害自身利益的苦果。中国奉行防御性的国防政策。中国发展不对任何国家构成威胁。中国无论发展到什么程度，永远不称霸，永远不搞扩张。 中国积极发展全球伙伴关系，扩大同各国的利益交汇点，推进大国协调和合作，构建总体稳定、均衡发展的大国关系框架，按照亲诚惠容理念和与邻为善、以邻为伴周边外交方针深化同周边国家关系，秉持正确义利观和真实亲诚理念加强同发展中国家团结合作。加强同各国政党和政治组织的交流合作，推进人大、政协、军队、地方、人民团体等的对外交往。 中国坚持对外开放的基本国策，坚持打开国门搞建设，积极促进“一带一路”国际合作，努力实现政策沟通、设施联通、贸易畅通、资金融通、民心相通，打造国际合作新平台，增添共同发展新动力。加大对发展中国家特别是最不发达国家援助力度，促进缩小南北发展差距。中国支持多边贸易体制，促进自由贸易区建设，推动建设开放型世界经济。 中国秉持共商共建共享的全球治理观，倡导国际关系民主化，坚持国家不分大小、强弱、贫富一律平等，支持联合国发挥积极作用，支持扩大发展中国家在国际事务中的代表性和发言权。中国将继续发挥负责任大国作用，积极参与全球治理体系改革和建设，不断贡献中国智慧和力量。 同志们！世界命运握在各国人民手中，人类前途系于各国人民的抉择。中国人民愿同各国人民一道，推动人类命运共同体建设，共同创造人类的美好未来！ 十三、坚定不移全面从严治党，不断提高党的执政能力和领导水平 中国特色社会主义进入新时代，我们党一定要有新气象新作为。打铁必须自身硬。党要团结带领人民进行伟大斗争、推进伟大事业、实现伟大梦想，必须毫不动摇坚持和完善党的领导，毫不动摇把党建设得更加坚强有力。 全面从严治党永远在路上。一个政党，一个政权，其前途命运取决于人心向背。人民群众反对什么、痛恨什么，我们就要坚决防范和纠正什么。全党要清醒认识到，我们党面临的执政环境是复杂的，影响党的先进性、弱化党的纯洁性的因素也是复杂的，党内存在的思想不纯、组织不纯、作风不纯等突出问题尚未得到根本解决。要深刻认识党面临的执政考验、改革开放考验、市场经济考验、外部环境考验的长期性和复杂性，深刻认识党面临的精神懈怠危险、能力不足危险、脱离群众危险、消极腐败危险的尖锐性和严峻性，坚持问题导向，保持战略定力，推动全面从严治党向纵深发展。 新时代党的建设总要求是：坚持和加强党的全面领导，坚持党要管党、全面从严治党，以加强党的长期执政能力建设、先进性和纯洁性建设为主线，以党的政治建设为统领，以坚定理想信念宗旨为根基，以调动全党积极性、主动性、创造性为着力点，全面推进党的政治建设、思想建设、组织建设、作风建设、纪律建设，把制度建设贯穿其中，深入推进反腐败斗争，不断提高党的建设质量，把党建设成为始终走在时代前列、人民衷心拥护、勇于自我革命、经得起各种风浪考验、朝气蓬勃的马克思主义执政党。 (一)把党的政治建设摆在首位。旗帜鲜明讲政治是我们党作为马克思主义政党的根本要求。党的政治建设是党的根本性建设，决定党的建设方向和效果。保证全党服从中央，坚持党中央权威和集中统一领导，是党的政治建设的首要任务。全党要坚定执行党的政治路线，严格遵守政治纪律和政治规矩，在政治立场、政治方向、政治原则、政治道路上同党中央保持高度一致。要尊崇党章，严格执行新形势下党内政治生活若干准则，增强党内政治生活的政治性、时代性、原则性、战斗性，自觉抵制商品交换原则对党内生活的侵蚀，营造风清气正的良好政治生态。完善和落实民主集中制的各项制度，坚持民主基础上的集中和集中指导下的民主相结合，既充分发扬民主，又善于集中统一。弘扬忠诚老实、公道正派、实事求是、清正廉洁等价值观，坚决防止和反对个人主义、分散主义、自由主义、本位主义、好人主义，坚决防止和反对宗派主义、圈子文化、码头文化，坚决反对搞两面派、做两面人。全党同志特别是高级干部要加强党性锻炼，不断提高政治觉悟和政治能力，把对党忠诚、为党分忧、为党尽职、为民造福作为根本政治担当，永葆共产党人政治本色。 (二)用新时代中国特色社会主义思想武装全党。思想建设是党的基础性建设。革命理想高于天。共产主义远大理想和中国特色社会主义共同理想，是中国共产党人的精神支柱和政治灵魂，也是保持党的团结统一的思想基础。要把坚定理想信念作为党的思想建设的首要任务，教育引导全党牢记党的宗旨，挺起共产党人的精神脊梁，解决好世界观、人生观、价值观这个“总开关”问题，自觉做共产主义远大理想和中国特色社会主义共同理想的坚定信仰者和忠实实践者。弘扬马克思主义学风，推进“两学一做”学习教育常态化制度化，以县处级以上领导干部为重点，在全党开展“不忘初心、牢记使命”主题教育，用党的创新理论武装头脑，推动全党更加自觉地为实现新时代党的历史使命不懈奋斗。 (三)建设高素质专业化干部队伍。党的干部是党和国家事业的中坚力量。要坚持党管干部原则，坚持德才兼备、以德为先，坚持五湖四海、任人唯贤，坚持事业为上、公道正派，把好干部标准落到实处。坚持正确选人用人导向，匡正选人用人风气，突出政治标准，提拔重用牢固树立“四个意识”和“四个自信”、坚决维护党中央权威、全面贯彻执行党的理论和路线方针政策、忠诚干净担当的干部，选优配强各级领导班子。注重培养专业能力、专业精神，增强干部队伍适应新时代中国特色社会主义发展要求的能力。大力发现储备年轻干部，注重在基层一线和困难艰苦的地方培养锻炼年轻干部，源源不断选拔使用经过实践考验的优秀年轻干部。统筹做好培养选拔女干部、少数民族干部和党外干部工作。认真做好离退体干部工作。坚持严管和厚爱结合、激励和约束并重，完善干部考核评价机制，建立激励机制和容错纠错机制，旗帜鲜明为那些敢于担当、踏实做事、不谋私利的干部撑腰鼓劲。各级党组织要关心爱护基层干部，主动为他们排忧解难。 人才是实现民族振兴、赢得国际竞争主动的战略资源。要坚持党管人才原则，聚天下英才而用之，加快建设人才强国。实行更加积极、更加开放、更加有效的人才政策，以识才的慧眼、爱才的诚意、用才的胆识、容才的雅量、聚才的良方，把党内和党外、国内和国外各方面优秀人才集聚到党和人民的伟大奋斗中来，鼓励引导人才向边远贫困地区、边疆民族地区、革命老区和基层一线流动，努力形成人人渴望成才、人人努力成才、人人皆可成才、人人尽展其才的良好局面，让各类人才的创造活力竞相进发、聪明才智充分涌流。 (四)加强基层组织建设。党的基层组织是确保党的路线方针政策和决策部署贯彻落实的基础。要以提升组织力为重点，突出政治功能，把企业、农村、机关、学校、科研院所、街道社区、社会组织等基层党组织建设成为宣传党的主张、贯彻党的决定、领导基层治理、团结动员群众、推动改革发展的坚强战斗堡垒。党支部要担负好直接教育党员、管理党员、监督党员和组织群众、宣传群众、凝聚群众、服务群众的职责，引导广大党员发挥先锋模范作用。坚持“三会一课”制度，推进党的基层组织设置和活动方式创新，加强基层党组织带头人队伍建设，扩大基层党组织覆盖面，着力解决一些基层党组织弱化、虚化、边缘化问题。扩大党内基层民主，推进党务公开，畅通党员参与党内事务、监督党的组织和干部、向上级党组织提出意见和建议的渠道。注重从产业工人、青年农民、高知识群体中和在非公有制经济组织、社会组织中发展党员。加强党内激励关怀帮扶。增强党员教育管理针对性和有效性，稳妥有序开展不合格党员组织处置工作。 (五)持之以恒正风肃纪。我们党来自人民、植根人民、服务人民，一旦脱离群众，就会失去生命力。加强作风建设，必须紧紧围绕保持党同人民群众的血肉联系，增强群众观念和群众感情，不断厚植党执政的群众基础。凡是群众反映强烈的问题都要严肃认真对待，凡是损害群众利益的行为都要坚决纠正。坚持以上率下，巩固拓展落实中央八项规定精神成果，继续整治“四风”问题，坚决反对特权思想和特权现象。重点强化政治纪律和组织纪律，带动廉洁纪律、群众纪律、工作纪律、生活纪律严起来。坚持开展批评和自我批评，坚持惩前毖后、治病救人，运用监督执纪“四种形态”，抓早抓小、防微杜渐。赋予有干部管理权限的党组相应纪律处分权限，强化监督执纪问责。加强纪律教育，强化纪律执行，让党员、干部知敬畏、存戒惧、守底线，习惯在受监督和约束的环境中工作生活。 (六)夺取反腐败斗争压倒性胜利。人民群众最痛恨腐败现象，腐败是我们党面临的最大威胁。只有以反腐败永远在路上的坚韧和执着，深化标本兼治，保证干部清正、政府清廉、政治清明，才能跳出历史周期率，确保党和国家长治久安。当前，反腐败斗争形势依然严峻复杂，巩固压倒性态势、夺取压倒性胜利的决心必须坚如磐石。要坚持无禁区、全覆盖、零容忍，坚持重遏制、强高压、长震慑，坚持受贿行贿一起查，坚决防止党内形成利益集团。在市县党委建立巡察制度，加大整治群众身边腐败问题力度。不管腐败分子逃到哪里，都要缉拿归案、绳之以法。推进反腐败国家立法，建设覆盖纪检监察系统的检举举报平台。强化不敢腐的震慑，扎牢不能腐的笼子，增强不想腐的自觉，通过不懈努力换来海晏河清、朗朗乾坤。 (七)健全党和国家监督体系。增强党自我净化能力，根本靠强化党的自我监督和群众监督。要加强对权力运行的制约和监督，让人民监督权力，让权力在阳光下运行，把权力关进制度的笼子。强化自上而下的组织监督，改进自下而上的民主监督，发挥同级相互监督作用，加强对党员领导干部的日常管理监督。深化政治巡视，坚持发现问题、形成震慑不动摇，建立巡视巡察上下联动的监督网。深化国家监察体制改革，将试点工作在全国推开，组建国家、省、市、县监察委员会，同党的纪律检查机关合署办公，实现对所有行使公权力的公职人员监察全覆盖。制定国家监察法，依法赋予监察委员会职责权限和调查手段，用留置取代“两规”措施。改革审计管理体制，完善统计体制。构建党统一指挥、全面覆盖、权威高效的监督体系，把党内监督同国家机关监督、民主监督、司法监督、群众监督、舆论监督贯通起来，增强监督合力。 (八)全面增强执政本领。领导十三亿多人的社会主义大国，我们党既要政治过硬，也要本领高强。要增强学习本领，在全党营造善于学习、勇于实践的浓厚氛围，建设马克思主义学习型政党，推动建设学习大国。增强政治领导本领，坚持战略思维、创新思维、辩证思维、法治思维、底线思维，科学制定和坚决执行党的路线方针政策，把党总揽全局、协调各方落到实处。增强改革创新本领，保持锐意进取的精神风貌，善于结合实际创造性推动工作，善于运用互联网技术和信息化手段开展工作。增强科学发展本领，善于贯彻新发展理念，不断开创发展新局面。增强依法执政本领，加快形成覆盖党的领导和党的建设各方面的党内法规制度体系，加强和改善对国家政权机关的领导。增强群众工作本领，创新群众工作体制机制和方式方法，推动工会、共青团、妇联等群团组织增强政治性、先进性、群众性，发挥联系群众的桥梁纽带作用，组织动员广大人民群众坚定不移跟党走。增强狠抓落实本领，坚持说实话、谋实事、出实招、求实效，把雷厉风行和久久为功有机结合起来，勇于攻坚克难，以钉钉子精神做实做细做好各项工作。增强驾驭风险本领，健全各方面风险防控机制，善于处理各种复杂矛盾，勇于战胜前进道路上的各种艰难险阻，牢牢把握工作主动权。 同志们！伟大的事业必须有坚强的党来领导。只要我们党把自身建设好、建设强，确保党始终同人民想在一起、干在一起，就一定能够引领承载看中国人民伟大梦想的航船破浪前进，胜利驶向光辉的彼岸！ 同志们！中华民族是历经磨难、不屈不挠的伟大民族，中国人民是勤劳勇敢、自强不息的伟大人民，中国共产党是敢于斗争、敢于胜利的伟大政党。历史车轮滚滚向前，时代潮流浩浩荡荡。历史只会眷顾坚定者、奋进者、搏击者，而不会等待犹豫者、懈怠者、畏难者。全党一定要保持艰苦奋斗、戒骄戒躁的作风，以时不我待、只争朝夕的精神，奋力走好新时代的长征路。全党一定要自觉维护党的团结统一，保持党同人民群众的血肉联系，巩固全国各族人民大团结，加强海内外中华儿女大团结，团结一切可以团结的力量，齐心协力走向中华民族伟大复兴的光明前景。 青年兴则国家兴，青年强则国家强。青年一代有理想、有本领、有担当，国家就有前途，民族就有希望。中国梦是历史的、现实的，也是未来的；是我们这一代的，更是青年一代的。中华民族伟大复兴的中国梦终将在一代代青年的接力奋斗中变为现实。全党要关心和爱护青年，为他们实现人生出彩搭建舞台。广大青年要坚定理想信念，志存高远，脚踏实地，勇做时代的弄潮儿，在实现中国梦的生动实践中放飞青春梦想，在为人民利益的不懈奋斗中书写人生华章！ 大道之行，天下为公。站立在九百六十多万平方公里的广裹土地上，吸吮着五千多年中华民族漫长奋斗积累的文化养分，拥有十三亿多中国人民聚合的磅礴之力，我们走中国特色社会主义道路，具有无比广阔的时代舞台，具有无比深厚的历史底蕴，具有无比强大的前进定力。全党全国各族人民要紧密团结在党中央周围，高举中国特色社会主义伟大旗帜，锐意进取，埋头苦干，为实现推进现代化建设、完成祖国统一、维护世界和平与促进共同发展三大历史任务，为决胜全面建成小康社会、夺取新时代中国特色社会主义伟大胜利、实现中华民族伟大复兴的中国梦、实现人民对美好生活的向往继续奋斗！ 参考自： https://mp.weixin.qq.com/s/e6quFK5Ct4hDHRZ6Hv8j7g 根据开幕式现场视频做出了增加。并将最后的图片识别为文字。 http://tv.cctv.com/live/cctv13/]]></content>
      <tags>
        <tag>十九大</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[梯度下降及其优化算法]]></title>
    <url>%2F2017%2F10%2F17%2FDL_gradient_descent%2F</url>
    <content type="text"><![CDATA[梯度下降法梯度下降是一个最优化算法，通俗的来讲也就是沿着梯度下降的方向来求出一个函数的极小值。 那么我们在高等数学中学过，对于一些我们了解的函数方程，我们可以对其求一阶导和二阶导，比如说二次函数。可是我们在处理问题的时候遇到的并不都是我们熟悉的函数，并且既然是机器学习就应该让机器自己去学习如何对其进行求解，显然我们需要换一个思路。因此我们采用梯度下降，不断迭代，沿着梯度下降的方向来移动，求出极小值。 批量梯度下降（Batch gradient descent）现在我们就要求出J(θ)取到极小值时的θT向量。之前已经说过了，沿着函数梯度的方向下降就能最快的找到极小值。 $$\theta=\theta-\eta \nabla_\theta{J(\theta)}$$ 计算J(θ)关于θT的偏导数,也就得到了向量中每一个θ的梯度。 沿着梯度的方向更新参数θ的值 迭代直到收敛。 批量梯度下降算法使用整个训练集计算目标函数的梯度并更新参数。代码如下： for i in range(nb_epochs): params_grad = evaluate_gradient(loss_function, data, params) params = params - learning_rate * params_grad 可以看到，批量梯度下降是用了训练集中的所有样本。因此在数据量很大的时候，每次迭代都要遍历训练集一遍，开销会很大，所以在数据量大的时候，可以采用随机梯度下降法。 随机梯度下降（Stochastic gradient descent）和批量梯度有所不同的地方在于，每次迭代只选取一个样本的数据，一旦到达最大的迭代次数或是满足预期的精度，就停止。 可以得出随机梯度下降法的θ更新表达式。 $$\theta=\theta-\eta\nabla_\theta{J(\theta;x^{(i)},y^{(i)})}$$ 因为每次只计算一个样本，所以SGD计算非常快并且适合线上更新模型。但是，频繁地更新参数也使得目标函数抖动非常厉害。 SGD频繁地参数更新可以使算法跳出局部最优点，更可能寻找到接近全局最优的解。SGD代码如下： for i in range(nb_epochs): np.random.shuffle(data) for example in data: params_grad = evaluate_gradient(loss_function, example, params) patams = params - learning_rate * params_grad 注意，上面的代码在每个epoch都对训练数据进行了打乱操作，这样可以保证不同epoch学习到的特征和训练样本的出现顺序没有关系。 使用情况如果仅从测试误差出发，标准梯度下降的效果会比随机梯度下降要好。但是标准梯度下降的训练时间会比随机梯度下降要长。 像线性回归这种简单的模型，训练时间的优先级不高，所以用标准梯度下降会比随机梯度下降要好。像神经网络这种复杂的模型，训练时间的优先级比较高，所以用随机梯度下降比较好。 如果模型的损失函数是凸函数，那么使用标准梯度下降一定能达到全局最优。如果模型比较复杂，容易进入局部最优，那么使用随机梯度下降会发生震荡，容易从局部最优中跳出，进入全局最优。 另外，神经网络模型使用标准梯度下降最重要的原因是神经网络容易过拟合，而不是训练时间。 小批量梯度下降(mini-batch gradient descent)小批量梯度下降结合了批量梯度下降和随机梯度下降的优点，它一次以小批量的训练数据计算目标函数的权重并更新参数。公式如下： $$\theta=\theta-\eta\nabla_\theta{J(\theta;x^{(i:i+n)};y^{(i:i+n)})}$$ 其中，n为每批训练集的数量，一般设为50到256。 for i in range(nb_epochs): np.random.shuffle(data) for batch in get_batches(data, batch_size=50): params_grad = evaluate_gradient(loss_function, batch, params) params = params - learning_rate * params_grad 这个算法有下面几个方面的优点： 相比较SGD增加了一次更新使用的训练数据量，使得目标函数收敛得更加平稳； 可以使用矩阵操作对每批数据进行计算，大大提升了算法的效率。 梯度下降的优缺点mini-batch gradient descent虽然相较于批量梯度下降和随机梯度下降方法效果有所改善但是任然存在许多挑战： 难以选择合适的学习速率：如果学习速率选择过小会造成网络收敛太慢，但是设得太大可能使得损失函数在最小点周围不断摇摆而永远达不到最小点； 可以在训练开始时设置一个较大地学习率然后每训练若干个周期后按比例降低学习率，虽然这个方法有一些作用，但是由于降低学习率的周期是人为事先设定的，所以它不能很好地适应数据内在的规律； 另一方面，我们对特征向量中的所有的特征都采用了相同的学习率，如果训练数据十分稀疏并且不同特征的变化频率差别很大，这时候对变化频率慢得特征采用大的学习率而对变化频率快的特征采用小的学习率是更好的选择。 这些梯度下降方法难以逃脱”鞍点”, 如下图所示，鞍点既不是最大点也不是最小点，在这个点附近，所有方向上的梯度都接近于0，这些梯度下降算法很难逃离它。 梯度下降算法的改进冲量(Momentum)实际中，我们遇到的目标函数往往在不同的维度上梯度相差很大，比如在下面的函数等高线图中可以看出函数在纵向上要比横向陡峭得多。 然而`SGD等基本梯度下降算法并不知道这些，因为y方向梯度大x方向梯度小所以它们会在y方向上不断摇摆而沿x方向缓慢移动，但是我们知道在y方向的震荡是无用的只有x方向的才在不断接近最优点。 冲量方法在SGD的基础上，加上了上一步的梯度： 其中γ通常设为0.9。 由于目标函数在y方向上摇摆，所以前后两次计算的梯度在y方向上相反，所以相加后相互抵消，而x方向上梯度方向不变，所以x方向的梯度是累加的，其效果就是损失函数在y方向上的震荡减小了，而更加迅速地从x方向接近最优点。 也可以把这个过程和在斜坡放一个球让其滚下类比：当从斜坡顶端释放一个小球时，由于重力的作用小球滚下的速度会越来越快；与此类似，冲量的作用会使相同方向的梯度不断累加，不同方向的梯度相互抵消，其效果就是逼近最优点的速度不断加快。 Nesterov accelerated gradient想象小球从山坡上滑落，它的速度沿着山坡不断加快，然而这并不是令我们满意的结果，当小球接近山谷(最优点)时，它已经有了很大的速度，很可能会再次冲向山谷的另一边，而错过了最优点。我们需要一颗更加“聪明”的小球，它能够感知坡度的变化，从而在它再次冲上山坡之前减速而避免错过山谷。 Nesterov accelerated gradient(NAG)就是一种让小球变“聪明”的方法。NAG不但增加了动量项，并且计算参数的梯度时，在损失函数中减去了梯度项将其作为下一次参数所在位置的预估： 同样，上式中的γ 一般设为0.9。 如下图所示，蓝色的是动量方法的更新路径，首先计算一次梯度更新一小步，然后在下一次累加上一次计算的梯度从而更新一大步。而NAG算法每一步更新过程由两个步骤组成：第一步($\gamma v_{t−1}$, 图中棕色)使用之前计算的梯度移动一大步，第二步在移动后的位置计算的梯度方向移动一小步(图中红色线)进行修正，经过这样的两步合成了最终的绿线部分。 分析上面的原理可知，当“小球”将要冲上山坡的另一面时，红色线表示的预测梯度方向发生改变，从而将棕色向量往回拉达到了“减速”的效果。 通过NAG方法，我们使参数更新速率能够自适应“坡度”的变化，另一方面，我们希望每个单独的参数能够自适应各自的变化频率，比如，稀疏特征采用高的更新速率，其他特征采用相对较低的更新速率。下面介绍几种常用的方法。 详细介绍可以参见Ilya Sutskever的PhD论文Sutskever, I. (2013). Training Recurrent neural Networks. PhD Thesis. AdagradAdadeltaRMSpropAdamAdam的全称是Adaptive Moment Estimation, 它也是一种自适应学习率方法，与Adadelta和RMSprop类似，它将每个参数的历史梯度平方均值存于$v_t$中，不同的是，Adam还使用了类似冲量的衰减项$m_t$: 效果图a中，所有方法都从相同位置出发，经历不同的路径到达了最小点，其中Adagrad、Adadelta和RMSprop一开始就朝向正确的方向并且迅速收敛，而冲量、NAG则会冲向错误的方向，但是由于NAG会向前多“看”一步所以能很快找到正确的方向。 图b显示了这些方法逃离鞍点的能力，鞍点有部分方向有正梯度另一些方向有负梯度，SGD方法逃离能力最差，冲量和NAG方法也不尽如人意，而Adagrad、RMSprop、Adadelta很快就能从鞍点逃离出来。 参考资料 http://www.cnblogs.com/Sinte-Beuve/p/6164689.html http://blog.csdn.net/ortyijing/article/details/54984058 http://blog.csdn.net/bupt_wx/article/details/52761751 http://blog.csdn.net/heyongluoyao8/article/details/52478715 http://cs231n.github.io/neural-networks-3/ http://www.360doc.com/content/16/1010/08/36492363_597225745.shtml其中，第四个文章写得不错。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
        <tag>gradient descent</tag>
        <tag>梯度下降</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BAT批处理中的字符串处理(字符串截取等)]]></title>
    <url>%2F2017%2F10%2F10%2Fbatch_string_process%2F</url>
    <content type="text"><![CDATA[什么是批处理？在windows下，以cmd或者bat结尾的文件就是批处理文件；linux下，也有以sh结尾的shell脚本文件。 本文主要介绍了批处理在字符串处理中的一些方法： 字符串截取 字符串替换 字符串合并 字符串扩充 1、截取字符串截取字符串可以说是字符串处理功能中最常用的一个子功能了，能够实现截取字符串中的特定位置的一个或多个字符。举例说明其基本功能： @echo off set ifo=abcdefghijklmnopqrstuvwxyz0123456789 echo 原字符串（第二行为各字符的序号）： echo %ifo% echo 123456789012345678901234567890123456 echo 截取前5个字符： echo %ifo:~0,5% echo 截取最后5个字符： echo %ifo:~-5% echo 截取第一个到倒数第6个字符： echo %ifo:~0,-5% echo 从第4个字符开始，截取5个字符： echo %ifo:~3,5% echo 从倒数第14个字符开始，截取5个字符： echo %ifo:~-14,5% pause 当然，上面的例子只是将字符串处理的基本功能展示出来了，还看不出字符串处理具体有什么用处。下面这个例子是对时间进行处理。 @echo off echo 当前时间是：%time% 即 %time:~0,2%点%time:~3,2%分%time:~6,2%秒%time:~9,2%厘秒 pause 2、替换字符串替换字符串，即将某一字符串中的特定字符或字符串替换为给定的字符串。举例说明其功能： @echo off set aa=伟大的中国！我为你自豪！ echo 替换前：%aa% echo 替换后：%aa:中国=中华人民共和国% echo aa = %aa% set &quot;aa=%aa:中国=中华人民共和国%&quot; echo aa = %aa% pause 对于上面的例子有一点说明，对比两个echo aa = %aa%可以发现，如果要修改变量aa的内容的话，就需要将修改结果“%aa:中国=中华人民共和国%”赋值给变量aa。上面的字符串截取也有着同样的特点。 3、字符串合并其实，合并字符串就是将两个字符串放在一起就可以了。举例说明： @echo off set aa=伟大的中国！ set bb=我为你自豪！ echo %aa%%bb% echo aa=%aa% echo bb=%bb% set &quot;aa=%aa%%bb%&quot; echo aa=%aa% pause 同样，如果要改变变量aa的内容的话，就需要将合并结果“%aa%%bb%”赋值给变量aa。 4、扩充字符串 “扩充”这个词汇来自于微软自己的翻译，意思就是对表示文件路径的字符串进行特殊的处理，具体功能罗列如下： ========================================= ~I - 删除任何引号(&quot;)，扩充 %I %~fI - 将 %I 扩充到一个完全合格的路径名 %~dI - 仅将 %I 扩充到一个驱动器号 %~pI - 仅将 %I 扩充到一个路径 %~nI - 仅将 %I 扩充到一个文件名 %~xI - 仅将 %I 扩充到一个文件扩展名 %~sI - 扩充的路径只含有短名 %~aI - 将 %I 扩充到文件的文件属性 %~tI - 将 %I 扩充到文件的日期/时间 %~zI - 将 %I 扩充到文件的大小 %~$PATH:I - 查找列在路径环境变量的目录，并将 %I 扩充到找到的第一个完全合格的名称。如果环境变量名未被定义，或者没有找到文件，此组合键会扩充到空字符串可以组合修饰符来得到多重结果: %~dpI - 仅将 %I 扩充到一个驱动器号和路径 %~nxI - 仅将 %I 扩充到一个文件名和扩展名 %~fsI - 仅将 %I 扩充到一个带有短名的完整路径名 %~dp$PATH:i - 查找列在路径环境变量的目录，并将 %I 扩充到找到的第一个驱动器号和路径。 %~ftzaI - 将 %I 扩充到类似输出线路的 DIR ========================================= 以上内容引用于for /?帮助信息。其中的I代表变量I，不过需要说明的是，不是所有的变量都能够进行扩充的，有两个条件：1、该字符串代表一个文件路径；2、变量要用%x来表示，x可取a-z A-Z 0-9共62个字符中的任意一个。举例说明： @echo off echo 正在运行的这个批处理： echo 完全路径：%0 echo 去掉引号：%~0 echo 所在分区：%~d0 echo 所处路径：%~p0 echo 文件名：%~n0 echo 扩展名：%~x0 echo 文件属性：%~a0 echo 修改时间：%~t0 echo 文件大小：%~z0 pause 其中的%0是批处理里面的参数，代表当前运行的批处理的完全路径。类似的还有%1-%9，分别代表传递来的第1-9个参数。例子如下： @echo off set aa=C:\Windows\PPP\a.btx call :deal aaa %aa% &quot;c c&quot; ddd eee pause&gt;nul exit :deal echo %%0 = %0 echo %%1 = %1 echo %%2 = %2 echo %%3 = %3 echo %%4 = %4 echo %%5 = %5 其中，变量aa在之前是不可以扩充的，通过call命令并将aa作为参数传递给子函数:deal，将aa变量转换成了变量%1，即符合%x格式，从而可以进行字符串扩充。 至于%x中x取a-z A-Z的形式，可以复习一下for语句，for语句里面的变量就是用%x来表示的，因而可以直接进行扩充。 补充C语中的strcpy函数C语中的strcpy函数，将一个字符串复制到另一个字符型指针或字符数组，覆盖原来的字符串。 C语言中的调用方法：strcpy(目标字符串,源字符串) 在批处理中的实现方法： set 目标字符串=%源字符串% 示例： @echo off ::关闭屏幕回显（可选） set str1=This is old string ::设置str1中存储的字符串，注意没有双引号，这点与C语言等不同！ set str2=This is new string ::设置str2中存储的字符串 echo 执行字符串拷贝以前： echo str1=%str1% echo str2=%str2% ::先输出一次原有的字符串 set str1=%str2% ::字符串拷贝 echo 执行字符串拷贝以后： echo str1=%str1% echo str2=%str2% ::输出执行完字符串拷贝后的字符串 echo 输出完毕，按任意键退出&amp;&amp;pause&gt;nul&amp;&amp;exit ::输出信息，当用户按任意键时，结束该批处理。 2.C语中的strcat函数C语中的strcat函数，将一个字符串连接到另一个字符型指针或字符数组的末尾。 C语言中的调用方法：strcat(目标字符串,源字符串) 在批处理中的实现方法： set 目标字符串=%目标字符串%%源字符串% 示例： @echo off set str1=This is string1 set str2=This is string2 ::设置str1和str2中存储的字符串 echo 连接字符串以前： echo str1=%str1% echo str2=%str2% ::先输出一次原有的字符串 set str1=%str1%%str2% ::字符串连接 echo 连接字符串以后： echo str1=%str1% echo str2=%str2% ::输出执行完字符串连接后的两个字符串 echo 输出完毕，按任意键退出&amp;&amp;pause&gt;nul&amp;&amp;exit 3、字符串截取C中没有这种函数，不过可以通过语句实现，不再介绍，直接说批处理的。 set 目标字符串=%源字符串:~起始值,截取长度% 注意，起始值从0开始！ 截取长度是可选的，如果省略逗号和截取长度，将会从起始值一直截取到字符串的结尾。 示例： @echo off set str1=This is string1 ::设置str1中存储的字符串 set str2=%str1:~8,6% set str3=%str1:~0,4% set str4=%str1:~5% ::字符串截取 echo 原字符串： echo str1=%str1% echo 截取得到的字符串： echo str2=%str2% echo str3=%str3% echo str4=%str4% ::输出执行结果 echo 输出完毕，按任意键退出&amp;&amp;pause&gt;nul&amp;&amp;exit 4、C语中的strlen函数，取得字符串的长度。C语言中的调用方法：strlen(字符串) 在批处理中的实现方法是利用goto和标签，形成循环结构，不断将字符串截短1字符，并用变量记录截短的次数，直到字符串变成空串。 示例： @echo off set str1=This is a test string set str2=Hello World ::设置两个字符串 set str=%str1% ::将str1复制到str :next1 ::标签，用于goto跳转 ::注意与注释语句的区别，注释用两个冒号开头，标签则为一个冒号 if not &quot;%str%&quot;==&quot;&quot; ( ::判断str是不是空串，如果不是则执行下边的语句 set /a num+=1 ::算术运算，使num的值自增1，相当于num++或者++num语句 set &quot;str=%str:~1%&quot; ::截取字符串，赋给自身 goto next1 ::跳转到next1标签 ::这里利用goto和标签，构成循环结构 ) ::当以上循环结构执行完毕时，会执行下边的语句 echo str1=%str1% echo str1的长度为：%num% ::输出结果 set num=0 ::将记和用的环境变量num置0，以便开始下一次运算。 set str=%str2% ::将str2复制到str :next2 ::定义一个新的标签 ::注意不能与已有的标签同名，否则会出错！ if not &quot;%str%&quot;==&quot;&quot; ( set /a num+=1 set &quot;str=%str:~1%&quot; goto next2 ) ::和上一个循环相似，不再介绍 echo str2=%str2% echo str2的长度为：%num% ::输出结果 echo 输出完毕，按任意键退出&amp;&amp;pause&gt;nul&amp;&amp;exit 5、C语中的strchr函数，在一个字符串中查找一个字符的首次出现位置，找到时返回所在位置，找不到时返回0值。 批处理中的思路：不断截短字符串，并取截短后字符串中的首字符，和要求的字符比较，如果相同就利用goto语句跳出循环，输出结果，如果没有相同的字符，执行到最后就输出0值。 示例： @echo off Setlocal ENABLEDELAYEDEXPANSION ::启用命令扩展，参加setlocal /?命令 set str1=This is a test string set ch1=t ::注意，这里是区分大小写的！ set str=%str1% ::复制字符串，用来截短，而不影响源字符串 :next if not &quot;%str%&quot;==&quot;&quot; ( set /a num+=1 if &quot;!str:~0,1!&quot;==&quot;%ch1%&quot; goto last ::比较首字符是否为要求的字符，如果是则跳出循环 set &quot;str=%str:~1%&quot; goto next ) set /a num=0 ::没有找到字符时，将num置零 :last echo 字符&apos;%ch1%&apos;在字符串&quot;%str1%&quot;中的首次出现位置为%num% echo 输出完毕，按任意键退出&amp;&amp;pause&gt;nul&amp;&amp;exit 参考自：http://www.jb51.net/article/52744.htm]]></content>
      <categories>
        <category>批处理</category>
      </categories>
      <tags>
        <tag>批处理</tag>
        <tag>bat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习系列：（五）机器学习基础]]></title>
    <url>%2F2017%2F10%2F08%2FDL_chap_5%2F</url>
    <content type="text"><![CDATA[5.8 无监督学习从不需要人为注释的样本中抽取信息。 通常与密度估计有关。 学习从分布中采样，学习从分布中去噪，寻找数据分布的流形 或是 将数据中相关的样本聚类。 一个经典的无监督学习任务：找到数据的“最佳”表示。 较简单表示主要有三种：低维表示、稀疏表示和独立表示。 表示的概念是深度学习的核心主题之一，也是本书的核心主题之一。 5.8.1 主成分分析通过线性变换W将数据从x投影到z时，得到的数据表示的协方差矩阵为对角的。即：z中的元素是彼此无关的。 5.8.2 k-均值聚类k均值聚类的算法提供了k维的one-hot编码向量h以表示输入x。当x属于聚类i时，有$h_i=1$，h的其他项为零。 one-hot编码是稀疏表示的极端示例，丢失了很多分布式表示的优点。 k-均值聚类初始化k个不同的中心点$\mu^{(1)},\cdots ,\mu^{(k)}$，然后迭代交换两个不同的步骤直到收敛。 步骤一，每个训练样本分配到最近的中心点$\mu^{(i)}$所代表的聚类$i\ $。步骤二，每个中心点更新为聚类$i\ $中所有训练样本$x^{(i)}$的均值。 聚类问题的本身是病态的。没有单一的标准去度量聚类的数据在真实世界中效果如何。 因此，我们可能更偏好于分布式表示。分布式表示可以对每个车辆赋予两个属性——一个表示它的颜色，一个表示它是汽车还是卡车。 5.9 随机梯度下降随机梯度下降：stochastic gradient descent,SGD。 机器学习中的代价函数通常可以分解为每个样本的代价函数的总和。 训练数据的负条件对数似然 $\;$可以写为： $$J(\theta) = E_{x,\; y \sim \hat P_{data}}L(x,y,\theta ) = \frac 1m \sum_{i=1}^m L(x^{(i)},y^{(i)},\theta ) $$ 其中，L是每个样本的损失函数。 随机梯度下降的核心是，梯度是期望。期望可使用小规模的样本近似估计。 5.10 构建机器学习算法组合模型、代价和优化算法 来构建机器学习算法的配方。适用于监督学习以及非监督学习。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[准确率，召回率与F1值]]></title>
    <url>%2F2017%2F10%2F08%2FDL_Precision_and_Recall%2F</url>
    <content type="text"><![CDATA[下面有关分类算法的准确率，召回率，F1 值的描述，错误的是？A.准确率是检索出相关文档数与检索出的文档总数的比率，衡量的是检索系统的查准率B.召回率是指检索出的相关文档数和文档库中所有的相关文档数的比率，衡量的是检索系统的查全率C.正确率、召回率和 F 值取值都在0和1之间，数值越接近0，查准率或查全率就越高D.为了解决准确率和召回率冲突问题，引入了F1分数 TP——将正类预测为正类数 FN——将正类预测为负类数 FP——将负类预测为正类数 TN——将负类预测为负类数 精确率（Precision）P = TP/(TP+FP)反映了被分类器判定的正例中真正的正例样本的比重。 精确率是针对我们预测结果而言的，它表示的是预测为正的样本中有多少是真正的正样本。那么预测为正就有两种可能了，一种就是把正类预测为正类(TP)，另一种就是把负类预测为正类(FP)。 准确率（Accuracy）：A = （TP+TN）/ （P+N） = （TP+TN）/ （TP+FN+FP+TN）准确率(正确率)：反映了分类器统对整个样本的判定能力——能将正的判定为正，负的判定为负。 被分对的样本数除以所有的样本数，通常来说，正确率越高，分类器越好。 召回率（Recall）：R = TP/（TP+FN）= 1-[FN/（TP+FN）]反映了被正确判定的正例占总的正例的比重。 而召回率是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确了。那也有两种可能，一种是把原来的正类预测成正类(TP)，另一种就是把原来的正类预测为负类(FN)。 所有正例中被分对的比例，衡量了分类器对正例的识别能力。 精确率和召回率，两者取值在0和1之间，数值越接近1，查准率或查全率就越高。 F1值F1 = 2（Recall Precision）/（Recall + Precision） 精准率和召回率和F1取值都在0和1之间，精准率和召回率高，F1值也会高，不存在数值越接近0越高的说法，应该是数值越接近1越高。 总结一句话概括：精确率Precision是预测的正例里有多少是预测正确的，召回率Recall是真正的正例里有多少预测正确的。 精确是预测，召回是原本。 参考资料： https://www.zhihu.com/question/19645541/answer/12502751 https://www.nowcoder.com/test/question/done?tid=11555865&amp;qid=14638#summary]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>准确率</tag>
        <tag>召回率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习系列：（六）前馈神经网络]]></title>
    <url>%2F2017%2F10%2F08%2FDL_chap_6%2F</url>
    <content type="text"><![CDATA[6.1 实例：学习XOR采用一个简单的前馈神经网络，一个隐含层，隐含层包含两个单元。 整个网络为： $$f(x;W,c,w,b) = w^T\text{max}(0,W^Tx+c)+b$$ 隐含层激活函数采用的是ReLU。 给出一个解：$$W= \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 1 \\ \end{bmatrix}$$$$c= \begin{bmatrix} 0 \\ -1 \\ \end{bmatrix}$$$$w= \begin{bmatrix} 1 \\ -2 \\ \end{bmatrix}$$以及：$$ b = 0 $$ 6.2 基于梯度的学习对于前馈神经网络，将所有权重初始化为小的值是很重要的。偏置可以初始化为0或者小的正值(如0.1)。 第8章介绍迭代的基于梯度的优化算法，8.4节为参数初始化，4.3节介绍了一些特别的算法，是对梯度下降思想的改进和提纯。随机梯度下降将算法的改进在5.9节。 6.2.1 代价函数大多数情况下，参数模型定义了一个分布$p(y|x;\theta)$，并且简单地使用最大似然原理。使用训练数据和模型预测间的交叉熵作为代价函数。 完整的代价函数 = 基本代价函数 + 正则项。 最流行的正则化策略：权重衰减（weight decay）。 第7章介绍更高级的正则化策略。 6.2.1.1 使用最大似然学习条件分布使用最大似然训练意味着代价函数就是负的对数似然。 负的对数似然 = 训练数据和模型分布间的交叉熵 。 代价函数为： $$J(\theta) = E_{x,\; y \sim \hat P_{data}} logP_{model}(y|x) $$ 代价函数的具体形式取决于模型$logP_{model}$的具体形式。展开后的代价函数，可以舍去其中不依赖于模型的参数。 如果有：$$P_{model}(y|x) = N(y;f(x;\theta),I) $$ 就可以得到均方误差代价： $$J(\theta) = \frac{1}{2} E_{x,\; y \sim \hat P_{data}} || y-f(x;\theta )||^2 +\text{const} $$ 代价函数的梯度必须足够大和具有足够的预测性，来为学习算法提供一个好的指引。 饱和（变得非常平）的函数破坏了这一目标，梯度非常小。该情况很常见是因为隐藏单元或输出单元的激活函数会饱和。 6.2.1.2 学习条件统计量预测器$f(x;\theta)$，预测y的均值。 代价泛函(可以表示一大类函数中的任何一个函数，仅仅被一些特征所限制，而不是具有特殊的参数形式)。 泛函是指函数到实数的映射。 对函数求解问题需要用到变分法(19.4.2节)。 变分法导出的第一个结果是解优化问题：$$f^* =\underset{f}{\mathrm{argmin}} E_{x,\; y \sim P_{data}}|| y-f(x)||^2$$ 得到：$$f^*(x) = E_{ y \sim P_{data}(y|x)}[y]$$ 最小化均方误差代价函数将得到一个函数，可以用来对每个x的值预测出y的均值。 第二个使用变分法得到的结果是： $$f^* = \underset{f}{\mathrm{argmin}} E_{x,\; y \sim P_{data}}|| y-f(x)||_1$$ 将得到一个函数可以对每个x预测y取值的中位数，只要这个函数在我们要优化的函数族里。这个函数通常被称为平均绝对误差(mean absolute error)。最小化平均绝对误差代价函数。 交叉熵代价函数 比均方误差或者平均绝对误差更受欢迎的原因也在此，饱和的输出单元当结合后两个代价函数时会产生非常小的梯度。 6.2.2 输出单元代价函数的选择：大多数情况下，简单使用数据分布和模型分布间的交叉熵。 本节中，假设前馈网络提供了一组定义为$h=f(x;\theta )$的隐藏特征。输出层的作用则是随后对这些特征进行额外的变换完成整个网络必须完成的任务。 6.2.2.1 用于Bernoulli输出分布的sigmoid单元两个类的分类问题，即预测二值型变量y。 最大似然定义$y\ $在$x\ $条件下的Bernoulli分布。 6.2.2.2 用于Multinoulli输出分布的softmax单元任何时候，当我们想要表示一个具有n个可能取值的离散型随机变量的分布时，都可以使用softmax函数。 softmax函数最常用作分类器的输出，来表示$n\ $个不同类上的概率分布。 首先，线性层预测了未归一化的对数概率：$$ z = W^Th+b$$其中，$z_i = log \hat P (y=i|x)$，softmax函数然后对$z\ $指数化和归一化来获得需要的$\hat y$。最终，softmax函数的形式为：$$ \text{softmax}(z)_i = \frac{\text{exp}(z_i)}{\sum_j \text{exp}(z_j)}$$ 当使用最大化对数似然训练softmax来输出目标值$y\ $时，这时，我们想要最大化$logP(y=i;z)=\log \text{softmax}(z)_i$。将softmax定义为指数的形式是因为对数似然中的log可以抵消softmax中的exp： $$\log \text{softmax(z)}_i = z_i -\log \sum_j \text{exp}(z_j)$$ 关于softmax的解释：这个函数更接近argmax函数而不是max函数。“soft”术语来源于softmax函数是连续可微的。“argmax”函数的结果表示为一个one-hot向量（只有一个元素为1，其余元素都为0的向量），不是连续可微的。softmax函数因此提供了argmax的“软化”版本，max函数相应的软化版本是$\text{softmax}(z)^Tz$。可能最好是把softmax函数称为“softargmax”，但当前名字已经是一个根深蒂固的习惯了。 6.2.2.4 其他的输出类型6.3 隐藏单元整流线性单元是隐藏单元极好的默认选择。 大多数隐藏单元的区别仅仅在于激活函数$g(z)$的形式。 隐藏单元少数点不可微的解释。 可微的定义是：只有函数在$z\ $处的左导数与右导数都有定义并且相等时，函数在$z\ $处才是可微的。 $g(z) = \text{max}(0,z)$，在$z=0$处的左导数为0，右导数为1。软件中实现通常是返回左导数或者右导数的其中一个，而不是报告导数未定义或者产生一个错误。 6.3.1 整流线性单元及其扩展整流线性单元的激活函数：$g(z) = \text{max}(0,z)$ 整流线性单元通常作用于仿射变换之上： $$h = g(W^Tx+b)$$ 6.3.2 logistic sigmoid与双曲正切函数双曲正切函数通常要比logistic sigmoid函数表现更好。 6.3.3 其他隐藏单元其中一种是完全没有隐藏单元$g(z)$。也可以说是用单位函数作为激活函数。 softmax单元是一种经常用作输出的单元，但有时候也可以用作隐藏单元。softmax单元很自然地表示具有k个可能值的离散型随机变量的概率分布，所以它们可以作为一种开关。将在10.12节介绍。 其他的一些隐藏单元包括： 径向基函数(radial basis function, RBF) softplus函数 硬双曲正切函数(hard tanh) 6.4 架构设计架构（architecture）一词指网络的整体结构：它应该具有多少单元，以及这些单元应该如何连接。 链式结构：每一层都是前一层的函数。主要的考虑因素是网络的深度和每层的宽度。 6.4.1 万能近似性质和深度万能近似定理(universal approximation theorem)：一个前馈神经网络如果具有线性输出层和至少一层具有任何一种“挤压”性质的激活函数（例如sigmoid函数）的隐含层，只要给予网络足够数量的隐藏单元，它可以以任意的精度近似任何从一个有限维空间到另一个有限维空间的Borel可测函数。 单层的前馈网络虽然足以表示任何函数，但是网络层可能大得不可实现。所以需要深度网络。 Montufar et al(2014):一些用深度整流网络表示的函数可能需要浅层网络（一个隐含层）指数级的隐藏单元才能表示。 根据经验，更深的模型确实在广泛的任务中泛化得更好。 6.4.2 其他架构上的考虑上述考虑的是简单的链式结构。在实践中，神经网络具有多样性。 用于计算机视觉的卷积神经网络的特殊架构在 第9章 中介绍。前馈网络也可以推广到序列处理的循环神经网络，但有它们自己的架构考虑，将在第10章中介绍。 架构设计考虑的另一个关键点是如何将层与层之间连接起来。 6.5 反向传播和其他的微分算法6.5.1 计算图图中每个节点表示一个变量。 6.5.2 微积分中的链式法则从标量扩展到向量的链式法则。 假设$x\in \mathbb R^m,\ y\in \mathbb R^n$，$g\ $是从$\mathbb R^m$到$\mathbb R^n$的映射，$f\ $是从$\mathbb R^n$到$\mathbb R\ $的映射。如果$y=g(x)$ 并且$z =f(y)$。那么：$$\frac{\partial z}{\partial x_i} = \sum_j \frac{\partial z}{\partial y_j} \frac{\partial y_j}{\partial x_i}$$ 使用向量记法，可以等价地写成：$$\triangledown_xz = (\frac {\partial y}{\partial x})^T \triangledown_yz$$这里的$\frac {\partial y}{\partial x}$是$g\ $的$n\times m $的Jacobian矩阵。 还可以从向量扩展到张量。 6.5.3 递归地使用链式法则来实现反向传播6.5.4 全连接MLP中的反向传播计算算法6.2反向传播时，偏导数的计算。 算法6.3是前向传播和代价函数的计算。 6.5.5 符号到符号的导数符号表示 反向传播的方法。 1 符号到数值的微分：计算图和一组用于图的输入的数值 2 符号到符号的方法：采用计算图和添加额外的节点到计算图中，这些额外的节点提供了我们所需导数的符号描述。 6.5.6 一般化的反向传播6.5.7 实例：用于MLP训练的反向传播训练多层感知机 交叉熵代价函数 6.5.8 复杂化操作返回多个张量。反向传播的内存消耗、现实实现。 6.5.9 深度学习界外的微分自动微分领域关系如何以算法方式计算微分。 这里描述的反向传播算法只是自动微分算法的一种方法。 反向模式累加和前向模式累加。 Theano和TensorFlow的实现使用基于匹配已知简化模式的试探法，以便重复地尝试去简化图。 在机器学习以外的社区，更常见的 是使用传统的编程语言来直接实现微分软件。例如用Python或者C来编程 6.5.10 高阶微分一些软件框架支持高阶导数。在深度学习软件框架中，这至少包括Theano和TensorFlow。 在深度学习的相关领域，很少会计算标量函数的单个二阶导数。相反，我们通常对Hessian矩阵的性质比较感兴趣。如果有函数$f:\mathbb{R}^n \to R$，那么Hessian矩阵的大小为$n\times n$。在典型的深度学习应用中，n将是模型的参数数量，可能很容易达到数十亿。因此，完整的Hessian矩阵甚至不能表示。 典型的深度学习方法是使用Krylov方法，而不是显式地计算Hessian矩阵。 Hessian矩阵上使用Krylov方法，只需要计算Hessian矩阵$H$和一个任意向量$v$间的乘积即可。 6.6 历史小记线性 -&gt; 非线性 反向传播 现代前馈网络的核心思想 交叉熵损失函数 分段线性隐藏单元（整流线性单元ReLU）]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MathJax的基本使用语法]]></title>
    <url>%2F2017%2F10%2F08%2Fmathjax_basic%2F</url>
    <content type="text"><![CDATA[字体 使用\mathbb或\Bbb来显示黑板粗体字，$\mathbb{NQRZ}$ 使用\mathbf来显示粗体字，$\mathbf {ABCDabcd}$ 使用\mathtt来显示打印式字体，$\mathtt{ABCDabcd}$ 使用\mathrm来显示罗马字体，$\mathrm{ABCDabcd}$ 使用\mathcal来显示手写字体，$\mathcal{ABCDabcd}$ 使用\mathscr来显示剧本字体，$\mathscr{ABCDabcd}$ 使用\mathfrak来显示Fraktur字母(一种旧的德国字体)，$\mathfrak{ABCDabcd}$ 插入公式如果是在文本中插入公式，则用$...$。 如果公式自成段落，则使用$$...$$。 多行公式如果要写出多行公式，就使用 \begin{equation}\begin{split} end{split}\end{equation} \\ 符号表示换行，再使用&amp;符号表示要对齐的位置，例子如下 \begin{equation}\begin{split} H(Y|X)&amp;=\sum_{x\in X} p(x)H(Y|X)\\ &amp;=-\sum_{x\in X} p(x)\sum_{y\in Y}p(y|x)\log p(y|x)\\ &amp;=-\sum_{x\in X} \sum_{y\in Y}p(y,x)\log p(y|x) \end{split}\end{equation} 当然，再加上$$...$$之后，显示如下：$$\begin{equation}\begin{split}H(Y|X)&amp;=\sum_{x\in X} p(x)H(Y|X)\\&amp;=-\sum_{x\in X} p(x)\sum_{y\in Y}p(y|x)\log p(y|x)\\&amp;=-\sum_{x\in X} \sum_{y\in Y}p(y,x)\log p(y|x)\end{split}\end{equation}$$ 分组通过大括号{}将操作数与符号分割开，消除二义性。 例如，若使用x^10，其效果为$x^10$，这里就要用到大括号，x^{10}，最终效果为$x^{10}$。 空间MathJax通常用自己的一套复杂策略来决定公式的空间距离。直接在两个元素之间加入空格是毫无用处的。 因此为了增加空间距离，使用\,可以增加稍许空间；使用\;可以增加更多的空间；\quad和\qquad分别对应更大的空间。 数学符号上标与下标上标或下标只需在后面加上^或_。另外需要注意的是，如果上下标不止一个字符，就需要用大括号括起来，表示是一个整体{...}。 分式有两种方式做到这个效果。 使用\frac ab。如\frac {1+a}{4+b}，效果为$\frac{1+a}{4+b}$; 使用a \over b。如{1+a} \over {4+b}，效果为${1+a}\over {4+b}$。 一般推荐使用第二种。个人倾向于使用第一种。 根式平方根： \sqrt{x^3}，效果为 $\sqrt{x^3} $。 其余： \sqrt[4]{\frac xy}，效果为 $\sqrt[4]{\frac xy}$。 关系比较符号&lt; \lt &gt; \gt ≤ \le ≥ \ge ≠ \neq $$\begin{array}{c|lcr}\text{符号} &amp; \text{\表示} \\\hline&lt; &amp; lt \\> &amp; gt \\≤ &amp; le \\≥ &amp; ge \\≠ &amp; neq \\\end{array}$$ argmax\underset{f}{\mathrm{argmin}} 效果如下：$$\underset{f}{\mathrm{argmin}}$$ 不显示斜体对于常量部分，有时候我们不想让他显示成斜体，而是正常的竖直显示，可加上\text{...}，就可以正常显示。 矩阵使用$$\begin{matrix}…\end{matrix}$$，每一行末用\\结束表示换行，用&amp;分隔矩阵元素。 $$ \begin{matrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \\ \end{matrix} $$ 效果：$$\begin{matrix}1 &amp; 0 &amp; 0 \\0 &amp; 1 &amp; 0 \\0 &amp; 0 &amp; 1 \\\end{matrix}$$ 如果要加括号，可以使用上面的括号符号。除此之外，还可以直接将matrix替换为pmatrix(小括号)，或者bmatrix(中括号)，或者Bmatrix(大括号)，或者vmatrix(竖线)，或者Vmatrix(是双竖线) 如果你想省略一些项，可以使用\cdots⋯，\ddots⋱，\vdots⋮。如： $$ \begin{pmatrix} 1 &amp; a_1 &amp; a_1^2 &amp; \cdots &amp; a_1^n\\ 1 &amp; a_2 &amp; a_2^2 &amp; \cdots &amp; a_2^n \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 1 &amp; a_n &amp; a_n^2 &amp; \cdots &amp; a_n^n \\ \end{pmatrix} $$ 效果：$$ \begin{pmatrix} 1 &amp; a_1 &amp; a_1^2 &amp; \cdots &amp; a_1^n\\ 1 &amp; a_2 &amp; a_2^2 &amp; \cdots &amp; a_2^n \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 1 &amp; a_n &amp; a_n^2 &amp; \cdots &amp; a_n^n \\ \end{pmatrix}$$ 代码块不同语言的代码块，可以用不同的标识符。如python语言，则代码块表示为` //下一行写具体代码 ``` `。12345678910111213就是用三个点号（英文状态下、键盘左上角、ESC下面的那个键）包围的部分就是代码块。测试：JavaScript代码块效果如下：```javascriptif (condition)&#123; return true&#125; Python代码块效果如下： 123def func(A): '''intresting document.''' return len(A)]]></content>
      <categories>
        <category>博客搭建系列</category>
      </categories>
      <tags>
        <tag>MathJax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[批处理的常用命令及用法]]></title>
    <url>%2F2017%2F10%2F05%2Fbatch_basic_usage%2F</url>
    <content type="text"><![CDATA[什么是批处理？在windows下，以cmd或者bat结尾的文件就是批处理文件；linux下，也有以sh结尾的shell脚本文件。 本文主要介绍了批处理的一些常用命令。 前言在这里，先解释什么是DOS？ DOS，即Disk Operation System，磁盘操作系统。 命令行就是在Windows操作系统中打开DOS窗口，以字符串的形式执行Windows管理程序。 那么，我们如何进入命令行窗口？ 开始–&gt;运行–&gt;键入”cmd”，回车即可。 阅读本文需要一定的dos基础概念，例如：盘符、文件、目录(文件夹)、子目录、根目录、当前目录 每个命令的完整说明请加 /? 参数参考微软的帮助文档可以看到。 注：如果对某一命令还不是很熟悉，可以在命令行窗口下输入：命令名/?的方式来获得帮助。 例如：对dir命令的应用不熟悉，可以在命令行窗口下输入： dir /? 批处理定义：顾名思义，批处理文件是将一系列命令按一定的顺序集合为一个可执行的文本文件，其扩展名为BAT或者CMD。这些命令统称批处理命令。 小知识：可以在键盘上按下Ctrl+C组合键来强行终止一个批处理的执行过程。 1 echo 和 @回显控制命令@ #关闭单行回显 echo off #从下一行开始关闭回显 @echo off #从本行开始关闭回显。一般批处理第一行都是这个 echo on #从下一行开始打开回显 echo #显示当前是 echo off 状态还是 echo on 状态 echo. #输出一个&quot;回车换行&quot;，一般就是指空白行 echo hello world #输出hello world “关闭回显”是指运行批处理文件时，不显示文件里的每条命令，只显示运行结果。批处理开始和结束时，系统都会自动打开回显 2 errorlevel程序返回码echo %errorlevel% 每个命令运行结束，可以用这个命令行格式查看返回码用于判断刚才的命令是否执行成功默认值为0， 一般命令执行出错会设 errorlevel 为1 3 dir显示目录中的文件和子目录列表dir #显示当前目录中的文件和子目录 dir /a #显示当前目录中的文件和子目录，包括隐藏文件和系统文件 dir c: /a:d #显示 C 盘当前目录中的目录 dir c:\ /a:-d #显示 C 盘根目录中的文件 dir d:\mp3 /b/p #逐屏显示 d:\mp3 目录里的文件，只显示文件名，不显示时间和大小 dir *.exe /s #显示当前目录和子目录里所有的.exe文件。 其中 是通配符，代表所有的文件名，还有一个通配符 ? 代表一个任意字母或汉字。如 `c.*代表以 c 开头的所有文件。?.exe` 代表所有文件名是一个字母的.exe文件。 如果指定的目录或文件不存在，将返回 errorlevel 为1;每个文件夹的 dir 输出都会有2个子目录.和..。. 代表当前目录， .. 代表当前目录的上级目录。 dir . #显示当前目录中的文件和子目录 dir .. #显示当前目录的上级目录中的文件和子目录 其它参数可参考dir /? 4 cd更改当前目录cd mp3 #进入当前目录中的mp3 目录 cd .. #进入当前目录中的上级目录 cd\ #进入根目录 cd #显示当前目录 cd /d d:\mp3 #可以同时更改盘符和目录 cd &quot;Documents and Settings&quot;\All users 文件名带空格，路径前需要加上引号！！如果更改到的目录不存在，则出错返回 errorlevel=1 cd /d d: 更改盘符需要加上/d参数。 5 md创建目录md abc #在当前目录里建立子目录 abc md d:\a\b\c #如果 d:\a 不存在，将会自动创建 6 rd删除目录rd abc #删除当前目录里的 abc 子目录，要求为空目录 rd /s/q d:\temp #删除 d:\temp 文件夹及其子文件夹和文件，不需要按 Y 确认 7 del删除文件del d:\test.txt #删除指定文件，不能是隐藏、系统、只读文件 del *.*删除当前目录里的所有文件，不包括隐藏、系统、只读文件，要求按 Y 确认 del /q/a/f d:\temp\*.*删除 d:\temp 文件夹里面的所有文件，包括隐藏、只读、系统文件，不包括子目录 del /q/a/f/s d:\temp\*.*删除 d:\temp 及子文件夹里面的所有文件，包括隐藏、只读、系统文件，不包括子目录 8 ren文件重命名ren 1.txt 2.bak #把 1.txt 更名为 2.bak ren *.txt *.ini #把当前目录里所有.txt文件改成.ini文件 ren d:\temp tmp #支持对文件夹的重命名 9 cls清屏10 type显示文件内容type c:\boot.ini #显示指定文件的内容，程序文件一般会显示乱码 type *.txt #显示当前目录里所有.txt文件的内容 11 copy拷贝文件copy c:\test.txt d:\ #复制 c:\test.txt 文件到 d:\ copy c:\test.txt d:\test.bak #复制 c:\test.txt 文件到 d:\ ，并重命名为 test.bak copy c:\*.* #复制 c:\ 所有文件到当前目录，不包括隐藏文件和系统文件不指定目标路径，则默认目标路径为当前目录 copy con test.txt #从屏幕上等待输入，按 Ctrl+Z 结束输入，输入内容存为test.txt文件con代表屏幕，prn代表打印机，nul代表空设备 copy 1.txt + 2.txt 3.txt #合并 1.txt 和 2.txt 的内容，保存为 3.txt 文件如果不指定 3.txt ，则保存到 1.txt copy test.txt + #复制文件到自己，实际上是修改了文件日期 12 title设置cmd窗口的标题title 新标题 #可以看到cmd窗口的标题栏变了 13 ver显示系统版本14 label 和 vol设置卷标vol #显示卷标 label #显示卷标，同时提示输入新卷标 label c:system #设置C盘的卷标为 system 15 pause暂停命令运行该命令时，将显示下面的消息：请按任意键继续 . . .一般用于看清楚屏幕上显示的内容 16 rem 和 ::注释命令注释行，不执行操作 17 date 和 time日期和时间date #显示当前日期，并提示输入新日期，按&quot;回车&quot;略过输入 date/t #只显示当前日期，不提示输入新日期 time #显示当前时间，并提示输入新时间，按&quot;回车&quot;略过输入 time/t #只显示当前时间，不提示输入新时间 18 goto 和 :跳转命令:label #行首为:表示该行是标签行，标签行不执行操作 goto label #跳转到指定的标签那一行 19 find (外部命令)查找命令find &quot;abc&quot; c:\test.txt在 c:\test.txt 文件里查找含 abc 字符串的行如果找不到，将设 errorlevel 返回码为1 find /i &quot;abc&quot; c:\test.txt查找含 abc 的行，忽略大小写 find /c &quot;abc&quot; c:\test.txt显示含 abc 的行的行数 20 more (外部命令)逐屏显示more c:\test.txt #逐屏显示 c:\test.txt 的文件内容 21 tree显示目录结构tree d:\ #显示D盘的文件目录结构 22 &amp;顺序执行多条命令，而不管命令是否执行成功c: &amp; cd\ &amp; dir /w #相当于把下面3行命令写到1行去了c:cd\dir /w 23 &amp;&amp;顺序执行多条命令，当碰到执行出错的命令后将不执行后面的命令f: &amp;&amp; cd\ &amp;&amp; dir &gt;c:\test.txt #注意如果f盘不存在，那么后面2条命令将不会执行 find &quot;ok&quot; c:\test.txt &amp;&amp; echo 成功 #如果找到了&quot;ok&quot;字样，就显示&quot;成功&quot;，找不到就不显示 24 ||顺序执行多条命令，当碰到执行正确的命令后将不执行后面的命令find &quot;ok&quot; c:\test.txt || echo 不成功 #如果找不到&quot;ok&quot;字样，就显示&quot;不成功&quot;，找到了就不显示 25 |管道命令前一个命令的执行结果输出到后一个命令 dir *.* /s/a | find /c &quot;.exe&quot; 管道命令表示先执行 dir 命令，对其输出的结果执行后面的 find 命令该命令行结果：输出当前文件夹及所有子文件夹里的.exe文件的个数 type c:\test.txt|more 这个和 more c:\test.txt 的效果是一样的 26 &gt; 和 &gt;&gt;输出重定向命令&gt; 清除文件中原有的内容后再写入 &gt;&gt; 追加内容到文件末尾，而不会清除原有的内容主要将本来显示在屏幕上的内容输出到指定文件中指定文件如果不存在，则自动生成该文件 echo hello world&gt;c:\test.txt生成c:\test.txt文件，内容为hello world这个格式在批处理文件里用得很多，可以成 .reg .bat .vbs 等临时文件 type c:\test.txt &gt;prn屏幕上不显示文件内容，转向输出到打印机 echo hello world&gt;con在屏幕上显示hello world，实际上所有输出都是默认 &gt;con 的 copy c:\test.txt f: &gt;nul拷贝文件，并且不显示&quot;文件复制成功&quot;的提示信息，但如果f盘不存在，还是会显示出错信息 copy c:\test.txt f: &gt;nul 2&gt;nul不显示&quot;文件复制成功&quot;的提示信息，并且f盘不存在的话，也不显示错误提示信息 echo ^^W ^&gt; ^W&gt;c:\test.txt生成的文件内容为 ^W &gt; W^ 和 &gt; 是控制命令，要把它们输出到文件，必须在前面加个 ^ 符号 27 &lt;从文件中获得输入信息，而不是从屏幕上一般用于 date time label 等需要等待输入的命令 @echo offecho 2005-05-01&gt;temp.txtdate &lt;temp.txtdel temp.txt这样就可以不等待输入直接修改当前日期 28 命令行传递给批处理参数%0 %1 %2 %3 %4 %5 %6 %7 %8 %9 %命令行传递给批处理的参数%0 批处理文件本身%1 第一个参数%9 第九个参数% 从第一个参数开始的所有参数在C盘根目录新建test.bat，内容如下： @echo off echo %0 echo %1 echo %2 echo %* 运行cmd，输入 c:\test.bat &quot;/a&quot; /b /c /d可以看出每个参数的含意 修改test.bat内容如下 @echo off echo %1 echo %~1 echo %0 echo %~f0 echo %~d0 echo %~p0 echo %~n0 echo %~x0 echo %~s0 echo %~a0 echo %~t0 echo %~z0 再运行cmd，输入 c:\test.bat “/a” /b /c /d可以参照 call/? 或 for/? 看出每个参数的含意。注意这里可以对文件进行日期比较和大小比较 echo load &quot;%%1&quot; &quot;%%2&quot;&gt;c:\test.txt 生成的文件内容为 load “%1” “%2”批处理文件里，用这个格式把命令行参数输出到文件 31 set设置变量引用变量可在变量名前后加 % ，即 %变量名% set #显示目前所有可用的变量，包括系统变量和自定义的变量 echo %SystemDrive% #显示系统盘盘符。系统变量可以直接引用 set p #显示所有以p开头的变量，要是一个也没有就设errorlevel=1 set p=aa1bb1aa2bb2 #设置变量p，并赋值为 = 后面的字符串，即aa1bb1aa2bb2 echo %p% #显示变量p代表的字符串，即aa1bb1aa2bb2 echo %p:~6% #显示变量p中第6个字符以后的所有字符，即aa2bb2 echo %p:~6,3% #显示第6个字符以后的3个字符，即aa2 echo %p:~0,3% #显示前3个字符，即aa1 echo %p:~-2% #显示最后面的2个字符，即b2 echo %p:~0,-2% #显示除了最后2个字符以外的其它字符，即aa1bb1aa2b echo %p:aa=c% #用c替换变量p中所有的aa，即显示c1bb1c2bb2 echo %p:aa=% #将变量p中的所有aa字符串置换为空，即显示1bb12bb2 echo %p:*bb=c% #第一个bb及其之前的所有字符被替换为c，即显示c1aa2bb2 set p=%p:*bb=c% #设置变量p，赋值为 %p:*bb=c% ，即c1aa2bb2 set /a p=39 #设置p为数值型变量，值为39 set /a p=39/10 #支持运算符，有小数时用去尾法，39/10=3.9，去尾得3，p=3 set /a p=p/10 #用 /a 参数时，在 = 后面的变量可以不加%直接引用 set /a p=&quot;1&amp;0&quot; #&quot;与&quot;运算，要加引号。其它支持的运算符参见set/? set p= #取消p变量 set /p p=请输入 #屏幕上显示&quot;请输入&quot;，并会将输入的字符串赋值给变量p注意这条可以用来取代 choice 命令 注意变量在 if 和 for 的复合语句里是一次性全部替换的，如 @echo off set p=aaa if %p%==aaa ( echo %p% set p=bbb echo %p% ) 结果将显示aaaaaa因为在读取 if 语句时已经将所有 %p% 替换为aaa这里的”替换”，在 /? 帮助里就是指”扩充”、”环境 变量扩充”可以启用”延缓环境变量扩充”，用 ! 来引用变量，即 !变量名! @echo off SETLOCAL ENABLEDELAYEDEXPANSION set p=aaaif %p%==aaa ( echo %p% set p=bbb echo !p! ) ENDLOCAL 结果将显示aaabbb还有几个动态变量，运行 set 看不到 %CD% #代表当前目录的字符串 %DATE% #当前日期 %TIME% #当前时间 %RANDOM% #随机整数，介于0~32767 %ERRORLEVEL% #当前ERRORLEVEL 值 %CMDEXTVERSION% #当前命令处理器扩展名版本号 %CMDCMDLINE% #调用命令处理器的原始命令行可以用echo命令查看每个变量值，如 echo %time%注意 %time% 精确到毫秒，在批处理需要延时处理时可以用到 32 start调用外部程序批处理中调用外部程序的命令，否则等外部程序完成后才继续执行剩下的指令 start explorer d:\调用图形界面打开D盘 @echo off cd /d %~dp0regedit /s 劲舞团.regstart patcher.exe 不加 start 命令的话，”劲舞团”运行时，后面会有个黑乎乎的cmd窗口 33 call调用另外一个批处理批处理中调用另外一个批处理的命令，否则剩下的批处理指令将不会被执行有时有的应用程序用start调用出错的，也可以call调用 34 choice (外部命令)选择命令让用户输入一个字符，从而选择运行不同的命令，返回码errorlevel为1234……win98里 是choice.com win2000pro里没有，可以从win98里拷过来win2003里是choice.exechoice /N /C y /T 5 /D y&gt;nul延时5秒 下面是个 choice 语句的例子 @echo off rem 以下在win2000pro运行通过，从win98里拷的chioce.com文件 choice /c:abc aaa,bbb,ccc if errorlevel 3 goto ccc if %errorlevel%==2 goto bbb if errorlevel==1 goto aaarem 必须先判断数值高的返回码rem 可以看到 errorlevel 值的判断有3种写法，有时某种写法不好用，可以用另外的写法rem 直接运行 chioce相当于运行 choice /c:yn:aaa echo aaa goto end :bbb echo bbb goto end :ccc echo ccc goto end :end 35 assoc 和 ftype文件关联assoc 设置’文件扩展名’关联，关联到’文件类型’ftype 设置’文件类型’关联，关联到’执行程序和参数’ 当你双击一个.txt文件时，windows并不是根据.txt直接判断用 notepad.exe 打开而是先判断.txt属于 txtfile ‘文件类型’再调用 txtfile 关联的命令行 txtfile=%SystemRoot%\system32\NOTEPAD.EXE %1 可以在”文件夹选项”→”文件类型”里修改这2种关联 assoc #显示所有&apos;文件扩展名&apos;关联 assoc .txt #显示.txt代表的&apos;文件类型&apos;，结果显示 .txt=txtfile assoc .doc #显示.doc代表的&apos;文件类型&apos;，结果显示 .doc=Word.Document.8 assoc .exe #显示.exe代表的&apos;文件类型&apos;，结果显示 .exe=exefile ftype #显示所有&apos;文件类型&apos;关联 ftype exefile #显示exefile类型关联的命令行，结果显示 exefile=&quot;%1&quot; %* assoc .txt=Word.Document.8设置.txt为word类型的文档，可以看到.txt文件的图标都变了 assoc .txt=txtfile恢复.txt的正确关联 ftype exefile=&quot;%1&quot; %*恢复 exefile 的正确关联 如果该关联已经被破坏，可以运行 command.com ，再输入这条命令 36 pushd 和 popd切换当前目录@echo off c: &amp; cd\ &amp; md mp3 #在 C:\ 建立 mp3 文件夹 md d:\mp4 #在 D:\ 建立 mp4 文件夹 cd /d d:\mp4 #更改当前目录为 d:\mp4 pushd c:\mp3 #保存当前目录，并切换当前目录为 c:\mp3 popd #恢复当前目录为刚才保存的 d:\mp4一般用处不大，在当前目录名不确定时，会有点帮助 37 subst (外部命令)映射磁盘。subst z: \\server\d #这样输入z:就可以访问\\server\d了 subst z: /d #取消该映射 subst #显示目前所有的映射 38 xcopy (外部命令)文件拷贝xcopy d:\mp3 e:\mp3 /s/e/i/y #复制 d:\mp3 文件夹、所有子文件夹和文件到 e:\ ，覆盖已有文件。加 /i 表示如果 e:\ 没有 mp3 文件夹就自动新建一个，否则会有询问 39 一些不常用的内部命令&gt;&amp; 将一个句柄的输出写入到另一个句柄的输入中 &lt;&amp; 从一个句柄读取输入并将其写入到另一个句柄输出中shift 命令行传递给批处理的参数不止9个时，用以切换参数color 设置cmd窗口的显示颜色 pormpt 更改命令提示符号，默认都是 盘符:\路径\&gt; ，如 c:\&gt; 40 format (外部命令)格式化硬盘format c: /q/u/autotest/q表示快速格式化，/autotest表示自动格式化，不需要按 Y 确认/u表示每字节用 F6 覆盖硬盘数据，使其不可用软件恢复format c: /c格式化C盘，并检测坏道 41 fdisk (外部命令)硬盘分区win2000不带该命令win98里的fdisk不支持80G以上大硬盘，winme里的支持fdisk/mbr重建硬盘分区表，一般用于清除引导区病毒、还原精灵注意使用该命令不能从硬盘启动，必须软驱或光驱启动后直接运行 42 ping (外部命令)ping -l 65500 -t 192.168.1.200不停的向192.168.1.200计算机发送大小为65500byte的数据包 ping -n 10 127.0.0.1&gt;nulping自己10次，可用于批处理延时10秒 43 SC (外部命令)服务控制命令sc create aaa displayname= bbb start= auto binpath= &quot;C:\WINDOWS\System32\alg.exe&quot;创建服务，服务名称aaa，显示名称bbb，启动类型:自动可执行文件的路径&quot;C:\WINDOWS\System32\alg.exe&quot; sc description aaa &quot;ccc&quot;更改aaa的描述为ccc sc config aaa start= disabled binpath= &quot;C:\WINDOWS\System32\svchost.exe -k netsvcs&quot;更改aaa的启动类型:已禁用更改aaa的可执行文件的路径&quot;C:\WINDOWS\System32\svchost.exe -k netsvcs&quot; sc config aaa start= demand displayname= ddd更改aaa的启动类型:手动更改aaa的显示名称ddd sc start aaa启动aaa服务 sc stop aaa停止aaa服务 sc delete aaa删除aaa服务 参考资料 http://bbs.bathome.net/thread-39-1-1.html http://www.cnblogs.com/DswCnblog/p/5436245.html]]></content>
      <categories>
        <category>批处理</category>
      </categories>
      <tags>
        <tag>批处理</tag>
        <tag>bat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[纪录片《轮回》观后记录]]></title>
    <url>%2F2017%2F09%2F25%2Fsamsara_documentary%2F</url>
    <content type="text"><![CDATA[多图预警，流量慎点。GIF较大，可能加载会比较慢。 001300 - 001640 延时摄影，日月星辰，风景变换。 001804 海啸后两幢平房中间翻斜挤压变形的汽车。 00:21:06 巴西圣保罗的教堂中，儿童们在接受洗礼。 与此对比的是，00:25:15处一个夭折的小男孩躺在棺材里。 00:34:50车灯比较有意思。车道右侧是向上前进的车，尾灯是红色的，前灯有白色的，还有蓝青色的。 追踪汽车尾灯的效果实在是太赞了。 00:39:49法国行为艺术家Olivier de Sagazan震撼人心的表演。此人以往自己脸上身上涂粘土和颜料著称，展现人类内在的兽性。 当这个诡异的类似伏地魔的表演结束之后，用一个机器人表现出震惊的样子，实在是笑死。 前面的表演的确震惊，表面斯文的人，作出如此疯狂的动作。 00:41:00 人跌倒时候的配乐是亮点，第一次看的时候忍不住笑了，这么正经的片子，居然还有这种效果，哈哈。 00:41:11 迪拜的一系列人工奇迹：号称世界上唯一的七星级酒店——阿联酋迪拜的阿拉伯塔酒店（Burj Al Arab）。（阿拉伯塔酒店因外形酷似船帆，又称迪拜帆船酒店） 第一张图的右侧是其外观，左侧为清真寺。 大型的填海工程令人叹为观止。 迪拜的一系列人工奇迹: 迪拜购物中心，全球第一大购物中心。 室内瀑布也是迪拜购物中心的标志景观，位于中庭处，24米高的瀑布至今还保持着一个世界纪录，即世界上第一高的室内喷泉。瀑布中还设置了一排排跳水运动员塑像，动作整齐划一，栩栩如生。 迪拜的一系列人工奇迹: 世界第一高楼——哈里发塔（Burj Khalifa），也可译为哈利法塔。 这座全球第一高塔位于Downtown，与迪拜音乐喷泉（The Dubai Fountain）、迪拜购物中心（The Dubai Mall）相距不远。 00:44:35两名时尚女郎走在意大利米兰的埃马努埃莱二世拱廊（Galleria Vittorio Emanuele II）中。拱廊一端的斯卡拉大剧院（La Scala）。 左边这妹子的裤子看来需要我帮她提一下哈哈哈。 ……中间省略一些，主要是繁忙的交通、生产（销毁）流水线、超市疯狂采购以及疯狂吃的人越来越胖具体内容如下： 日本东京繁忙的地铁。一些另类的奇装异服者。 厦门灿坤集团在福建漳州的小家电工厂城。工人们在流水线上如机器人般的劳作。马上跟着回收站中各种电器被压扁、绞碎、封存、筛选。同样是流水作业，一个制造，一个销毁。郑州三全食品股份有限公司的速冻食品生产基地。一个个饺子就这样高效的产出。 在高度机械化的丹麦，一台神奇的机器把一只只活鸡收入囊中。在中国长春，身着粉红色防护服的工人们在把整鸡大卸八块。在美国加州，奶牛们头朝内尾朝外肩并肩的被放在大转盘上转啊转的被挤奶。 超市里，人们在疯狂购物。餐厅里，三个胖子在饕餮着垃圾食品。 最后，讽刺地是，吃胖了的人也得像鸡、猪一样，被画线切开、动手术。 同样需要画线的还有充气娃娃。。。 00:57:30 日本生产充气娃娃的工厂。后面的就不截了。 00:58:35 泰国人妖俱乐部里，人妖们身着比基尼搔首弄姿的跳着钢管舞。 01:00:20 伏见稻荷大社，日本京都市伏见区的稻荷神社（Fushimi Inari-taisha）。竖立的鸟居（Torii）排列成一条长长的甬道，即闻名于世的千本鸟居。 稻荷神是农业与商业的神明，香客前来祭拜求取农作丰收、生意兴隆、交通安全。它是京都地区香火最盛的神社之一。（摘自百科） 01:01:31 上海黄浦江畔高楼林立。 01:03:50 菲律宾宿务市（Cebu City）的一个监狱~ 比起让犯人做什么手工活，大概每个月都教他们一个新的舞蹈，还要在家属面前表演… 男人们卖力的跳着，女人们轻柔的和着，典狱长漠然的看着。 01:06:59 这种房子的结构不错。 一边住人，一边养花草。很赞，第一次见到。 01:10:00 印尼的（卡瓦）伊真（Ijen）（活）火山上，赤膊的工人们在极具腐蚀性的硫酸雾气中把成筐的硫磺矿挑走。 01:17:40 中国国庆大阅兵。 01:18:16 少林寺塔沟武校。 小时候，看了少年包青天之类的电视剧，就好想去武校学习的啊，可惜。 01:19:31 韩国的条子。不要问我怎么知道的（看字）。 01:20:00 柏林墙是是这种大块的条状建筑组成，上面有很多涂鸦。 耶路撒冷哭墙（Western/Wailing Wall）。哭墙是由砖块石头组成。 之前两个没有区分开，所以特此说明一下。 01:33:00千手观音是最美的。 由21位聋哑人表演的千手观音舞蹈。领舞是自幼失聪的邰丽华。 首尾呼应。此处有表演，开头的时候没有。 01:25:29影片接近尾声，镜头来到沙特麦加，记录下几百万汇聚在清真寺周围的虔诚信徒，如沙，如画。 沙特麦加的禁寺（Masjid al-Haram）朝拜。镜头越来越高，那如沙砾般的白点点啊，围着克尔白（Kaaba）不停的转啊转。 (让我想起了刚做的数模中动目标检测的那个素材。。17年全国研究生数模D题) 01:30:47转眼间，镜头又回到了华美绚烂而又精密有序的坛城沙画。 然而，讶异的观众们此时看见，这个刚刚用沙子堆砌起来的世界，历经了积年累月呕心沥的创作，却在完成之后被毫不犹豫地全盘抹去。 一件拥有无上艺术价值的作品，顷刻之间，便化为乌有。 对于修行者来说，他们和它们的使命都已完成。于是那些色泽明艳的细沙将被装入瓶中，倾倒入河，顺流而去。 繁华世界，不过一掬细沙。 部分文字参考自豆瓣影评一沙一世界，无声引导沉思。]]></content>
      <categories>
        <category>观影指南</category>
      </categories>
      <tags>
        <tag>轮回</tag>
        <tag>纪录片</tag>
        <tag>samsara</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DeepLearnToolBox之BP算法]]></title>
    <url>%2F2017%2F09%2F23%2FDeepLearnToolBox_BP%2F</url>
    <content type="text"><![CDATA[工具箱下载下载地址：https://github.com/rasmusbergpalm/DeepLearnToolbox 总体测试代码\tests\test_example_NN.m nn = nnsetup([784 100 10]); opts.numepochs = 1; // Number of full sweeps through data opts.batchsize = 100; // Take a mean gradient step over this many samples [nn, L] = nntrain(nn, train_x, train_y, opts); [er, bad] = nntest(nn, test_x, test_y); 很简单的几步就训练了一个NN，我们发现其中最重要的几个函数就是nnsetup,nntrain和nntest了。 nnsetupNNSETUP创建前向反馈神经网络。 代码解释详细代码如下： function nn = nnsetup(architecture) %NNSETUP creates a Feedforward Backpropagate Neural Network % nn = nnsetup(architecture) returns an neural network structure with n=numel(architecture) % layers, architecture being a n x 1 vector of layer sizes e.g. [784 100 10] nn.size = architecture; nn.n = numel(nn.size); nn.activation_function = &apos;tanh_opt&apos;; % Activation functions of hidden layers: &apos;sigm&apos; (sigmoid) or &apos;tanh_opt&apos; (optimal tanh). nn.learningRate = 1; % learning rate Note: typically needs to be lower when using &apos;sigm&apos; activation function and non-normalized inputs. nn.momentum = 0.5; % Momentum 权值动量因子 nn.scaling_learningRate = 1; % Scaling factor for the learning rate (each epoch) 学习率变化因子 (each epoch) nn.weightPenaltyL2 = 0; % L2 regularization nn.nonSparsityPenalty = 0; % Non sparsity penalty 非稀疏惩罚 nn.sparsityTarget = 0.05; % Sparsity target 稀疏目标值 nn.inputZeroMaskedFraction = 0; % Used for Denoising AutoEncoders 自动编码的去噪作用 nn.dropoutFraction = 0; % Dropout level (http://www.cs.toronto.edu/~hinton/absps/dropout.pdf) nn.testing = 0; % Internal variable. nntest sets this to one. 一个标志参数--在nntest.m这个函数中会用到 nn.output = &apos;softmax&apos;; % output unit &apos;sigm&apos; (=logistic), &apos;softmax&apos; and &apos;linear&apos; for i = 2 : nn.n % weights and weight momentum nn.W{i - 1} = (rand(nn.size(i), nn.size(i - 1)+1) - 0.5) * 2 * 4 * sqrt(6 / (nn.size(i) + nn.size(i - 1))); nn.vW{i - 1} = zeros(size(nn.W{i - 1})); % average activations (for use with sparsity) nn.p{i} = zeros(1, nn.size(i)); end end nnsetup初始化网络结构以及一系列参数。对照着代码，看一下具体含义。 nn = nnsetup(architecture)返回一个神经网络结构，architecture为结构参数。architecture是一个n x 1 向量，表示每一层神经元的个数。 比如architecture=[784 100 10]，表示输入层为784维输入，100个隐含层，10个输出层 为什么是输入为784：因为每一个手写体大小为28*28的，也就是784维度 隐含层为什么是100：随便设置的，可以随意修改，需要设计 输出为什么是10：手写体有0-9这10种结果，所以为10 //对每一层的网络结构进行初始化，一共三个参数W,vW，p，其中W是主要的参数//vW是更新参数时的临时参数，p是所谓的sparsity，(等看到代码了再细讲) ##使用实例 nn=nnsetup([size(feature,2) 200 200 length(azimuth)]); nntrain截取出的主要框架为： for i = 1 : numepochs for l = 1 : numbatches nn = nnff(nn, batch_x, batch_y); nn = nnbp(nn); nn = nnapplygrads(nn); L(n) = nn.L; n = n + 1; end end 第一层for循环为迭代次数。第二次为遍历所有的batch。其中，先计算前向传播（ff），在计算反向传播（bp），接着更新参数（nnapplygrads），最后计算损失函数（代价函数）L。 下面分析三个函数nnff,nnbp和nnapplygrads。 nnffnnff就是进行feedforward pass，其实非常简单，就是整个网络正向跑一次就可以了 当然其中有dropout和sparsity的计算,具体的参见论文“Improving Neural Networks with Dropout“和Autoencoders and Sparsity 提取出主要框架为： for i = 2 : n-1 （遍历隐含层） //根据激活函数计算隐层输出 //隐层的dropout计算，舍弃部分输出 //计算sparsity，nonSparsityPenalty 是对没达到sparsitytarget的参数的惩罚系数 //Add the bias term end //根据输出层的结构计算输出层的输出。 //计算误差以及损失函数 nnbp代码：\NN\nnbp.mnnbp呢是进行back propagation的过程。值得注意的还是dropout和sparsity的部分。 提取出主要框架为： ①计算输出层的输出 ②依次反向计算隐层输出 for i = (n - 1) : -1 : 2 （反向遍历隐层） d_act为隐层 激活函数的导数 d{i}为隐层输出函数的导数。 计算中用到非稀疏惩罚项，以及dropout end ③计算权值的导数nn.dW{i} dW{i}基本就是计算的gradient(梯度)了，只是后面还要加入一些东西，进行一些修改。 nnapplygrads代码文件：\NN\nnapplygrads.m for i = 1 : (nn.n - 1) //应用weightPenaltyL2，learningRate ，momentum修正dW nn.W{i} = nn.W{i} - dW; //权值W更新 end 这个内容就简单了，nn.weightPenaltyL2是weight decay的部分，也是nnsetup时可以设置的一个参数 有的话就加入weight Penalty，防止过拟合，然后再根据momentum的大小调整一下，最后改变nn.W{i}即可 nntestfunction [er, bad] = nntest(nn, x, y) labels = nnpredict(nn, x); [~, expected] = max(y,[],2); bad = find(labels ~= expected); er = numel(bad) / size(x, 1); end nntest再简单不过了，就是调用一下nnpredict，在和test的集合进行比较 nnpredict代码文件：\NN\nnpredict.m function labels = nnpredict(nn, x) nn.testing = 1; nn = nnff(nn, x, zeros(size(x,1), nn.size(end))); nn.testing = 0; [~, i] = max(nn.a{end},[],2); labels = i; end 继续非常简单，predict不过是nnff一次，得到最后的output~~ max(nn.a{end},[],2); 是返回每一行的最大值以及所在的列数，所以labels返回的就是标号啦(这个test好像是专门用来test分类问题的，我们知道nnff得到最后的值即可) 总结这篇文章只要是基于代码的简单分析，基于公式推导的文章请参阅：BP神经网络部分具体的推导。 参考资料 http://blog.sina.com.cn/s/blog_4a1853330102vupc.html]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017“华为杯”第十四届中国研究生数学建模竞赛回顾]]></title>
    <url>%2F2017%2F09%2F22%2Freview_of_MathModel%2F</url>
    <content type="text"><![CDATA[试题下载地址中国研究生数模竞赛官网：http://gmcm.seu.edu.cn/01/49/c12a329/page.htm 我们组选择了D题。 D题题目基于监控视频的前景目标提取视频监控是中国安防产业中最为重要的信息获取手段。随着“平安城市”建设的顺利开展，各地普遍安装监控摄像头，利用大范围监控视频的信息，应对安防等领域存在的问题。近年来，中国各省市县乡的摄像头数目呈现井喷式增长，大量企业、部门甚至实现了监控视频的全方位覆盖。如北京、上海、杭州监控摄像头分布密度约分别为71、158、130个/平方公里，摄像头数量分别达到115万、100万、40万，为我们提供了丰富、海量的监控视频信息。 目前，监控视频信息的自动处理与预测在信息科学、计算机视觉、机器学习、模式识别等多个领域中受到极大的关注。而如何有效、快速抽取出监控视频中的前景目标信息，是其中非常重要而基础的问题[1-6]。这一问题的难度在于，需要有效分离出移动前景目标的视频往往具有复杂、多变、动态的背景[7，8]。这一技术往往能够对一般的视频处理任务提供有效的辅助。以筛选与跟踪夜晚时罪犯这一应用为例：若能够预先提取视频前景目标，判断出哪些视频并未包含移动前景目标，并事先从公安人员的辨识范围中排除；而对于剩下包含了移动目标的视频，只需辨识排除了背景干扰的纯粹前景，对比度显著，肉眼更易辨识。因此，这一技术已被广泛应用于视频目标追踪，城市交通检测，长时场景监测，视频动作捕捉，视频压缩等应用中。 下面简单介绍一下视频的存储格式与基本操作方法。一个视频由很多帧的图片构成，当逐帧播放这些图片时，类似放电影形成连续动态的视频效果。从数学表达上来看，存储于计算机中的视频，可理解为一个3维数据，其中代表视频帧的长，宽，代表视频帧的帧数。视频也可等价理解为逐帧图片的集合，即，其中为一张长宽分别为的图片。3维矩阵的每个元素（代表各帧灰度图上每个像素的明暗程度）为0到255之间的某一个值，越接近0，像素越黑暗；越接近255，像素越明亮。通常对灰度值预先进行归一化处理（即将矩阵所有元素除以255），可将其近似认为[0,1]区间的某一实数取值，从而方便数据处理。一张彩色图片由R（红），G（绿），B（蓝）三个通道信息构成，每个通道均为同样长宽的一张灰度图。由彩色图片构成的视频即为彩色视频。本问题中，可仅考虑黑白图片构成的视频。在Matlab环境下，视频的读取、播放及相应基本操作程序见附件1。如采用其他编程环境，也可查阅相关资料获得相应操作程序。 题目的监控视频主要由固定位置监控摄像头拍摄，要解决的问题为提取视频前景目标。请研究生通过设计有效的模型与方法，自动从视频中分离前景目标。注意此类视频的特点是相对于前景目标，背景结构较稳定，变化幅度较小，可充分利用该信息实现模型与算法设计。 请你们查阅相关资料和数据，结合视频数据特点，回答下列问题： 问题1对一个不包含动态背景、摄像头稳定拍摄时间大约5秒的监控视频，构造提取前景目标（如人、车、动物等）的数学模型，并对该模型设计有效的求解方法，从而实现类似图1的应用效果。（附件2提供了一些符合此类特征的监控视频） 问题2对包含动态背景信息的监控视频（如图2所示），设计有效的前景目标提取方案。（附件2中提供了一些符合此类特征的典型监控视频） 问题3在监控视频中，当监控摄像头发生晃动或偏移时，视频也会发生短暂的抖动现象（该类视频变换在短时间内可近似视为一种线性仿射变换，如旋转、平移、尺度变化等）。对这种类型的视频，如何有效地提取前景目标？（附件2中提供了一些符合此类特征的典型监控视频，其它一些典型视频可从 http://wordpress-jodoin.dmi.usherb.ca/dataset2014/ 下载） 问题4在附件3中提供了8组视频（avi文件与mat文件内容相同）。请利用你们所构造的建模方法，从每组视频中选出包含显著前景目标的视频帧标号，并将其在建模论文正文中独立成段表示。务须注明前景目标是出现于哪一个视频（如Campus视频）的哪些帧（如241-250，421-432帧）。 问题5如何通过从不同角度同时拍摄的近似同一地点的多个监控视频中（如图3所示）有效检测和提取视频前景目标？请充分考虑并利用多个角度视频的前景之间（或背景之间）相关性信息（一些典型视频可从http://cvlab.epfl.ch/research/surv/multi-people-tracking 下载） 问题6利用所获取前景目标信息，能否自动判断监控视频中有无人群短时聚集、人群惊慌逃散、群体规律性变化（如跳舞、列队排练等）、物体爆炸、建筑物倒塌等异常事件？可考虑的特征信息包括前景目标奔跑的线性变化形态特征、前景规律性变化的周期性特征等。尝试对更多的异常事件类型，设计相应的事件检测方案。（请从网络下载包含各种事件的监控视频进行算法验证） 注：强烈建议深刻考虑问题内涵，建造合理、高效的数学模型和求解方法，鼓励进行具有开放思路与创新思维的探索性尝试。 参考文献[1] Andrews Sobral &amp; Antoine Vacavant, A comprehensive review of background subtraction algorithms evaluated with synthetic and real videos, Computer Vision and Image Understanding, Volume 122, May 2014, Pages 4-21 [2] B. Lee and M. Hedley, “Background estimation for video surveillance,” IVCNZ02, pp. 315–320, 2002. [3] C. Stauffer and W. E. L. Grimson, “Adaptive background mixture models for real-time tracking,” in Computer Vision and Pattern Recognition, 1999. IEEE Computer Society Conference on., vol. 2. IEEE, 1999. [4] E. J. Cand`es, X. Li, Y. Ma, and J. Wright, “Robust principal component analysis?” Journal of the ACM (JACM), vol. 58, no. 3, p. 11, 2011. [5] D. Meng and F. De la Torre, “Robust matrix factorization with unknown noise,” in IEEE International Conference on Computer Vision, 2013, pp. 1337–1344. [6] Q. Zhao, D. Meng, Z. Xu,W. Zuo, and L. Zhang, “Robust principal component analysis with complex noise,” in Proceedings of the 31st International Conference on Machine Learning (ICML-14), 2014, pp. 55–63. [7] Y. Peng, A. Ganesh, J. Wright, W. Xu, and Y. Ma, “RASL: Robust alignment by sparse and low-rank decomposition for linearly correlated images,” Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 34, no. 11, pp. 2233–2246, 2012. [8] M. Babaee, D. T. Dinh, and G. Rigoll, “A deep convolutional neural network for background subtraction,” arXiv preprint arXiv: 1702.01731, 2017. 思路流程不阐述为什么这么做（因为我也不知道为什么），只记录下我所做的工作历程。 BGSLibrary编译安装与BGSlibrary GUI的下载与使用这部分详情可参考我的博客：https://qwerty200696.github.io/2017/09/20/BGSlibrary/ ViBe算法一种像素级视频背景建模或前景检测的算法。 详细地可参考ViBe算法官网主页：ViBe官网链接 该官网包含ViBe源码以及可在Windows和Linux中运行的程序。想了解该算法的童鞋可以详细探索该网站。 这篇CSDN博客介绍的也比较全面，可作参考。 光流法LK光流法分析及其源码请参考我的这篇文章：https://qwerty200696.github.io/2017/09/21/optical_flow/ 视频抗抖动算法参考链接：SIMPLE VIDEO STABILIZATION USING OPENCV 采用的方法是基于optical flow 光流法。 算法流程： &emsp;1 使用所有帧中的光流信息来查找从前一帧到当前帧的转换 &emsp;2 累积变换以获得每个帧的x，y，a 的轨迹 &emsp;3 使用滑动平均窗口对轨迹平滑处理 &emsp;4 创建一个新的变换，使得$F_{new}$ = $F_{old}$ + ( $T_{smoothed}$ - $T_{before}$ ) &emsp;5 将新的转换应用到视频中，得到去抖后的视频 其中 dx、dy 为x 和y 方向的流向，da 为抖动中旋转角度的变化量; $F_{new}$、$F_{old}$分别为新的变换与原先的变换，$T_{smoothed}$、$T_{before}$分别为平滑前后的轨迹。 Camera Jitter 相机抖动 数据集下载：http://wordpress-jodoin.dmi.usherb.ca/dataset2014/ opencv视频保存方法视频保存方法请参考这篇博文：https://qwerty200696.github.io/2017/09/21/opencv_SaveVideo/ opencv_contrib安装opencv_contrib的安装说明可以参考这篇博文https://qwerty200696.github.io/2017/09/21/opencv_contrib/ 杂七杂八动目标检测dataset 2014 里面的视频分类详细，很好的数据集。 目标跟踪Object Tracking using OpenCV (C++/Python) 这个算是做的比较好的了，很有参考价值。 D题问题五给出的网址：http://cvlab.epfl.ch/research/surv/multi-people-tracking 视频流跟踪目标OpenTLD Real-Time Tracking 多角度多目标跟踪Deep Occlusion Reasoning for Multi-Camera Multi-Target Detection DeepOcclusion 人群异常行为检测BEHAVE Interactions Test Case Scenarios Detection of Events UCF数据集：Crowd Segmentation Data Set 这是正常行为的，没找到不正常行为的。据说有的。 UMN数据集：Detection of Unusual Crowd Activity 总结至此，花了两天时间稍微记录了一下我自己做的工作吧，算是opencv小白入门记。（之后暂时应该不会研究了，毕竟不是学这个的） 最后附上一个收录计算机视觉题材的地址：百炼成金，计算机视觉修炼之道，想要从事相关研究的童鞋不容错过。]]></content>
  </entry>
  <entry>
    <title><![CDATA[opencv_contrib安装说明与错误解决方案]]></title>
    <url>%2F2017%2F09%2F21%2Fopencv_contrib%2F</url>
    <content type="text"><![CDATA[在数模的时候，需要实现目标跟踪，因此需要安装opencv附加库，即opencv_contrib。 没有安装该附加库的时候，会提示如下错误： opencv_contrib下载opencv_contrib的项目地址为：https://github.com/opencv/opencv_contrib 先将opencv_contrib下载下来，为后续安装做准备。 此外还需要的是opencv以及cmake。 opencv_contrib安装步骤概述windows控制台依次输入如下命令： $ cd &lt;opencv_build_directory&gt; $ cmake -DOPENCV_EXTRA_MODULES_PATH=&lt;opencv_contrib&gt;/modules &lt;opencv_source_directory&gt; $ make -j5 之后会在&lt;opencv_build_directory&gt;目录下生成opencv_contrib库的所有模块。如果不想安装所有的模块，则使用cmake命令的BUILD_opencv_*选项。示例程序如下： $ cmake -DOPENCV_EXTRA_MODULES_PATH=&lt;opencv_contrib&gt;/modules -DBUILD_opencv_legacy=OFF &lt;opencv_source_directory&gt; GUI图形界面安装 打开cmake-gui； 选择源码文件夹以及build文件夹； 点击configue按钮。可以看到opencv build时的一系列参数； 浏览参数并找到OPENCV_EXTRA_MODULES_PATH，将其路径设为&lt;opencv_contrib&gt;/modules； 点击configue按钮，完成后再点击generate按钮。（第一次会询问Makefile的类型） 点击open project，使用你选择的方法来生成opencv core。(上一步是Unix makfile，则相应的make，make install) 在自己的代码/IDE中添加相应模块的连接器标志（linker flags）。比如想使用aruco模块，则需要加上&quot;-lopencv_aruco&quot;。 上述步骤为该项目英文安装指南对应的翻译。 图形界面的安装可参考这篇文章：http://blog.csdn.net/cv_jason/article/details/70037545 opencv_contrib安装错误解决方案cmake出错Failed to downloadCmd下输入 wang@wang-PC MINGW64 /d/Program Files/opencv3/build $ cmake -DOPENCV_EXTRA_MODULES_PATH=&quot;D:\opencv_contrib-master\modules&quot; &quot;D:\Program Files\opencv3\sources&quot; 时出现下载错误，如下图所示： CMake Error at D:/Program Files/opencv3/sources/cmake/OpenCVUtils.cmake:1047 (message): Failed to download . Status= Call Stack (most recent call first): D:/opencv_contrib-master/modules/dnn_modern/CMakeLists.txt:18 (ocv_download) 即：无法下载对应的模块。 遇到此错误的解决方案为：将以下三处的filename改为PACKAGE。（代码中的PACKAGE原为filename） D:\opencv\opencv_contrib\modules\dnn_modern\CMakeLists.txt 20行改为 ocv_download(PACKAGE &quot;v1.0.0a3.tar.gz&quot; D:\opencv\opencv_contrib\modules\xfeatures2d\cmake\download_boostdesc.cmake 22行改为 ocv_download(PACKAGE ${name_${id}} D:\opencv\opencv_contrib\modules\xfeatures2d\cmake\download_vgg.cmake 16行改为 ocv_download(PACKAGE ${name_${id}} 修改后安装成功，可以在输出中查看具体的安装信息： 从图中可以发现，我所需要的tracking库也已经安装成功了。 没有make指令在使用命令行界面安装时，没有最后一步的make指令。 那么只能自己安装了。或者直接用cmake GUI安装。 打开之前opencv_contrib的build文件夹，找到已经生成的opencv项目并打开。 打开VS之后，可以看到完整的OpenCV项目。然后直接编译即可（看个人情况，可自行选择Release或者Debug）。时间相当长。。。 编译成功后，在CMakeTargets中找到INSTALL，然后生成INSTALL，得到我们想要的最终文件。 半永久配置上述步骤的确很麻烦，并且非常容易出错。 有热心网友给出了自己配置好的文件，可以半永久配置。读者感兴趣的可以自己尝试下：http://www.cnblogs.com/wjy-lulu/p/6605306.html 参考文献 https://stackoverflow.com/questions/28619037/opencv-where-is-tracking-hpp http://blog.csdn.net/qsy2000/article/details/70158537 http://blog.csdn.net/cv_jason/article/details/70037545 其实这篇教程写的并不算太详细，cmake GUI可以对照着第三个博客安装。]]></content>
      <categories>
        <category>邂逅opencv</category>
      </categories>
      <tags>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客使用MathJax并解决markdown渲染冲突问题]]></title>
    <url>%2F2017%2F09%2F21%2Fmarkdown_mathjax%2F</url>
    <content type="text"><![CDATA[利用MathJax来渲染LaTeX数学公式hexo主题Next中已经集成了对mathjax的支持。在主题配置文件，blog\themes\next\_config.yml中定位到如下片段: # MathJax Support mathjax: enable: true per_page: false cdn: //cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML 将enable中的false改为true即可。 另外，再安装一个自动部署MathJax的hexo插件 。安装方式也很简单，在你的博客文件夹下执行： npm install hexo-math --save hexo math install 然后在新建的博文中写上一个麦克斯韦方程组查看LaTeX效果： $$ \begin{eqnarray} \nabla\cdot\vec{E} &amp;=&amp; \frac{\rho}{\epsilon_0} \\ \nabla\cdot\vec{B} &amp;=&amp; 0 \\ \nabla\times\vec{E} &amp;=&amp; -\frac{\partial B}{\partial t} \\ \nabla\times\vec{B} &amp;=&amp; \mu_0\left(\vec{J}+\epsilon_0\frac{\partial E}{\partial t} \right) \end{eqnarray} $$ $$\begin{eqnarray}\nabla\cdot\vec{E} &amp;=&amp; \frac{\rho}{\epsilon_0} \\\nabla\cdot\vec{B} &amp;=&amp; 0 \\\nabla\times\vec{E} &amp;=&amp; -\frac{\partial B}{\partial t} \\\nabla\times\vec{B} &amp;=&amp; \mu_0\left(\vec{J}+\epsilon_0\frac{\partial E}{\partial t} \right)\end{eqnarray}$$ 这时如果你会发现出了一些问题，原因是hexo先用marked.js渲染，然后再交给MathJax渲染。在marked.js渲染的时候下划线_是被escape掉并且换成了&lt;em&gt;标签，即斜体字，另外LaTeX中的\\也会被转义成一个\，这样会导致MathJax渲染时不认为它是一个换行符了。 mathjax与markdown默认渲染冲突解决方案为：修改Hexo渲染源码。 这个方法是我目前使用的，相对来说，通用性较高的一种方式。思路就是修改hexo的渲染源码: nodes_modules/lib/marked/lib/marked.js: 去掉\的额外转义 将em标签对应的符号中，去掉_,因为markdown中有*可以表示斜体，—就去掉了。 具体思路参考了使Marked.js与MathJax共存, 打开nodes_modules/marked/lib/marked.js:第一步: 找到下面的代码: escape: /^\\([\\`*{}\[\]()# +\-.!_&gt;])/, 改为: escape: /^\\([`*{}\[\]()# +\-.!_&gt;])/, 这样就会去掉\的转义了。第二步: 找到em的符号: em: /^\b_((?:[^_]|__)+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, 改为: em:/^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, 去掉_的斜体含义,这样就解决了。为什么说通用性很高，因为我们没有修改文章的内容，可以放到别的引擎下也会顺利渲染。 这个困扰我许久的问题终于这么解决了。之前一直按照标准mathjax语法写公式，但是有的时候就会无法显示公式。 按照上述修改后，markdown不再处理(公式中的)_以及\。mathjax语法畅行无阻。 参考资料： https://segmentfault.com/a/1190000007261752]]></content>
      <categories>
        <category>博客搭建系列</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
        <tag>MathJax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LK光流法分析及其源码]]></title>
    <url>%2F2017%2F09%2F21%2Foptical_flow%2F</url>
    <content type="text"><![CDATA[光流法简介光流的概念是Gibson在1950年首先提出来的。它是空间运动物体在观察成像平面上的像素运动的瞬时速度，是利用图像序列中像素在时间域上的变化以及相邻帧之间的相关性来找到上一帧跟当前帧之间存在的对应关系，从而计算出相邻帧之间物体的运动信息的一种方法。 光流法，是利用目标物体在监控场景中的空间运动，体现在视频图像序列中为不同图像颜色分布变化。导致目标物在监控场景中的空间运动场，在图像中转化为光流场，体现图像中每一个像素点的变化趋势。光流场可视为监控场景中的瞬时速度场。 研究光流场的目的就是为了从图片序列中近似得到不能直接得到的运动场。运动场，其实就是物体在三维真实世界中的运动；光流场，是运动场在二维图像平面上（人的眼睛或者摄像头）的投影。 算法原理光流法的三种计算方法：LK，HS，最常用的还是LK。 Lucas–Kanade算法这个算法是最常见，最流行的。它计算两帧在时间t到t+δt之间每个每个像素点位置的移动。由于它是基于图像信号的泰勒级数，这种方法称为差分，这就是对于空间和时间坐标使用偏导数。 图像约束方程，也是光流法的基本方程，可以写为$I(x,y,z,t)=I(x +δx,y+δy,z+δz,t+δt)$ $I(x,y,z,t)$ 为在$(x,y,z)$位置的体素。 我们假设移动足够的小，那么对图像约束方程使用泰勒公式，我们可以得到： H.O.T.指更高阶，在移动足够小的情况下可以忽略。从这个方程中我们可以得到： 或者 我们得到： Vx ,Vy ,Vz 分别是$I(x,y,z,t)$的光流向量中x，y，z的组成。 $\frac{∂I}{∂x}$, $\frac{∂I}{∂y}$, $\frac{∂I}{∂z}$和 $\frac{∂I}{∂t}$则是图像在$(x,y,z,t)$这一点向相应方向的差分。所以$$I_x V_x + I_y V_y + I_z V_z = −I_t$$写做： 这个方程有三个未知量，尚不能被解决，这也就是所谓光流算法的光圈问题。那么要找到光流向量则需要另一套解决的方案。而Lucas-Kanade算法是一个非迭代的算法：假设流(Vx,Vy,Vz)在一个大小为$m*m*m$(m&gt;1)的小窗中是一个常数，那么从像素 $1,2,…,n,n =m^3$ 中可以得到下列一组方程： $$I_{x1} V_x + I_{y1} V_y + I_{z1} V_z = -I_{t_1} $$ $$I_{x2} V_x + I_{y2} V_y + I_{z2} V_z = -I_{t_2} $$ $$ \vdots $$ $$I_{xn} V_x + I_{yn} V_y + I_{zn} V_z = -I_{t_n} $$ 三个未知数但是有多于三个的方程，这个方程组自然是个超定方程，也就是说方程组内有冗余，方程组可以表示为： 记作： $$A \vec{v} = -b $$ 为了解决这个超定问题，我们采用最小二乘法： $$A^T A \vec{v} = A^T (-b) $$ or $$ \vec{v} = (A^T A)^{-1} A^T (-b) $$ 得到： 其中的求和是从1到n。 另外，由于LK算法假设是小位移，为了解决大位移问题，需要在多层图像缩放金字塔上求解，每一层的求解结果乘以2后加到下一层： 代码示例C++代码来自于： http://download.csdn.net/download/crzy_sparrow/4183674 有两点修改的地方： ①void handleTrackedPoint(Mat &frame;,Mat &output;)声明过程中循环条件points[i]要改为points[1]； ②新建项目时加上预编译头。 如果出现这个：warning:opening fiile(../../modules/highgui/src/cap_ffmpeg_impl.hpp:545)注意要把avi格式的视频文件放在debug下，可以用格式工厂转，注意视频编码那里要换成avc 效果：可以检测到运动目标。 参考资料： http://blog.csdn.net/crzy_sparrow/article/details/7407604http://blog.csdn.net/u014568921/article/details/46638557http://www.cnblogs.com/gnuhpc/archive/2012/12/04/2802124.html]]></content>
      <categories>
        <category>邂逅opencv</category>
      </categories>
      <tags>
        <tag>opencv</tag>
        <tag>光流法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv视频保存方法详解]]></title>
    <url>%2F2017%2F09%2F21%2Fopencv_SaveVideo%2F</url>
    <content type="text"><![CDATA[Opencv视频保存视频保存流程与示例视频保存三步走： 一开始（循环外） VideoWriter outputVideo; outputVideo.open(&quot;E:\\modeling\\视频\\compare3.avi&quot;, -1, 30, cvSize(cur.rows, cur.cols * 2 + 10),true); 接着（循环中） outputVideo &lt;&lt; canvas; //保存每帧图片到视频 最后释放（循环外） outputVideo.release(); //可以不要 视频保存详解第一步中： 先定义VideoWriter对象，并指定输出文件。其中，open函数的定义为： open ( const char* filename, int fourcc, double fps, CvSize frame_size, int is_color=1 ); 第一个参数filename为输出视频文件名。输出目录要存在，输出文件不存在时会自动创建。目录中注意使用转义字符。 第二个参数fourcc为编码格式。四个字符来表示压缩帧的codec。例如： CV_FOURCC(‘P’,’I’,’M’,’1’) = MPEG-1 codec CV_FOURCC(‘M’,’J’,’P’,’G’) = motion-jpeg codec CV_FOURCC(‘M’, ‘P’, ‘4’, ‘2’) = MPEG-4.2 codec CV_FOURCC(‘D’, ‘I’, ‘V’, ‘3’) = MPEG-4.3 codec CV_FOURCC(‘D’, ‘I’, ‘V’, ‘X’) = MPEG-4 codec CV_FOURCC(‘U’, ‘2’, ‘6’, ‘3’) = H263 codec CV_FOURCC(‘I’, ‘2’, ‘6’, ‘3’) = H263I codec CV_FOURCC(‘F’, ‘L’, ‘V’, ‘1’) = FLV1 codec 若编码器代号为 -1，则运行时会弹出一个编码器选择框。 详细的视频编解码格式可参考：Video Codecs by FOURCC 第三个参数fps 被创建视频流的帧率。 第四个参数frame_size 视频流的大小。 第五个参数is_color 如果非零(true)，编码器将希望得到彩色帧并进行编码；否则，是灰度帧（只有在Windows下支持这个标志）。 出错详解输出路径不对肯定就没有视频了。此外，容易出现的问题有保存的视频大小为0，保存的视频乱码或打不开。 保存的视频大小为0可能的原因有： 编码格式不对在open函数中第二个参数是编码格式，一定按照提供的编码格式进行填写，在应用中最好的解决方法是为-1。当为-1时，程序对弹出如下对话框供你选择： 本人电脑上只有选择全帧（非压缩的）才能正常打开。 帧速率不匹配该项会导致视频时间不同。 后缀名不对 选择.avi格式没有问题，其它待定。 保存的视频乱码或打不开这个情况一般就是编码格式不对造成的，也就是open函数中第二个参数。最好的解决方法是设为-1，然后手动选择编解码器。 http://www.cnblogs.com/polly333/p/5165290.html]]></content>
      <categories>
        <category>邂逅opencv</category>
      </categories>
      <tags>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BGSLibrary编译安装与BGSlibrary GUI的下载与使用]]></title>
    <url>%2F2017%2F09%2F20%2FBGSlibrary%2F</url>
    <content type="text"><![CDATA[本文主要介绍BGSLibrary编译安装与BGSlibrary GUI的下载与使用 安装前提：需要安装了opencv以及VS，可以参考这篇博文，写的很详细。 BGSLibrary简介BGSLibrary由Andrews Sobral开发，并提供了一个执行背景减除（BGS）的C++框架。该代码可以在Windows或Linux上运行。 目前，该库提供了35种BGS算法（PBAS算法从BGSLibrary中删除，因为它基于专利算法ViBE）。 几位作者提供了大量的算法。 源代码可以在GNU GPL v3许可证下获得，图书馆免费，学术目的开源。 任何用户都可以使用SVN客户端下载最新的项目源代码。 BGSLibrary地址该项目的github主页地址为：github地址 详细安装指南（官方修正版）在该项目的github主页上可以看到安装指导。本人的电脑配置为VS2015，Opencv3.2.0，所以在github主页上依次点击： Installation instructions 中的Windows installation -&gt; BGSLibrary with OpenCV 3.2.0 and Visual Studio 2015 from CMAKE (Recommended) 该界面下，详细的安装步骤（及修正）为： 打开windows控制台（cmd） 克隆BGSLibrary库到本地 克隆指令为： git clone https://github.com/andrewssobral/bgslibrary.git 切换到bgslibrary/build目录 设置opencv路径 特别注意：windows环境下没有`setlocal`命令。 所以跳过该步骤，直接进行下一步。 调用cmake命令安装 安装命令为： cmake -DOpenCV_DIR=%OpenCV_DIR% -G &quot;Visual Studio 14 Win64&quot; .. 注意：由于我们没有设置上一步的opencv路径，因此，上述cmake命令中的%OpenCV_DIR%需要用详细路径的形式替换，即直接指定opencv目录。笔者所用的命令为： cmake -D OpenCV_DIR=&quot;D:\Program Files\opencv3\build&quot; -G &quot;Visual Studio 14 Win64&quot; .. 命令中最后的两个点也是需要的。-D与OpenCV_DIR分开或者合在一起都可以。 上述两步骤的变化是笔者花了不少时间尝试出来的。 将opencv可执行文件目录添加到系统环境变量PATH中 计算机上右键 – 属性 – 高级系统设置 – 环境变量 – 系统变量中的PATH –添加opencv目录。 D:\Program Files\opencv3\build\x64\vc14\bin; 最后的是英文状态下的分号，表示不同路径间的分隔符。 VS中打开bgs.sln解决方案文件，切换到“RELEASE”模式（并且要注意选择x64而不是x86模式）下，点击“ALL_BUILD”项目开始生成。 安装完成，可以开始跑demo，跑BGSLibrary了。 主要有两种方式运行BGSLibrary，第一种是在cmd命令行下，第二种是运行写好的脚本文件。 运行方法一：windows控制台在windows控制台（cmd）下运行： ①用摄像头跑BGSLibrary C:\bgslibrary&gt; build\bgslibrary.exe --use_cam --camera=0 ②运行dome程序 C:\bgslibrary&gt; build\bgs_demo.exe dataset/video.avi ③运行demo2程序 C:\bgslibrary&gt; build\bgs_demo2.exe 注意：此时的目录为bgslibrary根目录。 运行方法二：直接运行脚本文件经过上述的成功生成过程后，可在bgslibrary根目录下找到写好的脚本文件（bat或者sh），直接双击运行即可。如下图所示： BGSlibrary GUI的下载与使用BGSlibrary GUI简介是否还在为上述繁琐的安装过程而苦恼，那么就快来下载BGSlibrary GUI吧。 BGSlibrary GUI是BGSLibrary的可执行版本，可用于Windows 32位和64位。 对于Linux和Mac用户，可以使用Makefile来编译所有文件并生成可执行示例。 该GUI中集成了37种背景建模算法，可以显示输入视频/图像、基于背景建模得到的前景和背景建模得到的背景图像，还可以显示出每种算法的计算复杂度等等。并且，测试的可以是视频、图片序列以及摄像头输入视频。 下载方式一文件名：bgslibrary_x86_v1.9.2_with_mfc_gui_v1.4.2.7z 下载地址：CSDN (找的网上的，亲测可用) 上传者设置了积分，没有积分的童鞋可以联系我，我私下发给你，或者我看情况可以上传百度云啥的。 下载方式二最新版本：BGSLibrary v1.9.1 with MFC GUI v1.4.1 (x86/x64) 下载地址：GITHUB（bgslibrary/binaries/） BGSlibrary GUI的使用已经是GUI界面了，所以使用非常简单，在此不再赘述。基本上和编译完成后能实现的功能相同。]]></content>
      <categories>
        <category>邂逅opencv</category>
      </categories>
      <tags>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BP神经网络部分具体的推导]]></title>
    <url>%2F2017%2F09%2F12%2FBP_derivation%2F</url>
    <content type="text"><![CDATA[mathjax公式中不能有多余的{} 网络结构参数说明BP神经网络示意图 网络结构一个输入层，两个隐含层，一个输出层。 参数标记 输入层神经元个数n、输出层神经元个数m【其中有m=n，每一帧都有对应的输出】 两个隐含层神经元个数均为100 权值：输入层与第一个隐含层之间的权值为$w_{ij}$，两个隐含层之间的权值为$w_{jk}$，第二个隐含层与输出层之间的权值为$w_{kl}$ 阈值：两个隐含层$a^1_j,a^2_k$,输出层$b_l$ 其中，$i=1,2,…,n$，$j,k=1,2,…,100$，$l=1,2,…,m$凡是下标含有$i,j,k,l$的，均表示单个神经元。 BP网络推导两个隐含层及输出层的输出$$H_j^1 = f(\sum_{i=1}^n w_{ij} x_i - a_{j}^1 )\ \ \ j=1,2,…,100$$ $$H_{k}^2 = f(\sum^{100}_{j=1} w_{jk} H^1_{j} - a^2_{k} )\ \ \ k = 1,2, \cdots ,100$$ $$O_l = \sum_{k = 1}^{100} w_{kl}H_{k}^2 - {b_l} \ \ \ l = 1,2, \cdots ,m$$ 误差$$e_l = y_l - O_l\ \ \ l = 1,2, \cdots ,m$$ 反向传播的权值更新$$\begin{equation}\begin{split}w_{kl} &amp;= w_{kl} - dw_{kl} \\&amp;= w_{kl} - \eta \frac{\partial e_l}{\partial w_{kl}}\\&amp;= w_{kl} + \eta H_k^2 e_l \ \ \ \ \ \ k = 1,2, \cdots ,100 \\\end{split}\end{equation}$$ $$\begin{equation}\begin{split}{w_{jk}} &amp;= {w_{jk}} - \eta \frac{\partial e_l}{\partial w_{jk}} \\&amp;= {w_{jk}} - \eta \frac{\partial e_l}{\partial O_l} \frac{\partial O_l}{\partial H_{k}^2} \frac{\partial H_{k}^2}{\partial w_{jk}} \\&amp;= {w_{jk}} - \eta (-e_l)(\sum_{l = 1}^m w_{kl}) (f’_{H_k^2} H_j^1) \\&amp;= {w_{jk}} + \eta f’_{H_k^2} H_j^1 \sum_{l = 1}^m w_{kl}e_l \ \ \ \ \ j = 1,2, \cdots ,100 \\\end{split}\end{equation}$$ $$\begin{equation}\begin{split}{w_{ij}} &amp;= {w_{ij}} - \eta \frac{\partial e_l}{\partial w_{ij}} \\&amp;= {w_{jk}} - \eta \frac{\partial e_l}{\partial O_l} \frac{\partial O_l}{\partial H_{k}^2} \frac{\partial H_{k}^2}{\partial H_{j}^1} \frac{\partial H_{j}^1}{\partial w_{ij}} \\&amp;= {w_{jk}} - \eta (-e_l)(\sum_{l = 1}^m w_{kl}) (f’_{H_k^2} \sum_{k = 1}^{100} w_{jk}) (f’_{H_j^1} x_i) \\&amp;= {w_{ij}} + \eta f’_{H_j^1}{x_i}\sum_{k = 1}^{100} [(\sum_{l = 1}^m w_{kl}e_l)w_{jk}f’_{H_k^2}] \\\ \ \ \ &amp;其中 i = 1,2, \cdots ,n;j = 1,2, \cdots ,100 \\\end{split}\end{equation}$$ 关于激活函数的说明上述公式中，$f’_{H_k^2}$, $f’_{H_j^1}$ 之所以没有代入具体值，是因为这取决与所采用的激活函数。DeepLearnToolBox之BP算法中可采用的激活函数有两种，一是sigmoid函数，二是双曲正切函数。 sigmoid函数当激活函数为sigmoid函数$f(x) = \frac{1} { 1 + e^{-x} }$时，sigmoid函数的导数具有下面的一个性质： 其导数为： $$\begin{equation}\begin{split}f’(x) &amp;= \frac{e^{ - x}}{(1 + e^{ - x})^2} \\&amp;= \frac{e^{ - x}}{(1 + e^{ - x})}\frac{1}{(1 + e^{ - x})}\\&amp;= (1 - \frac{1}{(1 + e^{-x})})(\frac{1}{(1 + e^{ - x})}) \\&amp;= (1-f(x))f(x)\\\end{split}\end{equation}$$ 因此，比如说，在$H^2_K$中对$f$求导，结果为$f’_{H_k^2} = H_k^2(1-H_k^2)$，同理$f’_{H_k^1} = H_k^1(1-H_k^1)$ tanh函数激活函数也可以是双曲正切函数$tanhx= \frac{sinhx}{coshx} = \frac{e^x-e^{-x}}{e^x+e^{-x}}$。 双曲正切函数的图形夹在水平直线y=1及y=-1之间，且当x的绝对值很大时，它的图形在第一象限内接近于直线y=1，而在第三象限内接近于直线y=-1。[1]即双曲正切函数的值域是(-1,1)。 tanh(4) = (exp(4)-exp(-4))/(exp(4)+exp(-4)) = 0.9993 超过[-4,4]的范围已经可以看为1了。 双曲正切函数的标准导数公式： $$ tanh(x) = \frac{1}{cosh(x)^2} = 1- tanh(x)^2 $$ 用如下命令作图，并画出导数图像： plot(x,1-tanh(x).^2) plot(x,1./cosh(x).^2) 代码中给出的导数公式为： $$f’_{tanhx} = 1.7159 * \frac{2}{3} (1 -\frac{1}{1.7159^2}tanhx^2) $$ 用如下命令plot(x,1.7159*2/3*(1-1/1.7159^2*tanh(x).^2))作图，画出导数图像： 可以看到，总体形状是类似的，但是幅度上还是存在着较大差异。具体缩放的原因还不太清楚。 总结这篇文章只要是基于公式推导BP网络的整体流程。基于代码的实现请参阅： DeepLearnToolBox之BP算法。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo搭建的Github博客之优化]]></title>
    <url>%2F2017%2F09%2F09%2Fblog-opti%2F</url>
    <content type="text"><![CDATA[本篇教程基于NexT主题的博客配置，实现更换主题、评论、打赏等36项功能，接下来根据这些功能进行分点描述，附上个人博客以供比对参考：链接。 搭建基本Hexo博客Hexo博客基本搭建参考：《hexo+GitHub博客搭建实战》一文，，笔者按照教程的顺序一步一步来，是没有出现错误的，如果读者们在搭建的时候遇到了问题不知如何解决，笔者会尽自己所能帮助读者，并将遇到的问题及解决方法附在文章下方。 Hexo博客绑定域名关于Hexo博客如何绑定自己的域名，详情可参阅《hexo搭建的Github博客绑定域名》一文。 博主按照上述教程，已经成功地绑定域名wangwlj.com。 更换Hexo主题笔者更换后的主题为NexT，其Github网址为：https://github.com/iissnan/hexo-theme-next 。首先将NexT的主题源文件下载到本地，使用Git克隆指令如下： git clone https://github.com/iissnan/hexo-theme-next themes/next 下载后，将压缩包解压缩(文件位于指令运行的当前目录)，复制其中名称为next的文件夹到Hexo的主题目录下，主题目录的路径为： Hexo博客根目录/themes/ 在Hexo根目录下有一个以_config.yml命名的文件（下称站点配置文件），用Sublime/NotePad++等文本编辑器打开，在其中找到theme属性，将其由landscape改为next。 然后在Hexo根目录执行部署Hexo指令： // 清理缓存 hexo clean // 生成文件 hexo generate // 部署 hexo deploy 便可以在远程的博客上看到修改主题后的样式了。 设置Hexo主题模式看到上图，读者可能会产生疑问，为什么自己的主题样式和笔者的不一样，这是因为在Hexo主题中，有四种不同的模式，通过切换模式，让NexT主题显示不一样的样式。 在NexT根目录下有一个同样名称为_config.yml，为了区分hexo根目录下的_config.yml，将前者称为主题配置文件，在其中找到scheme属性，如下图所示： # Schemes #scheme: Muse #scheme: Mist scheme: Pisces #scheme: Gemini NexT主题默认使用Muse模式，笔者采用的是Pisces模式，读者可根据自己的喜好，选择其中一种模式。 设置预览摘要设置完模式后，读者们会发现，尽管首页显示的是所有文章的列表，但是每一篇文章都显示了所有内容，这样感觉看起来不舒服，这时候可以启用预览摘要模式，在主题配置文件中找到auto_excerpt属性，将enable设置为true ，将length设置为想要预览到的字数，如下图所示： auto_excerpt: enable: true #将原有的false改为true length: 300 #设置预览的字数 这里说明一下：上述的部署指令中hexo deploy可以换成hexo server，两者的区别在于，前者是将博客部署到远程的Github上，而后者是运行在本地，通过http://localhost:4000在浏览器中访问。后者是为了调试配置方便而使用，但是最终本地博客还是需要hexo deploy指令将其部署至Github上。 添加评论功能NexT目前出到5.1.0版本，功能模块已经相当的丰富。NexT主题集成了评论系统，只需要设置相关的属性即可实现功能，其目前支持多说、Disqus、Facebook评论、Hyper评论、网页云跟帖等，其中“多说”是NexT推荐的评论系统，但是多说评论系统不稳定，经常会出现服务异常的问题。 ~~笔者采用的是一款名为友言的评论系统，它也是NexT已经集成好的，可以直接拿来用的。下面对其操作进行讲解： ~~- 注册友言账号 ~~打开友言官网，单击“注册”按钮后，按照套路可完成账号注册。 ~~- 获取uid ~~注册完登录后，在首页单击“后台管理”按钮进入后台界面便可看到自己的用户ID，将其复制下来。 ~~- 设置uid ~~打开主题配置文件，在其中找到属性youyan_uid，然后在: 后添加之前复制的uid。 ~~&gt; 提醒一下，: 冒号后面一定要有一个空格 ~~然后部署一下Hexo，可以在本地或远程看到实现的评论功能，如下图所示： &gt; 在笔者配置评论功能的时候，笔者遇到了一个问题：本地博客有评论功能，而远程博客却没有 。折腾了一下午，始终不知道其原因所在。后来，当笔者对博客绑定自己的域名后，发现远程的博客自动出现了评论功能。在此推测为域名的缘故。若没有绑定域名的读者们遇到这个情况，可以放放，先配置其他功能。 更新目前的评论系统，友言，网易云跟帖都挂了。所以，我最终采用的是来必力。 这边详细地介绍一下。我新写一篇文章简要介绍一下。会更新在我的博客上。 设置侧边栏显示效果在主题配置文件中，找到sidebar的display属性，display属性有四种显示模式：分别为： post // 默认显示方式 always // 一直显示 hide // 初始隐藏 remove // 移除侧边栏 笔者将其设置为hide模式，读者们可根据个人喜好进行设置。 添加菜单选项默认情况下，菜单导航栏有首页、归档、关于三个选项，除此之外笔者还添加了分类、标签和关于。在主题配置文件中，找到menu属性，并去掉categories、 tags、about的的注释，如下图所示： 然后在Hexo根目录执行指令如下： // 添加分类页面 hexo new page &quot;categories&quot; // 添加标签页面 hexo new page “tags” // 添加关于页面 hexo new page &quot;about&quot; 执行完上述指令后，在Hexo根目录/source/文件夹下创建三个文件夹，命名分别为：categories、tags、about文件夹，在这些文件夹中分别会创建一个以index命名的Markdown文件，对这三个Markdown文件内容进行修改，使之分别为： --- title: categories date: 2017-03-12 22:06:24 type: &quot;categories&quot; --- --- title: 标签 date: 2017-03-12 17:27:16 type: &quot;tags&quot; --- --- title: about date: 2017-03-12 22:07:26 type: &quot;about&quot; --- 完成文件的修改，然后部署Hexo即可完成菜单选项的添加。 添加阅读次数统计注册LeanCloud账号，完成激活；点击左上角的”应用”-“创建新应用”-点击“数据”右边的齿轮–点击创建类class，类名字叫做Counter。 然后，修改主题配置文件，找到leancloud_visitors，添加修改： leancloud_visitors: enable: true #将原来的false改为true app_id: #&lt;app_id&gt; app_key: #&lt;app_key&gt; 从设置中找到相应的id和key： 然后预览，如图： 添加社交链接笔者希望在个人博客中加入自己的微博、知乎和Github链接以提高访问量，接下来了解一下社交链接如何添加： 添加链接及图标 在主题配置文件中找到social属性，在其下方添加社交链接及图标，其格式为： 社交平台名称：链接 || 图标 链接的图标全部来自于Font Awesome 个人配置 笔者社交链接添加情况如以下代码所示： social: GitHub: https://github.com/qwerty200696 || github E-Mail: mailto:yourname@gmail.com || envelope 知乎: https://www.zhihu.com/people/LijieWang || gratipay 微博: https://weibo.com/3280603012 || weibo Google: https://plus.google.com/yourname || google Twitter: https://twitter.com/yourname || twitter FB Page: https://www.facebook.com/yourname || facebook #VK Group: https://vk.com/yourname || vk #StackOverflow: https://stackoverflow.com/yourname || stack-overflow YouTube: https://youtube.com/yourname || youtube Instagram: https://instagram.com/yourname || instagram 其中，微博有其对应的图标，而知乎在图标库中却没有找到，笔者找了一款gratipay的图标来代替知乎图标。 如果没有找到指定的图标，将会启用默认的图标。 效果展示 配置完成后，具体效果显示如下： 添加友情链接功能在主题配置文件中找到links属性，修改links_title属性的值为“友情链接”（也可以是其他文案），取消注释links:，然后添加上好友的博客名称和博客地址，其格式如下： # Blog rolls links_title: 友情链接 #修改名称 #links_layout: block #links_layout: inline links: #该行取消注释 小草莓: http://my.csdn.net/qq_31196849 qingkong: http://my.csdn.net/qingkong1994 笔者友情链接出现位置在社交链接的下方，效果如下图所示： 设置博文内链接为蓝色 修改原因 链接的默认颜色是白色的，和普通字体颜色相同，不容易区分，如下图所示： 修改方法 通过路径： F:Hexo\themes\next\source\css\_common\components\post\ 打开post.styl文件，在文件中添加，如下字段： .post-body p a{ color: #0593d3; border-bottom: none; &amp;:hover { color: #0477ab; text-decoration: underline; } } 最好将新添加的内容放在原文件内容的底部，便于查看。 效果预览 设置完成后部署一下，预览效果如图： 图中Git的链接出现的下划线是鼠标悬停时的效果。 设置文章末尾”本文结束”标记实现方法 在路径F:\Hexo\themes\next\layout\_macro下，新建一个文件passage-end-tag.swig,文件内容中添加以下代码： {% if theme.passage_end_tag.enabled %} ------ 本文结束感谢您的阅读 ------ {% endif %} 代码截图如下(在网站中看到的div标签生效消失了，故此截图)： 这里可以更改字体显示的颜色，大小，以及内容，例如可将本文结束用The Happy Ending代替，并将字体颜色设置为了自己喜欢的#CDBA96，你可以去这里选择自己喜欢的颜色对应的RGB值。 然后在路径\themes\next\layout\_macro\下找到并打开post.swig文件，在 post-body 之后， post-footer 之前添加如下代码（post-footer之前两个DIV）： {% if not is_index %} {% include 'passage-end-tag.swig' %} {% endif %} 具体位置如下图所示： 最后在主题配置文件中，在末尾添加如下语句： passage_end_tag: enabled: true 实现效果图 最终实现效果如下： 显示每篇文章字数实现方法 首先安装插件，执行以下命令： npm install hexo-wordcount --save 然后修改主题配置文件，定位到post_wordcount，将wordcount由false改为true即可。 实现效果图 在每篇文章标题下会有如下效果： 显示站点文章总字数实现方法 首先安装插件，插件安装同上（已经“显示每篇文章字数”则忽略这步）。 然后修改主题配置文件，定位到post_wordcount，将totalcount由false改为true即可。 实现效果图 在页面最底部会有如下效果： 文章末尾添加版权说明直接修改主题配置文件，定位到post_copyright，将enable由false改为true即可。 该字段如下： # Declare license on posts post_copyright: enable: true license: CC BY-NC-SA 3.0 license_url: https://creativecommons.org/licenses/by-nc-sa/3.0/ 实现效果如图所示： 设置个人头像通过上面切换到Pisces发现，自己的头像还是属于匿名状态，因此，我们有必要设置一下自己的头像。 实现方法 在主题配置文件中找到avatar字段,进行修改: # Sidebar Avatar # in theme directory(source/images): /images/avatar.gif # in site directory(source/uploads): /uploads/avatar.gif avatar: /images/head_icon.jpg 先将avatar字段前的#删除，然后粘贴上头像的目录位置或者链接。 笔者将突破保存在了主题目录下的source/images文件夹，也可以存放在站点目录下的source/uploads文件夹。也可以将自己的头像图片，保存在百度网盘或者新浪微盘的某个地方，然后将对应的url地址复制过来，添加在avatar字段后即可。 实现效果图 其效果如下图所示： 达到效果后即可部署至远程。 设置头像动态特效在路径F:\Hexo\themes\next\layout\_partials找到head.swig文件并打开，在其末尾添加，如下字段： &lt;link href=&quot;//cdn.bootcss.com/animate.css/3.5.0/animate.min.css&quot; rel=&quot;stylesheet&quot;&gt; 并在路径themes\next\source\css\_common\components\sidebar\下找到sidebar-author.styl文件并打开，添加如下语句： .site-author-image:hover { -webkit-animation: jello 1s; animation: jello 1s; }; 其中jello是我选择的动态效果，你可以在这里找到你喜欢的特效;然后更换上述代码中的jello字段，达到预期效果后，即可部署至远程。 设置网站图标实现方法 打开主题配置文件，找到以下字段，进行相应的修改： # Put your favicon.ico into `hexo-site/source/` directory. favicon: /web_icon.jpg 然后预览，在自己的博客网站上有这样的图标： 因为我使用了与头像一样的图片，所以图标与头像一样。达到效果后即可部署至远程。 添加留言版块我们还可以在菜单栏增加一个”留言板”,让他人可以通过留言板直接给我们留言。 实现方法 在博客目录中，执行以下命令，新建一个页面： hexo n page guestbook 然后通过路径F:\Hexo\source\guestbook找到并打开guestbook文件夹下的index.md文件，然后再文件中添加以下代码: &lt;div class=&quot;ds-recent-visitors&quot; data-num-items=&quot;28&quot; data-avatar-size=&quot;42&quot; id=&quot;ds-recent-visitors&quot;&gt;&lt;/div&gt; 然后打开主题配置文件，在menu字段下，添加如下字段： menu: home: / || home about: /about/ || user tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive 留言板: /guestbook || newspaper-o #自己添加的字段 newspaper-o是留言板的图标，可以在这里找到自己喜欢的图标。 笔者采用的youyan评论系统，默认在新建页面上会产生评论板块。效果如下： 这个效果暂时不稳定，可能是由于笔者暂时还没有绑定域名的关系。 项目主页添加README在建立Github上建立自己的博客仓库的时候，没有生成README文件，这样使得其他人无法知道我们这个仓库是做什么，即我们的这个仓库缺少一个说明文件；但是如果直接使用命令hexo n README，再部署至远程的时候，hexo会将它解析为html文件，这不是我们想要的。 实现方法 因此，解决方式是在路径F:\Hexo\source下手动新建README.mdown注意这里的后缀是.mdown，Mardownpad可以将文件保存为.mdown后缀文件；然后再在这个新建文件中写README即可。再之后hexo g会把它复制到public文件夹，而不会被解析成html文件，发布在博客中。 实现效果图 预览效果，如图： 实现fork me on github在右上角或者左上角实现fork me on github。 实现方法 点击这里挑选自己喜欢的样式，并复制代码。 例如，我是复制如下代码： 然后粘贴刚才复制的代码到themes/next/layout/_layout.swig文件中(放在&lt;div class=&quot;headband&quot;&gt;&lt;/div&gt;的下面)，并把href标签改为你的github地址： 实现效果图 实现效果图如下（右上角）： 实现点击出现桃心效果实现方法 打开浏览器，输入如下网址 http://7u2ss1.com1.z0.glb.clouddn.com/love.js 然后将里面的代码copy一下，新建love.js文件并且将代码复制进去，然后保存。将love.js文件放到路径/themes/next/source/js/src里面，然后打开\themes\next\layout\_layout.swig文件,在末尾（在前面引用会出现找不到的bug）添加以下代码： &lt;!-- 页面点击小红心 --&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/love.js&quot;&gt;&lt;/script&gt; 实现效果图 修改文章底部的#号标签实现方法 修改模板/themes/next/layout/_macro/post.swig，搜索 rel=&quot;tag&quot;&gt;#，将其中的 # 换成&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt; 实现效果图 添加动态背景实现方法 在主题配置文件中，定位到如下部分： # Canvas-nest canvas_nest: true # three_waves three_waves: false # canvas_lines canvas_lines: false # canvas_sphere canvas_sphere: false # Only fit scheme Pisces # Canvas-ribbon canvas_ribbon: false 这是已经集成好的几个动态效果，笔者采用的是canvas_nest，读者可依次体验(将false改为true)，选择最喜欢的动态背景。 实现效果图 代码块样式自定义实现方法 打开\themes\next\source\css_custom\custom.styl,向里面加入：(颜色可以自己定义) // Custom styles. code { color: #ff7600; background: #fbf7f8; margin: 2px; } // 大代码块的自定义样式 .highlight, pre { margin: 5px 0; padding: 5px; border-radius: 3px; } .highlight, code, pre { border: 1px solid #d6d6d6; } 实现效果图 文章加密访问实现方法 打开themes-&gt;next-&gt;layout-&gt;_partials-&gt;head.swig文件,在以下位置插入这样一段代码： 代码如下： &lt;script&gt; (function(){ if(&apos;{{ page.password }}&apos;){ if (prompt(&apos;请输入文章密码&apos;) !== &apos;{{ page.password }}&apos;){ alert(&apos;密码错误！&apos;); history.back(); } } })(); &lt;/script&gt; 然后在文章上写成类似这样： 实现效果图 添加jiathis分享实现方法 在主题配置文件中，jiathis为true，就行了，代码如下： # Share # This plugin is more useful in China, make sure you known how to use it. # And you can find the use guide at official webiste: http://www.jiathis.com/. # Warning: JiaThis does not support https. jiathis: true ##uid: Get this uid from http://www.jiathis.com/ #add_this_id: 实现效果图 自定义鼠标样式实现方法 打开themes/next/source/css/_custom/custom.styl,在里面写下如下代码 // 鼠标样式 * { cursor: url(&quot;http://om8u46rmb.bkt.clouddn.com/sword2.ico&quot;),auto!important } :active { cursor: url(&quot;http://om8u46rmb.bkt.clouddn.com/sword1.ico&quot;),auto!important } 其中 url 里面必须是 ico 图片，ico 图片可以上传到网上（我是使用七牛云图床），然后获取外链，复制到 url 里就行了 #支持mathjax公式 看到网上说明安装hexo-math工具，或者其他的一系列教程，如这个。 其实在目前的hexo/NexT主题已经集成了mathjax，所以不需要那么麻烦的设置了。 实现方法 在主题配置文件中，定位到mathjax，将后面的选项为true，就行了。 另外，虽然这样设置了，但是在编写的时候还会出现mathjax与markdown默认渲染不兼容的问题，导致有时候公式一复杂就显示不出来。 解决上述问题的方法请参照我写的另一片博客：https://qwerty200696.github.io/2017/09/21/markdown_mathjax/ 修改部分字体的颜色，大小比如说，想在文章中对某一部分的文字进行强调（改变大小，颜色），该操作具体说明如下： 如果想自定义字体大小以及颜色，可以直接在 Markdown 文档中使用 html 语法： &lt;font size=4 &gt; 这里输入文字，自定义大小 &lt;/font&gt; &lt;font color=&quot;#FF0000&quot;&gt; 这里输入文字，自定义颜色的字体 &lt;/font&gt; 其中#FF0000为RGB颜色代码，读者可去RGB颜色查询对照表网站查找自己喜欢的颜色。 若想在RGB颜色值与十六进制颜色码之间相互转化，可查看该网站。 实现首行缩进由于markdown语法主要考虑的是英文，所以对于中文的首行缩进并不太友好，因此想要实现行缩进需要加上相应的代码，如下。 在需要缩进行的开头处，先输入下面的代码，然后紧跟着输入文本即可。分号也不要漏掉。 直接写: 半方大的空白&amp;ensp;或&amp;#8194;全方大的空白&amp;emsp;或&amp;#8195;不断行的空白格&amp;nbsp;或&amp;#160; 亲测可行。 插入表格插入表格的代码是：12345678910&lt;table class="table table-bordered table-striped table-condensed"&gt; &lt;tr&gt; &lt;td&gt;北京&lt;/td&gt; &lt;td&gt;雾霾&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;深圳&lt;/td&gt; &lt;td&gt;暴雨&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; 效果为： 北京 雾霾 深圳 暴雨 添加RSS安装 hexo-generator-feed 插件RSS需要有一个Feed链接，而这个链接需要靠hexo-generator-feed插件来生成，所以第一步需要添加插件，在Hexo根目录执行安装指令：1npm install hexo-generator-feed --save 配置feed信息在站点配置文件中追加如下代码：123456feed: type: rss2 path: rss2.xml limit: 10 hub: content: &apos;true&apos; feed属性下的各个子属性的含义借用feed官方英文解释如下：12345type - Feed type. (atom/rss2)path - Feed path. (Default: atom.xml/rss2.xml)limit - Maximum number of posts in the feed (Use 0 or false to show all posts)hub - URL of the PubSubHubbub hubs (Leave it empty if you don&apos;t use it)content - (optional) set to &apos;true&apos; to include the contents of the entire post in the feed. 至此RSS功能大功告成，部署至远程后，会发现RSS已经自动出现，效果图如下： 手机端订阅图 添加搜索功能笔者采用的是local search。安装 hexo-generator-searchdb，在站点的根目录下执行以下命令：1$ npm install hexo-generator-searchdb --save 编辑 站点配置文件（站点根目录下），新增以下内容到任意位置：12345search: path: search.xml field: post format: html limit: 10000 编辑 主题配置文件（主题目录下），启用本地搜索功能：123# Local searchlocal_search: enable: true 之后部署到远程即可。 Hexo博客提交百度和Google收录TODO 最后这几个由于感觉暂时没有必要，就先搁置了，有空补。 添加打赏功能TODO 博文置顶TODO 参考文献 【干货】2个小时教你hexo博客添加评论、打赏、RSS等功能 GitHub+Hexo+NexT搭建个人博客 hexo博客的背景设置]]></content>
      <categories>
        <category>博客搭建系列</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo+GitHub博客搭建实战]]></title>
    <url>%2F2017%2F09%2F08%2Fblog_setup%2F</url>
    <content type="text"><![CDATA[准备工作1、安装 Node.js: https://nodejs.org/en/ 2、安装 Git: https://github.com/waylau/git-for-win Git教程 https://github.com/waylau/git-for-win廖雪峰老师的教程，非常好。 3、安装完成后，在开始菜单里找到“Git”-&gt;“Git Bash”，名称和邮箱是Github上的。 4、安装 Hexo。所有必备的应用程序安装完成后，即可使用 npm 安装 Hexo。 $ npm install -g hexo-cli 5、安装hexo出错：unable to verify the first certificate（无法验证第一证书） 查找到解决方案： 参考网址：npm报错 依据解决方案所述，在命令行输入如下命令，来取消ssl验证： npm config set strict-ssl false 之后安装就会成功了，显示如下： 配置Github首先注册、登录 https://github.com/ 记住自己的Username（很重要） 然后右上角选择 Create a new repository https://github.com/new Repository name（填自己的名字） yourname.github.io(yourname与你的注册用户名一致,这个就是你博客的域名了) 仓库创建完成后，开始生成添加秘钥。 在终端（cmd）输入： ssh-keygen -t rsa -C &quot;Github的注册邮箱地址&quot; 一路Enter过来就好，待秘钥生成完毕，会得到两个文件id_rsa和id_rsa.pub，用带格式的记事本打开id_rsa.pub，Ctrl + a复制里面的所有内容，然后进入https://github.com/settings/ssh： 将复制的内容粘贴到Key的输入框，随便写好Title里面的内容，点击Add SSH key按钮即可。 若没有配置GitHub，就执行第三步（初始化博客），会出现如下错误： 初始化博客在电脑F盘（自己随意）目录下新建文件夹 test，进入test，按住Shift键点击鼠标右键，点击“在此处打开命令窗口”： 输入 hexo init blog 稍微等待下，速度有点慢。成功提示： INFO Start blogging with Hexo! 因为你初始化hexo 之后source目录下自带一篇hello world文章, 所以直接执行下方命令:123456$ hexo generate# 启动本地服务器$ hexo server# 在浏览器输入 http://localhost:4000/就可以看见网页和模板了INFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 访问http://localhost:4000/，便可以看到网站初步的模样，不要激动，我们还要把网页发布到Github上去。 配置博客在blog目录下，用sublime/notepad++等文本编辑器打开_config.yml文件，修改参数信息 特别提醒，在每个参数的：后都要加一个空格 修改网站相关信息123456title: wangwlj测试所用博客subtitle: 积跬步以至千里！description: 网页描述author: wangwljlanguage: zh-CNtimezone: Asia/Shanghai language和timezone都是有输入规范的，详细可参考 语言规范和时区规范。 配置部署代码中的qwerty200696，修改成自己的。 deploy: type: git repo: https://github.com/qwerty200696/qwerty200696.github.io branch: master 其中repo项是之前Github上创建好的仓库的地址，可以通过如下图所示的方式得到： branch是项目的分支，我们默认用主分支master。 配置统一资源定位符如果有个人域名的话可以设置，否则跳过即可。如果是github.io的网址，也是可以填上的。 url: https://qwerty200696.github.io 对于root（根目录）、permalink（永久链接）、permalink_defaults（默认永久链接）等其他信息保持默认。 发表文章1.新建一篇博文，在CMD中输入: $ hexo new &quot;我的测试文章&quot; INFO Created: F:\test\blog\source\_posts\我的测试文章.md 2.找到该文章，打开，使用Markdown语法编辑文章。 该语法介绍可以查看：markdown语法 在文章的一开始处，可以按如下格式添加文章标题，日期，分类、标签以及描述等。 --- title: title #文章標題 date: 2017-09-08 23:47:44 #文章生成時間 categories: &quot;Hexo教程&quot; #文章分類目錄 可以省略 tags: #文章標籤 可以省略 - 标签1 - 标签2 description: #你對本頁的描述 可以省略 --- 3.接着输入如下的一系列命令：123456789101112131415F:\test\blog$ hexo cleanINFO Deleted database.INFO Deleted public folder.F:\test\blog$ hexo generateINFO Start processingINFO Files loaded in 1.48 s#省略INFO 29 files generated in 4.27 s$ hexo serverINFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 我直接跑的server，也可以。 最后一步，发布到网上，执行：123456F:\test\blog$ hexo deployINFO Deploying: gitINFO Clearing .deploy_git folder...INFO Copying files from public folder...#省略 其中会跳出Github登录，直接登录，如果没有问题，在浏览器输入qwerty200696（换成你的）.github.io/ 我的测试所用博客 https://qwerty200696.github.io/ 然后就可以看到已经发布了。 错误记录一deploy not found： git 解决方案：执行如下语句后， 再部署即可： npm install hexo-deployer-git --save 参考自：https://www.v2ex.com/t/175940 错误记录二今天运行： hexo deploy 同步文章到github时，出错： fatal: unable to access &apos;https://username:password@github.com/username/username.github.io.git/&apos;: SSL certificate problem: unable to get local issuer certificate FATAL Something&apos;s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.html Error: fatal: unable to access &apos;https://username:password@github.com/username/username.github.io.git/&apos;: SSL certificate problem: unable to get local issuer certificate at ChildProcess.&lt;anonymous&gt; (D:\test\blog2\node_modules\hexo-util\lib\spawn.js:37:17) at emitTwo (events.js:106:13) at ChildProcess.emit (events.js:191:7) at ChildProcess.cp.emit (D:\test\blog2\node_modules\cross-spawn\lib\enoent.js:40:29) at maybeClose (internal/child_process.js:920:16) at Process.ChildProcess._handle.onexit (internal/child_process.js:230:5) 解决方法：执行如下语句： $ git config --global http.sslVerify false 参考自：git获取代码提示SSL certificate problem: unable to get local issuer certificate （optional）另外，可将_config.yml中的repo修改为如下标准格式： repo: https://用户名:密码@github.com/用户名/用户名.github.io.git 参考自： hexo提交报错 unable to access 之后再次运行发布指令，终于成功： hexo deploy 添加图片经过上面的配置后，发现上传的博客文章里面的本地图片居然显示不来（没有同步上传）。 于是，找到解决方案： 1 把主页配置文件_config.yml 里的post_asset_folder:这个选项设置为true 2 在你的hexo目录下执行这样一句话npm install hexo-asset-image --save，这是下载安装一个可以上传本地图片的插件 3 等待一小段时间后，再运行hexo n &quot;xxxx&quot;来生成md博文时，/source/_posts文件夹内除了xxxx.md文件还有一个同名的文件夹 4 最后在xxxx.md中想引入图片时，先把图片复制到xxxx这个文件夹中，然后只需要在xxxx.md中按照markdown的格式引入图片： ![你想输入的替代文字](xxxx/图片名.jpg) 注意： xxxx是这个md文件的名字，也是同名文件夹的名字。只需要有文件夹名字即可，不需要有什么绝对路径。你想引入的图片就只需要放入xxxx这个文件夹内就好了，很像引用相对路径。 5 最后检查一下，hexo g生成页面后，进入public\2017\02\26\index.html文件中查看相关字段，可以发现，html标签内的语句是&lt;img src=&quot;2017/02/26/xxxx/图片名.jpg&quot;&gt;，而不是&lt;img src=&quot;xxxx/图片名.jpg&gt;。这很重要，关乎你的网页是否可以真正加载你想插入的图片。 6.hexo s，运行本地服务器，打开http://localhost:4000/，可实时查看修改情况。 7.hexo g，同步到github。 参考自：hexo生成博文插入图片 总结发布文章的步骤： 1、hexo new 创建文章 2、Markdown语法编辑文章 3、部署（所有打开CMD都是在blog目录下） hexo clean #清除缓存 网页正常情况下可以忽略此条命令 hexo generate #生成 hexo server #启动服务预览，非必要，可本地浏览网页 hexo deploy #部署发布 简写Tips： hexo n “我的博客” == hexo new “我的博客” #新建文章 hexo p == hexo publish hexo g == hexo generate#生成 hexo s == hexo server #启动服务预览 hexo d == hexo deploy#部署 参考文献： 教你免费搭建个人博客，Hexo&amp;Github hexo生成博文插入图片]]></content>
      <categories>
        <category>博客搭建系列</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows下TensorFlow完整安装流程及出错解决方案]]></title>
    <url>%2F2017%2F09%2F07%2FTensorFlow_setup%2F</url>
    <content type="text"><![CDATA[安装python通过Pip在Windows上安装PythonTensorFlow在Windows上只支持64位Python3.5，可以通过Python 3.5 from python.org 下载并安装Python3.5.2（注意选择正确的操作系统）。 或者通过https://www.python.org/downloads/选择3.5的任意版本。 设置环境变量上一步安装时，如果勾选了“自动配置环境变量”操作，即：在cmd中输入pip，如果找到了该命令，则可省去该步骤。 若在cmd中输入pip找不到该命令，则需要将Python安装路径下“%安装路径%\Scripts”添加到Path下；再到cmd中输入pip看到若干命令提示，则代表python安装成功（Python安装包自带pip）。“开始”-&gt;“所有程序”，也可以找到Python终端。 参考自：http://blog.csdn.net/include1224/article/details/53452824 cuda以及cudnn的安装TensorFlow分为CPU版和GPU版，如果你打算安装GPU版，请先安装如下两个驱动： 1、CUDA安装：https://developer.nvidia.com/cuda-downloads 2、CuDNN安装：https://developer.nvidia.com/cudnn（要注册Nvidia用户，并加入CuDNN开发组，填若干问卷就可以下载了）选择下载版本时要注意和Cuda版本匹配。 我的账户是qq邮箱。 解压后（三个目录，分别是：bin、include、lib），覆盖至CUDA的安装目录下。例如： C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0\ 安装tensorflow我安装的是GPU版本。 windows不支持pip在线安装。即不支持：pip install tensorflow-gpu该命令。 两种方法安装tensorflow： 手动下载tensorflow gpu版本文件：tensorflow_gpu-0.12.0rc0-cp35-cp35m-win_amd64.whl下载网址：https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.1-cp35-cp35m-win_amd64.whl 下载完成后，打开cmd，切换到安装文件目录，输入: pip install tensorflow_gpu-0.12.0rc0-cp35-cp35m-win_amd64.whl 即可成功安装。 输入pip命令pip install --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.1-cp35-cp35m-win_amd64.whl 参考自tensorflow官网：https://www.tensorflow.org/versions/r0.12/get_started/os_setup#pip_installation_on_windows mac和linux可另行参考网上教程。 测试测试是否安装成功。 问题一import tensorflow as tf 导入tensorflow时出现错误： “Couldn&apos;t open CUDA library cudnn64_5.dll” 找到解决方案：安装时没有注意cudnn版本要求，下载安装了cudnnv6.0，安装完后自己查找文件，只有cudnn64_6.dll，没有cudnn64_5.dll。 解决方案为将cudnnV6.0替换为cudnnV5.1即可。 即重新下载cudnn5.1版本。 https://developer.nvidia.com/rdp/cudnn-download 解决方案来自：http://blog.csdn.net/suo_ivy/article/details/70445103 替换完成后，该错误消失。 问题二 执行tf.Session()的时候，出现如下提示： Could not identify NUMA node of /job:localhost/replica:0/task:0/gpu:0, defaulting to 0. Your kernel may not have been built with NUMA support.` 不过这并不影响最终结果的执行。（只是个警告） 网上找到相关说明： http://blog.csdn.net/baixiaozhe/article/details/54598346可供参考一下。大体上的意思是：只要我们不是使用多GPU，这个警告应该是可以忽略的，所以我们目前也不需要担心了。 至此，tensorflow 测试完成，并成功运行了测试样例。 (optional) 测试程序源码]]></content>
      <categories>
        <category>TensorFlow系列</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ Primer学习笔记：(三)字符串、向量和数组]]></title>
    <url>%2F2016%2F10%2F05%2FcPP_03%2F</url>
    <content type="text"><![CDATA[第三章 字符串、向量和数组第三章主要讲这么五个概念： 1.using声明，我知道挺多同学写代码练手都要在源文件前几句直接加using namespace std;然而using语句并不是什么情况都这么使用的，稍后我们将会看到详细的用法。 2.标准库类型string,和C的字符数组有区别的string，到底是怎么个构造，这章将会讲述。 3.标准库类型vector，vector和数组区别很大，这里将会提到，并引入一个“容器”的重要概念。 4.迭代器，迭代器用来代替下标这种传统方式访问容器或一些支持迭代器的类型。 5.数组和多维数组，经典概念。 命名空间的using声明(P75,3.1)尽管我们可以在各种文件里都使用using namespace std;或者using std::endl;这种语句，但是，在头文件包含命名空间可能产生各种意外。因此，头文件不应包含using声明。 标准库类型string本节介绍最常用的操作，9.5节将介绍另外的。 定义和初始化string对象(P76,3.2.1)12#include &lt;string.h&gt;using std::string; 以下几种初始化语句被string支持： 123456string s1;//创建了一个空的字符串，对象名为s1，类型为string类型。string s2(s1);//是s2的值与s1的值相等。string s2=s1;//同上一句，拷贝初始化。string s3("value");//直接用字符串字面值初始化string类型的对象。string s3="value";//字符串字面值转化为string类型变量并赋值给string。string s4(10,'c');//直接初始化string，操作后s4拥有10个字符，每个字符的值都是'c'。 最后，其实string s5={&quot;value&quot;}和string s3=&quot;value&quot;一样，也是合法的。不过大括号初始化是严格检测匹配的，比如int a={3.5};就是错误的。 string支持的操作(P77,3.2.2)1.输入流中获取字符串首先要强调是cin&gt;&gt;string的操作，这种操作就是从输入流中读字符串，值得注意的是这个过程会忽略掉开头输入的各种空白（我们说空白时是在说 空格，换行符，制表符）,读取输入流直到遇到字符后的第一个空白为止。 另一种getline（cin,string）;的操作则可以读一行，也就是读入输入流的数据（包括空格，制表符），直到遇到换行符为止，这里输入流中的换行符本身已经被读过了，但是字符串里不保存这个换行符。下次再从输入流里读什么数据至少也要从这个换行符后面对输入流进行操作了。 2.string::type_size为了更抽象，脱离机器特性，调用每个string对象的size成员函数，返回值都是一个string::type_size类型，这个类型拥有无符号整形数的一些性质。在string对下标的支持中，[ ]中的数字也会被转换为string::type_size类型。这里要强调的是string::type_size是一个无符号类型。使用这个类型和int型这种有符号的类型一起进行计算可能出现一些错误。1auto len = line.size(); //len的类型是string::size_type 如果一个表达式中已经有了size()函数，就不要再使用int了，这样可以避免混用int和unsigned可能带来的问题。 3.string对象与字符串字面值相加字符串字面值是字符数组类型，字符串字面值和string类型的对象在一起计算时会被自动转换为string类型。 4.其他支持的操作包括下标运算符[ ]、重载的+、==、！=、&lt;、&gt;、&lt;=、&gt;=。 范围for（range for）语句(P82，3.2.3)范围for语句用于遍历元素。形如： 123for(一个用于访问序列中基础元素的变量a : 被访问的序列对象b)&#123; statement..... blabla;&#125; 首次初始化，变量a的值会被初始化为对象b序列中的第一个元素，迭代之后每次访问下一个元素，直到序列被完全访问结束。 可以使用auto &amp;a的方式声明变量a,使变量绑定到具体的序列元素上，从而进行更改。如在for(auto a : str){}中，每次把a初始化的行为实质上是使a获得str每个元素的副本（拷贝），而for(auto &amp;a ： str){}这样的语句则使a成为了str对应的每个元素的”别名”,从而可以修改str。 使用范围for循环遍历多维数组，为了不手动打类名，也为了防止外层数组的名被auto类型转化成指针，要在对外层数组的访问上都加上&amp;绑定。]]></content>
      <categories>
        <category>C++ Primer</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
</search>
